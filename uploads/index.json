[
  {
    "id": "3f7ff646-f37d-4509-aa06-17399c438d68",
    "name": "aiclinical.pdf",
    "file_type": "pdf",
    "size": 12023986,
    "upload_date": "2025-08-31T02:37:28.202125+00:00",
    "content": "AI-based Clinical Decision Support\nfor Primary Care: A Real-World Study\nRobert Korom*,1, Sarah Kiptinness\n*,1, Najib Adan1, Kassim Said\n1, Catherine Ithuli1,\nOliver Rotich\n1, Boniface Kimani\n1, Irene King’ori\n1, Stellah Kamau\n1, Elizabeth Atemba1,\nMuna Aden2, Preston Bowman3, Michael Sharman3, Rebecca Soskin Hicks\n3,\nRebecca Distler3, Johannes Heidecke3, Rahul K. Arora\n*,3, Karan Singhal\n*,3\n1Penda Health 2Nairobi County 3OpenAI\nAbstract\nWe evaluate the impact of large language model-based clinical decision support in live care. In\npartnership with Penda Health, a network of primary care clinics in Nairobi, Kenya, we studied AI\nConsult, a tool that serves as a safety net for clinicians by identifying potential documentation and\nclinical decision-making errors. AI Consult integrates into clinician workflows, activating only when\nneeded and preserving clinician autonomy. We conducted a quality improvement study, comparing\noutcomes for 39,849 patient visits performed by clinicians with or without access to AI Consult across\n15 clinics. Visits were rated by independent physicians to identify clinical errors. Clinicians with access\nto AI Consult made relatively fewer errors: 16% fewer diagnostic errors and 13% fewer treatment errors.\nIn absolute terms, the introduction of AI Consult would avert diagnostic errors in 22,000 visits and\ntreatment errors in 29,000 visits annually at Penda alone. In a survey of clinicians with AI Consult, all\nclinicians said that AI Consult improved the quality of care they delivered, with 75% saying the effect\nwas “substantial”. These results required a clinical workflow-aligned AI Consult implementation and\nactive deployment to encourage clinician uptake. We hope this study demonstrates the potential for\nLLM-based clinical decision support tools to reduce errors in real-world settings and provides a practical\nframework for advancing responsible adoption.\n1\n1 Introduction\nArtificial intelligence (AI) systems have the potential to widen access to reliable health information and high-\nquality care (Beam and Kohane, 2018; Topol, 2019; Rajkomar et al., 2019). Large language models (LLMs)\nhave recently experienced significant leaps in performance, reliability, and safety for health applications\n(Arora et al., 2025; Nori et al., 2025; Singhal et al., 2023, 2025). These advances suggest new opportunities\nfor improving healthcare delivery—including supporting clinicians in delivering better care.\nDespite research progress, scaled real-world deployment of AI tools in clinical environments remains limited.\nState-of-the-art LLMs now often outperform physicians on benchmarks (Goh et al., 2025; Arora et al., 2025;\nNori et al., 2025; Van Veen et al., 2024), but these gains have yet to translate into measurable benefits for\npatients and clinicians in live care settings. The most critical bottleneck in the health AI ecosystem is no\nlonger better models, but rather the model-implementation gap: the chasm between model capabilities and\nreal-world implementation.\nClosing the model-implementation gap necessitates the responsible study of LLM implementations in frontier\nhealth AI use cases. One example is clinical decision support (CDS) systems (Sutton et al., 2020; Middleton\net al., 2016), which provide clinicians with relevant knowledge at the point of care. Efforts to measure\n∗Correspondence to: robert@pendahealth.com sarah.kiptinness@pendahealth.com rahul@openai.com karan@openai.com\n1This quality improvement study was conducted with the approval of Kenya’s Ministry of Health, Kenya’s Digital Health\nAgency, Nairobi County, and AMREF Health Africa Ethical and Scientific Review Committee (approval ESRC P1795/2024).\n1\nFigure 1: AI Consult is a safety net that runs in the background of a patient visit to identify potential\nerrors. It was iteratively designed with clinicians, providing outputs with green/yellow/red severity and\nissuing alerts only when needed to reduce errors. In this example, AI Consult provided a red flag that\nhelped a clinician identify and remove an unnecessary antibiotic prescription.\nhow well LLMs can help with clinical decisions so far have used offline evaluations, often measuring model\ncapabilities on clinical vignettes without capturing the unique challenges of designing and deploying an\nimplementation for real-world care (Benary et al., 2023; Goh et al., 2025; Oniani et al., 2024).\nIn this study, we examine the impact of an LLM-based clinical decision support tool in live care. Penda\nHealth, where several authors are affiliated, is a network of high-volume clinics in Nairobi, Kenya that\ndelivers 24-hour primary and urgent care to a broad range of Nairobi residents. We studied Penda’s AI\nConsult, which serves as a clinical safety net to prevent errors. The system is triggered asynchronously\nduring key clinical workflow decision points in the electronic medical record (e.g., diagnosis, treatment). It\nsurfaces guidance through a tiered traffic-light interface (green: no action, yellow: advisory, red: requires\nreview), and is explicitly designed to minimize cognitive burden and preserve clinician autonomy. The tool\nwas developed through iterative co-design with frontline clinicians and tailored to local epidemiology, Kenyan\nclinical guidelines, and Penda’s care protocols.\nTo assess the tool’s impact, we conducted a pragmatic cluster-assigned study of 39,849 visits, comparing\noutcomes for patient visits managed by clinicians with and without access to AI Consult. We aimed to\nevaluate three primary domains: (i) clinical quality, as rated by independent physicians reviewing clinical\ndocumentation with patient identification removed; (ii) use and usability, based on a clinician survey and\nAI Consult usage data; and (iii) patient-reported outcomes collected via routine follow-up calls. We find\nmeaningful reductions in clinical errors for clinicians with the tool (“AI group”) vs those without (“non-\nAI group”) and encouraging feedback from clinicians using AI Consult. We did not detect a significant\ndifference in patient-reported outcomes. This study was conducted with the approval and consultation of\nKenya’s Ministry of Health, Kenya’s Digital Health Agency, Nairobi County, AMREF Health Africa Ethical\nand Scientific Review Committee, Kenya’s National Commission for Science, Technology and Innovation\n(NACOSTI), and other local stakeholders to ensure it aligned with national priorities, ethical standards,\nand data protection requirements.\nThis study makes three key contributions:\n2\n• We describe a live deployment and study of an LLM-powered clinical decision support tool across\n39,849 patient visits, 106 clinicians, and 15 clinics.\n• We report findings:\n– We observe significant relative reductions in errors, including 32% for history-taking errors (num-\nber needed to treat [NNT] 11.3), 10% for investigation errors (NNT 27.8), 16% for diagnostic\nerrors (NNT 18.1), and 13% for treatment errors (NNT 13.9) for clinicians in the AI vs the non-\nAI group. In absolute terms, the introduction of AI Consult would avert diagnostic errors in\n22,000 visits and treatment errors in 29,000 visits annually at Penda alone.\n– AI group clinicians saw significant reductions in important clinical failure modes, including incor-\nrect primary diagnosis, inappropriate medications, missing patient education and follow-up plan,\nkey history details missing, and key investigations missing.\n– The effect of the tool became more pronounced after an initial induction period, when Penda\nrolled out active strategies to drive clinician uptake.\n– LLMs evaluating study visits found a greater difference in clinical errors between the AI group\nand the non-AI group than the difference found by physician evaluators (e.g., 22% reduction in\ntreatment errors and 19% in diagnostic errors according to GPT-4.1).\n– In routine follow-up calls, 3.8% of patients treated by AI group clinicians said they were not feeling\nbetter, compared to 4.3% for the non-AI group, a difference that was not statistically significant.\n– All survey respondents in the AI group said AI Consult helped them improve the quality of care\nthey could deliver, with 75% saying the effect was “substantial”.\n– Over the study, AI group clinicians learned to avoid “red” outputs even before receiving them\n(the fraction of AI group visits with initial red outputs decreased from 45% to 35% during the\nstudy), suggesting the tool helped clinicians improve their own practice.\n– In patient safety reports, there were no cases where AI Consult advice actively caused harm.\n• We describe the key factors for success: a capable model, a clinically-aligned implementation, and\nactive deployment strategies.\nThis work offers an early demonstration of the potential for LLM-based tools to serve as real-time copilots for\ndelivering care and a practical framework for advancing responsible adoption in real-world health systems.\n2 Background\n2.1 Primary care\nPrimary care clinicians see patients across every age group, organ system, and disease type, often in the\nsame day, requiring broad knowledge. The breadth of practice contributes to primary care quality challenges\nworldwide, with the WHO reporting substantial rates of preventable patient harm (WHO, 2023). This\nsuggests that AI systems could be especially useful in primary care.\nIn Kenya, primary care is largely delivered by clinical officers: clinicians who complete three years of aca-\ndemic training followed by a one-year supervised internship. They manage the full breadth of acute and\nchronic conditions across the life course. Structural challenges in Kenyan primary care (late presentation,\nhigh patient volumes, limited diagnostics) compound this wide scope of practice to create a sizable quality\ngap: Studies suggest low adherence to national guidelines by healthcare workers across multiple levels of\nKenya’s healthcare system, with frequent errors such as missed comorbidities, antibiotic overprescription,\nand diagnostic delays (Marete et al., 2020; Kr¨uger et al., 2017; Kiener et al., 2025).\n2.2 Penda Health\nPenda Health is a Nairobi-based social enterprise founded in 2012 that delivers comprehensive, 24-hour\nprimary and urgent care services through a network of fully-licensed medical centers distributed across the\ncity. The organization presently operates 16 clinics and records over 1000 patient visits a day, supported by\n3\na clinical workforce of more than 100 licensed clinical officers. For a video and photos depicting Penda’s care\ncontext and AI Consult, see the blog post that accompanies this paper.\n2.3 Digital infrastructure and clinical decision support at Penda\nPenda has invested substantially in its digital infrastructure and quality improvement programs over the\nyears, and has been a pioneer in implementing clinical decision support tools.\nElectronic medical record (2017). A cloud-hosted electronic medical record (EMR), Easy Clinic, was\nintroduced in 2017, supporting all patient visits and enabling real-time monitoring of quality metrics and\noperations.\nRule-based system (2019-2020). Penda implemented an early non-AI CDS system before its first iter-\nation of AI Consult (Korom and Njue, 2020). In this system, decision trees embedded in the EMR provided\npoint-of-care reminders for some common conditions. Similar early approaches have been employed and\nstudied in other contexts for many years (Papadopoulos et al., 2022; Bright et al., 2012; Musen et al., 2021).\nThe rule-based system and concurrent quality improvement efforts had a large effect. Within 12 months\nof deployment, guideline adherence at Penda rose from the national baseline of 40% to over 90%. While\nthe rule-based system was very effective for improving adherence to specific national practice guidelines, it\nwas narrow in scope: there was still a significant quality gap in clinical officers’ history taking, diagnostic\naccuracy, and patient management. Rule-based systems struggled to effectively support the wide variety of\nsituations a Penda clinician faces daily.\nAI Consult v1 (February 2024). Penda Health implemented an early version of an LLM copilot prior\nto the version studied in this work. AI Consult v1 provided feedback from an LLM on the current visit at\nclinician request. Clinicians clicked a button within the EMR during a patient visit, chose an area to receive\nfeedback on (including documentation, patient management, and overall visit), and received structured\nfeedback from an LLM. Similar to Penda’s other CDS iterations, clinicians reviewed the output of the tool\nand made all clinical decisions.\nDuring the early deployment of AI Consult v1, Penda performed an internal safety audit of 100 randomly\nselected cases. Each of these cases included (1) patient documentation state before AI Consult use, (2)\nAI Consult response, and (3) final documentation state, including any changes resulting from AI Consult.\nThese cases were reviewed by Penda’s quality team. Each AI Consult output was scored from 1–5, where\n5 was outstanding feedback from the LLM on the case (relevant, locally-appropriate, comprehensive, and\nactionable); 3 was neutral; and 1 was actively harmful (e.g., encouraging the clinician to perform unnecessary\ntests, offering an inappropriate diagnosis, or an incorrect or not locally appropriate treatment plan). Cases\nwere also annotated with qualitative notes on how clinicians may have acted on AI Consult responses.\nIn that audit, Penda assigned 64 outputs a rating of 5, 21 a rating of 4, and 14 a rating of 3 (one visit lacked\nsufficient clinical documentation to be analyzed). No AI responses were unsafe, and the team did not find\nany instances where the effect of AI Consult was harmful. Penda did find some qualitative improvements in\ncare after clinicians received AI feedback.\nDespite showing early promise in terms of patient safety and quality improvement, AI Consult v1 only\nachieved adoption in about 60% of visits. Qualitative notes showed many cases in which AI feedback was\nnot heeded despite being correct and clinically actionable. There was a need to further optimize the AI\nConsult workflow to seamlessly intervene at key decision points without creating alert fatigue, and to work\nclosely with clinician users to increase uptake. These analyses gave Penda’s quality team the confidence they\nneeded to further develop and test AI Consult.\nAI Consult v2 (January 2025). To create a universal “safety net” in the EMR workflow without increas-\ning cognitive load, AI Consult was re-engineered to run silently in the background at key workflow inflection\npoints (documentation of vitals and chief complaint, documentation of history and physical examinations,\n4\nordering diagnostic tests, diagnosis, management plan). Outputs are surfaced through a traffic-light inter-\nface: green: no action, yellow: advisory, red: mandatory review before proceeding. This design couples high\ncoverage with minimal interruption, and leaves the clinician with ultimate control over all clinical decisions.\nFor a video of AI Consult, see the blog post that accompanies this paper. In this work, we refer to this\nversion of the tool as “AI Consult”. The tool is described further in Section 3.1.\n2.4 Motivation for the present study\nCollectively, Penda’s large patient volumes and a highly variable disease mix, in combination with its strong\nquality program, digital maturity, and CDS experience make Penda’s clinics an informative setting for\nevaluating the impact of LLM-based clinical decision support on patient care.\nIn addition to evaluating the impact of LLMs in real-world settings, this study focuses on two additional\nfactors driving the successful uptake of AI-based CDS: clinically-aligned implementation (Section 3.2), or\nhighly iterative development of a tool well-integrated into clinical workflows, and active deployment (Sec-\ntion 3.4), or strategies to build clinician understanding of and buy-in for a tool. We find all three factors\n(model performance, clinically-aligned implementation, and active deployment) are crucial for successful\nimplementation and adoption.\n3 Methods\nHere, we describe AI Consult, how Penda integrated it into its clinical workflow, Penda’s rollout of the tool\nto half of clinicians, and the design and methods for our study of that rollout. For images of AI Consult, see\nFigs. 9 to 13. For a video of AI Consult, see the blog post that accompanies this paper.\n3.1 AI Consult\nDesign rationale. Penda’s AI Consult tool is conceived as a continuously-running safety net. Its core\nobjectives are to:\n1. Maximize coverage: the model reviews every visit and each major decision node, and this review\ndoes not require active clinician requests.\n2. Minimize cognitive load: model feedback interrupts the clinical workflow only when it identifies\nmaterial risk.\n3. Maintain clinician autonomy: the system issues recommendations, but all final decisions remain\nthe clinician’s.\nThere are three types of responses that can be returned, following a three-color traffic light interface:\n• Green: indicates no concerns; appears as a green checkmark.\n• Yellow: indicates moderate concerns; appears as a yellow ringing bell that clinicians can choose whether\nto view.\n• Red: indicates safety-critical issues; appears as a pop-up that clinicians are required to view and\nacknowledge before continuing.\nClassification thresholds must balance sensitivity against alert fatigue. The traffic-light approach helps create\nthis balance: red alerts are cases with high probability or severity of harm, meaning that alerts are likely to\nbe true positives and therefore can safely interrupt the clinician workflow. Yellow events are in an ambiguous\nmiddle region, and the bell helps engage clinician judgment without interrupting. Green events confirm that\nAI Consult is running correctly while fading into the background.\nAsynchronous, event-driven architecture. AI Consult is embedded in Penda’s cloud-hosted EMR\n(Easy Clinic). The EMR triggers AI Consult calls in response to predefined events: whenever the user\nfinishes typing and navigates away from a critical field (i.e., chief complaint, clinical notes, investigations,\n5\ndiagnosis, and medications), AI Consult will run in the background with the documentation state up until\nthat point and return a response to the clinician.\nPrompt engineering. The LLM prompt contextualizes the patient visit and contains Penda-specific\ncontext as well as a summary of relevant clinical practice guidelines. It then includes the task for the model,\nthe definition of each clinical category, and few-shot examples of red, yellow, and green responses for each\ncategory. The model is asked to return a color (alert severity level), a rationale for that color, and an action\nfor the clinician to consider. For the full prompts used in AI Consult, see Appendix E.\nModel-agnostic. The design of AI Consult—in particular, its reliance on a prompted general model rather\nthan a specialized or fine-tuned model—permits any model to easily be used. This allows more performant\nmodels, cheaper models, or models that meet other specific needs to easily be substituted in.\nPenda opted to use GPT-4o as the default model for AI Consult due to its strong few-shot reasoning and\nlow latency. At the time of the study, more performant models like GPT-4.1, o3, and o4-mini were not yet\navailable. While reasoning models offer advantages in terms of nuanced performance on challenging health-\nrelated questions, Penda found that minimizing latency was more important for the tool to give feedback\ntimely enough to be actionable to ensure clinician adoption, and thus maximize downstream impact of the\ntool.\nDevelopment. AI Consult was developed in partnership with Penda’s EMR vendor and Penda’s clinical\nquality and IT teams.\n3.2 Iteration towards clinically-aligned implementation\nTo achieve the clinically-aligned implementation of AI Consult used in the present study, Penda went through\nnumerous iterative development cycles. Penda’s clinical quality team initially documented the proposed\nproduct specifications and user acceptance criteria for the end-to-end tool. After initial development and\nprior to deployment to the production environment, Penda’s clinical quality and IT teams used, tested, and\nred-teamed AI Consult extensively in order to maximize safety and usability for frontline clinicians. During\nthe study’s induction period (described in Section 3.3), Penda’s teams also continued to iterate on AI Consult\nwith real user feedback.\nHundreds of design decisions were made during this process; here, we document the most important cate-\ngories.\nAI Consult triggers. A fundamental challenge in designing AI Consult is knowing when to call the model\n(i.e., when to have the model review documentation and return a response). If it is called prematurely,\nfeedback is returned before it is useful to the clinician. If it is called (or returns feedback) too late, the\nclinician’s decision-making moment has passed, and it can be challenging to reverse decisions already made.\nPenda initially explored the possibility of making model calls only at the point that a patient is sent to a\ndifferent physical location (e.g., pharmacy or laboratory). Testing revealed that by then, the clinician has\noften already explained the next steps to the patient; it can be uncomfortable for clinicians to walk those next\nsteps back if AI Consult recommendations conflict, making AI Consult less useful. After several iterations,\nPenda decided to trigger when users navigate away (“focus out”) from specific EMR fields.\nOne example of a specific technical challenge Penda faced in its implementation of triggers: if a user was\ntyping in a decision-triggering box (say, the clinical notes) and a red response appeared for a previous\nworkflow stage, acknowledging that red alert was considered an event which triggers AI Consult for the\ncurrent workflow. This results in another model call, even if the clinician user was not done with that\nsection. In testing, this behavior could lead to a painful cycle of red-alert pop-ups that were clinically\ninappropriate and led to alert fatigue. Identifying this in testing allowed engineers to modify the criteria for\nAI Consult triggers to exclude the acknowledgment of previous AI Consult alerts.\n6\nThreshold-setting. In live testing with clinicians, the overall usability of the tool was highly dependent\non the red/yellow/green severity thresholds. When the threshold for problems is set too low, over-triggering\nof the system becomes apparent immediately and clinicians may begin to ignore alerts.\nGiven the design of AI Consult, threshold-setting to avoid alert fatigue while still surfacing the most critical\nclinical problems is primarily a prompt engineering problem. Clear explanations and few-shot prompting\nallowed Penda to precisely define which gaps ought to trigger a red alert. For example, Penda included\nfew-shot examples to ensure that missing vital signs would trigger red alerts. Vital signs are so critical to\nchoosing diagnostic tests and making a diagnosis that a history and physical exam could not be considered\ncomplete if vital signs were absent. On the other hand, Penda had to moderate its expectations on the\ncomprehensiveness of history and physical examination. In initial testing, red alerts were over-triggering for\nmissing components of the clinical history. While the missing history components were not unreasonable,\nfully acting on these alerts would have required too dramatic of a shift in the documentation of history for\nPenda’s practice setting, so a more lenient threshold was selected here.\nUser interface. Subtle design decisions for the user interface can substantially impact the user experi-\nence and adoption of a new tool. Penda’s first iteration of the tool focused only on red-alert pop-ups for\nserious problems. However, many opportunities for clinical quality improvement are of intermediate (yel-\nlow) severity. Pre-deployment testing showed a need to allow these quality improvement opportunities to\nsurface to clinicians at the right moment without forcing a pop-up. Similarly, the initial UI did not include\na green checkmark for green model outputs, which caused clinicians to wait in case a yellow or red alert was\nincoming. The final iteration of AI Consult included this green checkmark to reduce cognitive overhead for\nclinicians.\nPenda also made final implementation improvements early in the rollout of the AI Consult tool, as described\nin Section 3.3.\n3.3 Quality improvement rollout\nPenda’s audit of AI Consult safety (Section 2.3) and the design of AI Consult as a safety net, with all final\ndecisions made by Penda clinicians, gave the Penda leadership team the confidence in AI Consult it needed to\npilot the tool more broadly. As part of its quality improvement practice, Penda decided to roll out AI Consult\nto half of its clinicians from January 30 2025 to April 18 2025. It rolled out AI Consult at the clinician level:\nhalf of clinicians in each clinic were randomly assigned to have access to AI Consult (AI group), while their\ncolleagues did not (non-AI group).\n2 As a further assurance during this rollout, Penda actively monitored\nmodel outputs throughout the course of the study through its established patient safety reporting process,\nrapidly reviewing any case where a patient experienced an adverse event. This process found no cases where\na model recommendation directly caused patient harm; see Section 4.3.2 for full findings.\nFigure 2: Timeline of AI Consult deployment and quality\nimprovement evaluation.\nThe first part of this rollout, from January 30\n2025 to February 28 2025, was an induction\nperiod for clinicians to familiarize themselves\nwith the tool. It included up-front training\nbut no active change management. The pri-\nmary period of the quality improvement eval-\nuation was from March 1 2025 to April 18 2025,\nand included active deployment to drive adop-\ntion from Penda quality and branch leadership\n(Section 3.4). A diagram of the timeline is in\nFig. 2.\n2Clinicians were split at the clinic-level across 15 clinics because different Penda clinics serve populations with different\ndemographics. The way Penda implemented this was equivalent to randomly allocating clinicians stratified by clinic, with block\nsize 2 and a 1:1 allocation ratio at the clinic level. Note that some randomized providers left Penda before the rollout started\nand are therefore not included in the study analysis.\n7\nShadow mode. AI Consult was also built with a shadow mode, where AI Consult would operate as normal\nin the background of a visit, calling an LLM and logging responses, but no alerts (whether red, yellow, or\ngreen) were shown to clinicians. When Penda ultimately rolled out AI Consult to the AI group, it also\nused shadow mode for the non-AI group providers, enabling Penda to compare AI group clinicians with\nnon-AI group clinicians by understanding triggers that would have occurred if non-AI group clinicians had\nAI Consult. This is used in reporting several of the results in Section 4.\nFinal implementation improvements during the induction period. Continuing to iterate on AI\nConsult after it was first deployed to clinicians in live care was also essential to make it as useful as possible.\nThe first part of Penda’s deployment was an induction period, intended to familiarize clinicians with the\ntool and to iterate given feedback.\nPenda continuously collected feedback from clinicians through online surveys and virtual roundtable discus-\nsions. This feedback surfaced further areas for improvement on AI Consult thresholds and prompting to\nprevent alert fatigue. For example, this helped Penda ensure AI Consult did not ask for patient history not\nroutinely collected at Penda or diagnostics unavailable in the Penda setting.\nDuring this time, Penda also shadowed clinicians at every clinic to see how they engaged with the tool\nduring their typical workflow. Clinician shadowing revealed a challenge not seen in pre-deployment testing:\nin real-world practice, many clinicians were facing system slowness that led to the AI Consult not providing\nnear-real-time feedback. Due to a combination of technical factors, the time taken to return AI Consult\nresponses had increased dramatically with the number of simultaneous API calls that were now being made.\nPenda re-engineered AI Consult’s code to improve its speed and asynchronous functionality, allowing the\nAPI call to return, on average, in under three seconds.\n3.4 Active deployment\nFollowing the initial deployment of AI Consult to Penda’s production EMR, Penda monitored the adoption\nof the tool, the safety and helpfulness of its outputs, and the extent to which clinicians acted on model\noutputs. Penda’s approach had three pillars:\n• Connection: Peer champions and branch managers explained why the copilot mattered, walked\ncolleagues through its strengths and limitations, and offered one-on-one coaching to support uptake.\n• Measurement: Penda tracked how often clinicians interacted with AI Consult recommendations and\nreached out with personalized coaching.\n• Incentives: Penda quality leadership recognized clinicians and clinics that used the tool well.\nConnecting with clinicians to share AI Consult strengths and limitations. The Penda team made\nconsiderable efforts to connect clinicians with AI Consult’s value.\nIn Penda’s continuing medical education sessions, clinical leaders identified real examples where an AI\nConsult clinician had received a red response and acted on it, and discussed with teams how this choice\nimproved the quality of care delivery. These examples built tangible buy-in for clinicians who could see in\nreal practice and hear from their peers about how the tool improved quality. Penda also nominated high-\nperforming peer champions at each clinic, who shared how they had learned to use AI Consult well and\nprovided suggestions and feedback to other clinicians to encourage successful uptake.\nPenda’s work to connect with clinicians also identified other factors that made it difficult for clinicians to act\non AI Consult. For example, some clinicians were accustomed to documenting patient visits asynchronously,\nmeaning a patient may have gone to receive medications before a provider documented medications and\nreceived AI Consult feedback. This and related patterns sometimes made AI Consult challenging to act on.\nPenda coached providers to document in real-time and trigger AI Consult before taking the next steps to\nensure AI Consult recommendations were considered. While a major workflow change for some, this was\nessential to enabling clinicians to act on the feedback in real time.\n8\nData and measurement. Penda’s data infrastructure was crucial to building the metrics required for\nmonitoring: the data backend allowed Penda clinical leadership to view AI inputs, red/yellow/green model\noutputs, and final patient documentation for over 8000 model calls per day.\nTo summarize this data, Penda’s clinical leadership team developed a single north star indicator: the “left\nin red” rate. This metric tracked the fraction of patient visits where the final AI Consult model call for any\ncategory was red. Recall that when a red pop-up occurs, the clinician must acknowledge it, but then has the\noption to either leave things as they are or change a decision. If a decision is changed, AI Consult will run\nagain, again returning a color for severity. If the issue causing the red alert was addressed, AI Consult will\nlikely return yellow or green, and would no longer be “left in red.” Thus, the left in red rate is a useful metric\nfor understanding the extent to which clinicians with AI Consult are acting on the most severe alerts. A\nhigh left in red rate could reflect that clinicians were not seeing AI Consult alerts, that they were not reading\nthese alerts, or that they were intentionally choosing not to act on the feedback from these results—each of\nwhich is valuable to understand to increase the tool’s impact. Improving this single metric enabled Penda’s\nteam to identify and improve instances of each of these failure modes.\nIn the first month of piloting the tool, Penda noticed that clinicians with AI Consult had only a slightly\nlower left in red rate compared to clinicians in the non-AI group (where the left in red rate could be\ncalculated because AI Consult was running in shadow mode, with data logged but without outputs shown\nto providers). Penda reviewed AI Consult’s red alerts and found them to be generally high quality, which\nmade it concerning that clinicians were often not heeding AI recommendations. Penda therefore entered a\nperiod of active change management to further drive adoption.\nCreating positive incentives. To socially incentivize use of AI Consult, Penda also shared individual\nleft in red rates with each AI group clinician and included their decile of performance compared to their\npeers. This approach provided positive encouragement for clinicians who were among the best in acting\non AI Consult feedback. It also showed clinicians who were not acting on the AI Consult outputs that\nthere was room for improvement relative to their peers—in many cases, clinicians were surprised about their\nrelative performance. These steps, combined with peer champion weekly coaching feedback, helped Penda\nsubstantially reduce the left in red rate for clinicians with AI Consult (Fig. 6).\n3.5 Study of AI Consult\nPenda and OpenAI embarked on a research study of the rollout across 15 clinics using routinely-collected\npatient documentation and outcomes. The study compared providers with and without access to AI Consult.\nWe examined the effects of the tool on (i) quality of care, including diagnosis and treatment errors (using\nclinical documentation with patient identifiers removed); (ii) patient-reported outcomes (using routinely-\ncollected patient outcomes data); and (iii) clinician workflows (using anonymous clinician surveys and clinical\nworkflow data).\nEthical considerations. This study was approved by the AMREF Health Africa Ethical and Scien-\ntific Review Committee (approval number ESRC P1795/2024) and conducted under a research license\nfrom the National Commission for Science, Technology, and Innovation in Kenya (license number NA-\nCOSTI/P/25/415242). This research was also approved by the Ministry of Health in Kenya, Kenya’s Digital\nHealth Agency, and Nairobi County.\nOnly patients who agreed to Penda’s general patient consent form—which includes consent for use of data\nwithout patient identifiers for research purposes and to follow-up calls to collect patient-reported out-\ncomes—were included in this analysis. Patients were also able to withdraw their consent for the use of\ndata in this study until 15 days after the end of the study period.\nGiven that the research involved no deviation from the care that patients would otherwise receive during\nthe phased rollout, all patient data used for study analysis was routinely-collected, and the analyzed data\nwere stripped of patient identifiers, the AMREF Health Africa Ethical and Scientific Review Committee\ndetermined that additional consent particular to this study was not needed beyond Penda’s existing consent\nform.\n9\nThe study also included a survey of clinicians to understand their satisfaction with Penda’s EMR and AI\nConsult. As these surveys are not ordinarily done, we sought explicit written consent from clinicians. These\nsurveys were fully anonymous.\nFunding. Funding for this study was provided by OpenAI. OpenAI was involved in the study analysis and\nreporting.\nReporting. The reporting of this quality improvement study was guided by the SQUIRE 2.0 statement\n(Ogrinc et al., 2016).\n3.6 Study population and data\nFor this study, we included data from all 15 Penda clinics in Nairobi County, Kenya.\n3 These centers provide\nboth primary and urgent care services, and also have laboratory and pharmacy services onsite. In most\ncases, these centers are located within Nairobi’s urban low- and middle-income demographic communities.\nWe included in-person visits at Penda where clinicians actively document in the Penda EMR. This means\nthat we excluded visit categories where clinicians generally do not actively document in the EMR, e.g.,\nover-the-counter medication requests, laboratory self-requests, as well as patients in Penda’s blood pressure\nchronic care management program “BP Sawa” and routine well-baby care. Finally, we excluded telemedicine\nvisits because they are not in person, and dental visits because of their more narrow focus.\nFrom January 30 2025 to April 18 2025, a total of 87931 patient visits were recorded at all of Penda’s clinics\n(Fig. 3). Of these, 52409 visits (59.6%) met the study eligibility criteria (Fig. 3). The remaining 35522 visits\n(40.4%) were excluded either because (1) they occurred at Penda’s single clinic outside Nairobi County (3878\nvisits, 4.4%); (2) they had an ineligible visit category (29210 visits, 33.2%); or (3) the patient was not seen\nby a clinical officer in the course of their visit (2434 visits, 2.8%). Among the 52409 eligible visits, 40745\n(77.7%) were visits where patients agreed to Penda’s general consent form and so were included in the study.\nAcross the study, 57 clinicians in the AI group had access to AI Consult, while the 49 clinical officers in the\nnon-AI group did not. Each clinician contributed a median of 395 visits in the AI arm and 428 visits in the\nnon-AI arm.\nPatient visits were split into the “AI” group if all clinicians who saw them had access to AI Consult and into\nthe “non-AI” group if no clinician who saw them had access to AI Consult. The AI group included 20589\nvisits (50.5% of visits with general consent), with clinician documentation available for 20589 (100.0%) and\nstructured outcome data for 7918 (38.5%). The non-AI group included 18990 visits (46.6% of visits with\ngeneral consent), with patient documentation available for 18990 (100.0%) and structured outcome data for\n7331 (38.6%). A small portion of visits (1166, 2.2%) were attended by clinicians in both groups, primarily\ndue to handover at shift change, and were excluded from analysis.\nPatient age, insurance vs cash-pay mix, and 8-day follow-up call response rates were generally well-balanced\nbetween the non-AI and AI arms (Table 1).\nVisits were distributed across Nairobi’s three service regions. Comparatively more patient visits in the AI\ngroup occurred in clinics in the Thika Road Corridor (42.8% AI vs 34.2% non-AI), while comparatively fewer\nwere in Eastlands clinics (38.4% vs 43.6%) and Southwest clinics (18.8% vs 22.2%) (Table 1).\n3.7 Data analysis\nStatistical analysis for this study was done using Python 3.12, using scipy for statistical testing, statsmodels\nfor statistical modeling, and a threshold of p = 0.05 in determining statistical significance. We conducted\n3The specific clinics included span Penda’s three service regions: Eastlands (Tassia, Umoja 1, Umoja 2, Embakasi, and\nPipeline); Southwest (Kangemi, Kawangware, Kimathi Street, and Lang’ata), and the Thika Road Corridor (Mathare North,\nKasarani, Sunton, Lucky Summer, Zimmerman, and Kahawa West). This is all but one of Penda’s facilities; the remaining one,\nGithurai 45, is located in Kiambu County and was excluded as we sought approval for this study specifically in Nairobi County.\n10\nFigure 3: Flow diagram showing visit eligibility, consent, group assignment, and data availability.\n11\nVariable Non-AI AI\nn 18,990 20,589\nInduction period (before March 1 2025) 7,773 (40.9%) 8,201 (39.8%)\nMain study period (March 1 2025 or later) 11,217 (59.1%) 12,388 (60.2%)\nVisit location: Eastlands clinics 8,277 (43.6%) 7,911 (38.4%)\nVisit location: Southwest clinics 4,223 (22.2%) 3,867 (18.8%)\nVisit location: Thika Road Corridor clinics 6,490 (34.2%) 8,811 (42.8%)\nAge (years), median [q25, q75] 20.8 [4.0, 32.2] 20.7 [3.9, 31.6]\nFemale 10,505 (55.3%) 11,282 (54.8%)\nMale 8,485 (44.7%) 9,307 (45.2%)\nInsurance visit 10,501 (55.3%) 11,713 (56.9%)\nCash visit 8,489 (44.7%) 8,876 (43.1%)\nDid respond to 8-day follow-up call 7,333 (38.6%) 7,919 (38.5%)\nDid not respond to 8-day follow-up call 11,657 (61.4%) 12,670 (61.5%)\nTable 1: Demographics of visits included in this study.\nan intent-to-treat analysis, comparing patient visits seen only by clinicians in the AI group with those seen\nonly by clinicians in the non-AI group.\n3.8 Effects on quality of care\nWe examined the effects of AI Consult on quality of care by having independent physicians rate visit docu-\nmentation stripped of patient identifiers.\nWe selected a random sample of 5666 visits recorded during the study. We then presented these to a panel\nof 108 physicians for review of documentation and clinical decision-making quality, including diagnosis and\ntreatment errors.\n4\nPhysician rater panel. The 108 physician raters included staff physicians and senior residents from\naround the world, including 29 from Kenya. The vast majority of these were family physicians, emergency\nphysicians, internists, pediatricians, or general practitioners. The remaining physicians had practice expe-\nrience in other relevant specialties: obstetrics, preventative medicine, physical medicine and rehabilitation,\ngeneral surgery, and public health. These physicians were selected by OpenAI using a multi-step process to\nensure their quality and performance. For more details on selection and the physician panel, see Arora et al.\n(2025).\nBlinding. Raters were blinded to whether the patient visit was in the AI or non-AI group. They also had\nno information about the quality improvement study, AI Consult, or study hypotheses. Raters were told\nthese visits occurred in a primary/urgent-care setting in Kenya and the resources available in the setting, so\nthey had enough information to rate visits.\nThe rating task. Physician raters were presented with a form containing patient documentation stripped\nof patient identifiers, which included the patient history (age, gender, vital signs, chief complaint, and clinical\nnote), any diagnostic investigations done with results, the clinician-assigned diagnosis, and management plan\nincluding medications, referrals, and any diagnostic investigations that could not be done in that clinic.\n4One consequence of this approach is that we have physician-assessed outcome data for a random sample of visits. We\npresent an analysis of all complete cases for this outcome, as is valid for data missing at random (Ross et al., 2020).\n12\nClinical Category Description\nHistory &\nExamination The patient’s presenting chief complaint, vital signs, past medical history, social and\nfamily history, and physical exam findings. A thorough history and physical examination\nis essential for high-quality clinical reasoning.\nInvestigations Diagnostic tests ordered or performed, including laboratory investigations, imaging, and\npoint-of-care tests. These investigations are critical to confirming or ruling out clinical\nhypotheses.\nDiagnosis Most likely clinical condition(s) given history and investigations. A high-quality diagnosis\ncaptures both primary and any clinically-relevant comorbid conditions with appropriate\nspecificity.\nTreatment Clinical management plan, including medications prescribed, procedures performed, refer-\nrals made, patient education, and follow-up instructions. Treatment should be individu-\nalized and guideline-concordant.\nTable 2: Descriptions of the four core clinical categories used to evaluate visit quality.\nPhysicians were asked to give a five-point Likert rating for (1) the depth and appropriateness of the history\nand physical exam; (2) whether appropriate investigations were done and inappropriate investigations were\nnot; (3) whether the diagnosis assigned was likely correct, and whether relevant additional diagnoses were\ncaptured if present (e.g., anemia being captured if present on blood testing, even if the chief complaint was\na respiratory illness); and (4) whether the management plan was correct and high quality. A score of 1 or\n2 on any of these Likert scales was intended to correspond to a clinically meaningful error.5 For full Likert\nscale definitions for each category, see Tables 15 to 18. For the reference examples provided to physicians of\neach Likert value for each category, including examples of Likert 1 and 2 errors, see Appendix I.\nFor each of these categories, physicians were also asked to enumerate the failure modes present (i.e., the\nspecific errors made in each category above), if any. For example, for the “diagnosis” category, physician\nraters were asked to choose as many options as applicable from the below. For all options across categories,\nsee Table 19.\n• Primary diagnosis is likely incorrect\n• Primary diagnosis is missing\n• Primary diagnosis is too specific to be supported based on current documentation or investigations (e.g.,\nusing “allergic rhinitis” as the diagnosis where it’s clear that rhinitis is present but documentation does\nnot support a specific etiology)\n• Primary diagnosis is too broad when a more specific diagnosis is supported\n• Additional diagnosis is likely incorrect\n• Clinically relevant additional diagnosis is missing (e.g. anemia)\n• None of the above\nFinally, we asked physicians to rate the acuity of the clinical scenario as “low”, “medium”, or “high”, to\nenable analysis stratified by severity. For the full form shown to physicians, including examples and full\nquestion text, please see Appendix I.\n5For cases after April 9, the structured chief complaint field was missing, so we omitted data from April 10 onward in analysis\nof History Likert and multiple-choice question data; sufficient information was still available about the history from the clinical\nnotes and other history fields to enable assessment of the patient note, and so we still included the investigations, diagnosis,\nand treatment data for these cases.\n13\nRater agreement. The physician rater panel was trained to reduce subjectivity and improve reliability.\nFor each Likert scale, we established golden examples for each Likert value based on the consensus of\nthree physician investigators, and shared these golden examples with the panel as reference points (see\nAppendix I). In addition to the multi-step onboarding and quality-filtering described in Arora et al. (2025),\nwe also provided detailed training on how to review clinical documentation to evaluators. This included\nupfront training over video call, frequent “office hours”, and ongoing clarifications when ambiguities arose.\nWe evaluate rater agreement by having a portion of unique tasks be completed by two independent raters.\nOf the 5666 visits rated, 1387 (about 25%) were rated by two physicians; the remaining 4279 of these were\nrated by a single physician. We calculated inter-rater agreement for the Likert scales, defining “agreement”\nas cases where the Likert values that two physician raters chose were within one point of one another. We\nalso calculate agreement on error (i.e., whether raters agreed on an instance being Likert 1/2 vs Likert 3/4/5)\nbetween two raters compared to the agreement that would be expected by chance using Fleiss’ κ.\nStatistical analysis. Our primary outcome measure is the relative risk reduction (RRR) in clinically\nmeaningful errors (i.e., Likert 1/2) for each category (history, investigations, diagnosis, and treatment)\nbetween the AI and non-AI groups.\nWe report the proportion of clinically meaningful errors in each group and the corresponding 95% Wilson\nconfidence intervals, comparing this between the non-AI and AI groups using Fisher’s exact test. We also\ncompute the relative risk reduction for errors in the AI group compared to the non-AI group, with its 95%\nconfidence interval computed using the Katz method. For cases rated by two physicians, we assign each\nrating weight 0.5 so that each visit ultimately has equal weight in the final analysis. We use the Benjamini-\nHochberg procedure to control the false discovery rate between the four clinical domains that we measure.\nWe also report covariate and clustering-adjusted measures of effect size. To do so, we fit a generalized linear\nmodel, using generalized estimating equations (GEE) to fit the model to account for within-clinician effects\nwhile yielding population-average effects. We fit a log-binomial GEE model, using a log link to estimate risk\nratios and calculate the relative risk reduction as 1 minus the risk ratio. We fit this model with grouping at\nthe clinician level, specifying an exchangeable covariance structure to account for clinician effects. The fixed\neffects we include in this model are AI vs non-AI (reference: non-AI), age (in years, continuous), gender\n(reference: male), and insurance vs cash visit (reference: cash). We also include clinic as a fixed effect\nin this model, both in order to estimate effects for specific clinics, and recognizing that we observe all of\nPenda’s Nairobi County clinics in this study.6 We use sum-to-zero coding for clinic, with Zimmerman as the\nnecessary omitted clinic.\nFinally, for robustness and to evaluate sensitivity to modeling assumptions, we also fit and report results from\na modified Poisson regression model with cluster-robust standard errors. The modified Poisson approach has\nbecome a common method to estimate relative risks in binary outcome studies (Zou, 2004; Zou and Donner,\n2013). We specify this analysis with the fixed effects specified above and include clinicians as clustering\nvariables.\nAdditional analyses. Our primary analysis was of the main study period, after the induction phase\n(March 1 2025 to April 18 2025).\nTo examine whether AI Consult signals correlate with clinical quality, we also study the physician-rated\nquality of cases that were “left in red” (i.e., where the final AI Consult response was red for at least one of\nthe five AI Consult categories, or would have been red for cases in the non-AI group) vs cases that were not\nleft in red. This measures how well the tool’s responses match the clinical judgment of our physician rater\npanel.\nWe also do sensitivity analyses to examine the effect of AI Consult in visits where there was at least one red\nAI Consult response, and in visits during the induction period only.\n6At Penda, clinicians operate across multiple clinics, so we cannot consider clinicians to be a level of grouping nested within\na clinic.\n14\nLLM rater analysis. We also conduct a version of this analysis where we have LLMs rate clinical docu-\nmentation, enabling rating of all patient documentation and the evaluation of LLM ability to conduct such\nratings. We conduct independent ratings using two different OpenAI models: o3, which is currently Ope-\nnAI’s most capable model in health, and GPT-4.1, which the HealthBench paper established as a strong\ngrader for health-related tasks (Arora et al., 2025).\nFor each rater model, we conduct analysis as described above, including computing risk ratios and fitting\nmodified Poisson regression and GEE models. We also study the agreement of each model-based rater with\nphysicians who rated the same visit, computing the rate of model agreement with physician ratings within\none Likert point, and again evaluating whether models agreed with physician ratings on whether a given\ntask contained errors (Likert 1/2 vs Likert 3/4/5) vs chance agreement with Fleiss’ κ.\n3.9 Use and usability analysis\nClinician survey. At the end of the rollout period, we invited Penda clinicians in both the AI and non-AI\ngroups to participate in an anonymous, consented survey.\nWe asked both groups about their experience with Penda’s EMR (including AI Consult) and whether it\nchanges the quality of care that they deliver on a five-point scale. We compare this between groups with a\nMann-Whitney U -test. We also asked the AI group about AI Consult: whether it changes the quality of\nthe care they deliver (five-point scale), whether they’d recommend AI Consult to others (to compute net\npromoter score), and their satisfaction (five-point scale). Finally, we solicited qualitative feedback from both\ngroups. The full text of the clinician survey is available in Appendix G.\nUsage data. We also examine differences in the median visit duration and median clinical documentation\nlength between groups, as well as the fraction of AI Consult responses given “thumbs up” ratings vs “thumbs\ndown” ratings by clinicians.\n3.10 Patient outcomes\nPatient-reported outcomes. As part of standard care, Penda Health makes calls to all eligible and\nconsenting patients by telephone 8 days after an index visit to collect patient-reported outcomes. Patients\nwho respond are asked whether they are feeling better on a five-point Likert scale (5 = “much better”, 4 =\n“a bit better”, 3 = “about the same”, 2 = “a bit worse”, 1 = “much worse”), with patients who report 3 or\nless defined as “not feeling better”. Patients are also asked whether they visited another pharmacy or went\nto another clinic themselves (without Penda’s referral; see Appendix F for the full script).\nPenda also identifies patients with more clinically severe presentations as possible candidates for one-day\nfollow-up calls, as described in Appendix H. Clinicians in Penda’s call centers ultimately decide which patients\nto follow up with, and call to ask whether patients’ conditions have worsened since their visit.\nWe compare these outcomes between the AI and non-AI groups with Fisher’s exact test. Given the high\nrates of missingness in patient outcome data (about 60%), we report a complete-case analysis that we treat\nas exploratory rather than confirmatory, following recommendations from Jakobsen et al. (2017).\nSerious escalations. We also monitored the frequency of serious escalations reported to Penda as part of\nroutine patient care through Penda’s patient safety reporting (PSR) system. This system, which has been\nin effect since 2020, allows any staff member at Penda to raise a quality or patient safety concern. PSRs are\noften raised by Penda’s customer service team when a patient experiences harm or potential harm that could\nbe related to their care at Penda. This includes harm that is deemed unavoidable (e.g., a new medication\nallergy) and serious errors that did not result in harm (“near miss” events).\nPenda’s clinical quality team reviews all PSRs to identify any safety or quality gaps that need to be addressed.\nWe examined the frequency and severity of such reports in the non-AI and AI groups. For reports in the\nnon-AI group, we examine whether AI Consult alerts that would have been raised during the patient’s visit\ncould have prevented harm or a near miss from occurring, if the clinician was able to see them and acted on\n15\nRRR: all visits NNT Yearly errors averted at Penda\nHistory 31.8% (21.9%-40.5%) 11.3 35383\nInvestigations 10.3% (1.0%-18.8%) 27.8 14388\nDiagnosis 16.0% (6.9%-24.2%) 18.1 22102\nTreatment 12.7% (6.8%-18.3%) 13.9 28880\nTable 3: Relative risk reduction in clinical errors. Includes overall effect size and number needed to treat for\nthe main study period. Also includes the absolute number of errors we would expect to be averted if this\ntool were widely deployed in the 400,000 annual patient visits at Penda.\nthem. For reports in the AI group, we examine whether the AI alerts raised during the patient’s visit could\nhave (i) been responsible for the harm experienced; (ii) failed to prevent harm; or (iii) have prevented harm\nbut failed to because the clinician did not see them or chose not to act on them.\n3.11 Data management and privacy\nWe handled, stored, and processed all participant data following Kenya’s Data Protection Act. Patient\ndata was fully stripped of patient identifiers (e.g., patient names, date of birth, phone numbers, national\nID numbers, medical record numbers, specific geography) as well as clinician identifiers. This removal was\naccomplished in two steps. First, Penda clinician training includes specific instructions not to use patient\nidentifiers in their free-text clinical notes. Secondly, the Penda data team reviewed the patient notes used in\nthis study to ensure privacy. They identified a very low rate of cases where possible patient identifiers were\nused (approximately 5 per 10,000 notes). In these cases, any identifiers present were redacted. The research\nteam had access only to this research dataset stripped of identifiers.\nParticipants were able to request that we remove their data from this study until 15 days after the AI Consult\nrollout ended. After that period, the data from participants was fully processed and anonymized, meaning\nit was not possible to remove it. No participant requested that we remove their data at any time.\nStudy data will be retained for a 5-year period after publication of the results to enable research reproducibil-\nity. After this period, all study-related data will be securely destroyed to ensure privacy and compliance\nwith data protection standards.\n4 Results\nWe present results on quality of care (Section 4.1), use and usability (Section 4.2), and patient outcomes\n(Section 4.3).\n4.1 Effects on quality of care\nAI Consult reduced clinical error rates. Error rates across each of the four clinical categories were\nsignificantly reduced in the AI group compared to the non-AI group. The relative risk reduction for AI\ncompared to non-AI was 31.8% (95% CI 21.9%-40.5%, p = 0.000) for history-taking, 10.3% (1.0%-18.8%,\np = 0.034) for investigations, 16.0% (6.9%-24.2%, p = 0.001) for diagnostic errors, and 12.7% (6.8%-18.3%,\np = 0.001) for treatment errors (Fig. 4, Table 3). All four p-values remain significant after applying the\nBenjamini–Hochberg procedure with FDR 5% across these tests.\nNotably, the number needed to treat (NNT) for AI Consult was low, particularly for a tool with such broad\neffects: 18.1 for diagnostic errors and 13.9 for treatment errors. If Penda adopted AI Consult across its\n400,000 annual visits, this would correspond to about 22102 fewer diagnostic errors annually and 28880\nfewer treatment errors annually (Table 3).\nWe also examined the effect size during the induction period. The error rate reduction for history, diagnosis,\nand treatment is much higher in the main study period compared to the induction period (e.g., for treatment,\n16\nFigure 4: Clinical error rates for history-taking, investigations, diagnosis, and treatment, comparing the AI\ngroup to the non-AI group. Error bars show 95% Wilson confidence intervals. * indicates p < 0.05, **\np < 0.01, *** p < 0.001.\nMain period, all visits Induction period Main period, only visits with reds\nHistory 31.8% (21.9%-40.5%) 16.7% (4.5%-27.3%) 30.8% (12.8%-45.1%)\nInvestigations 10.3% (1.0%-18.8%) 13.8% (2.7%-23.6%) 17.9% (-72.6%-60.9%)\nDiagnosis 16.0% (6.9%-24.2%) 6.4% (-5.6%-17.1%) 31.5% (14.0%-45.5%)\nTreatment 12.7% (6.8%-18.3%) 4.3% (-3.0%-11.1%) 18.0% (9.4%-25.9%)\nTable 4: Relative risk reduction in clinical errors across each category for all visits during the main study\nperiod, all visits during the induction period, and only visits with reds for the relevant category during the\nmain study period.\n12.7%, 95% CI 6.8%-18.3% during the main study period compared to 4.3%, 95% CI -3.0%-11.1% during\nthe induction period), providing evidence for the value of active deployment (Table 4).\nWe also examined the effect size in visits where there was at least one red AI Consult response for each\ncategory. The effect sizes for diagnosis and treatment were considerably higher in such visits (diagnosis:\nRRR 31.5% for visits with at least one red vs 16.0% for all cases; treatment: 18.0% vs 12.7%; Table 4).\nThere were no obvious trends in effect size by physician-rated acuity (Table 20).\nWe also fit statistical models to account for clinician clustering, clinic effects, and patient covariates, which\nyielded similar results to the unadjusted analysis. For diagnosis and treatment, GEE model effect sizes\nwere of the same magnitude and retained statistical significance: for diagnosis, 16.8% (GEE fit) vs 16.0%\n(unadjusted effect); and for treatment, 12.2% vs 12.7%. For history, the effect size was somewhat smaller\n(25.3% vs 31.8%), but retained statistical significance. For investigations, the effect size was similar (9.8%\nvs 10.3%), but had 0.05 < p < 0.1. Examining other model coefficients, there was notable variation in error\nrates across clinics for all categories. For the treatment category, we also observed a higher risk of errors in\nyounger patients. Full GEE results are available in Tables 21 to 24. Results from modified Poisson models\n(which are largely similar) are in Tables 25 to 28.\n17\nFigure 5: Rates of selected clinical failure modes in the AI group compared to the non-AI group. Error bars\nshow 95% Wilson confidence intervals. * indicates p < 0.05, ** p < 0.01, *** p < 0.001. For a full table of\nfailure modes and their rates in both groups, see Table 29.\nLastly, we also repeated this analysis using a large language model rather than physician ratings. We report\nfindings from this analysis in Table 6.\nThe rate of common clinical failure modes was lower in the AI group. We also had raters identify\nthe specific clinical failure modes present in the visit documentation. We find that several error categories\nare less common in the AI group, including the rate of key details missed in the history, key investigations\nmissed, or incorrect main diagnoses (Fig. 5). We also find that AI group visits were less likely to have the\nwrong medications prescribed or important patient education omitted. No failure modes are more common\nin the AI group compared to the non-AI group. For a full table of failure modes and their frequency between\ngroups, see Table 29.\nFewer visits were left with red AI Consult responses in the AI group. To understand how AI\nConsult achieved this effect, we examined how many visits had any calls left in red–that is, where the final\nAI Consult call in the visit was red, for any of history, investigations, diagnosis, or treatment.\nAt the start of the induction period, the left in red rate was similar between groups at 35-40%, suggesting\nthat clinicians in the AI group were only sometimes seeing or acting on the red alerts displayed to them.\nOnce Penda iterated on AI Consult to improve reliability and started active deployment, the left in red rate\nin the AI group dropped to 20% while the non-AI group rate stayed at 40% (Fig. 6a). This was also the\ncase when looking at cases where the treatment specifically was left in red (Fig. 19). This difference helps\nexplain AI Consult’s effects and also emphasizes the importance of user testing and active deployment.\nClinicians in the AI group learned to avoid common mistakes over time. We also examine the\nproportion of visits where AI Consult started red–that is, where the first AI call for any category was red.\nIn the AI group, this rate drops from 45% at the start of the study to 35% at the end of the study, while\nstaying steady at 45-50% in the non-AI group during the study (Fig. 6b). This suggests that AI Consult\nis training clinicians to avoid common mistakes even prior to AI Consult alerts. We see this training effect\neven when only looking at the history-related AI Consult categories, indicating that this effect cannot just\nbe explained by AI Consult history popups leading to better initial diagnoses and treatments (Fig. 17). We\nalso see this training effect when looking at cases where the treatment specifically started red (Fig. 18).\nTo further interrogate this training effect, we examine the distribution of the left in red rate across clinicians\nover time. We find that the active deployment period led to a considerable drop in the left in red rate for\nthe 10th percentile clinician from 20% at the start of the study to 0% at the end (Fig. 20). The 25th, 50th,\n18\nLeft in red Left in yellow Left in green p: R vs Y p: Y vs G\nHistory 33.3% (28.5%-38.6%) 22.7% (21.0%-24.5%) 14.5% (11.0%-18.9%) 0.000 0.000\nInvestigations 29.4% (19.9%-41.1%) 32.5% (29.3%-35.8%) 30.7% (27.6%-33.8%) 0.686 0.456\nDiagnosis 46.2% (40.7%-51.7%) 35.3% (32.8%-37.8%) 20.5% (18.4%-22.9%) 0.000 0.000\nTreatment 68.1% (64.1%-71.9%) 54.0% (51.7%-56.3%) 33.6% (29.6%-37.9%) 0.000 0.000\nTable 5: Clinical error rates in cases where the final AI Consult response was red, yellow, or green for the\nrelevant category. p-values calculated by Fisher’s exact test.\nand 75th percentiles also improved considerably. In contrast, the 90th percentile (clinicians with the highest\nleft in red rate) regressed towards the end of the active deployment period, suggesting that these clinicians\nmay have been generally disengaged.\n(a) Left in red rate: rate of visits where the final call\nfor any of the AI Consult categories is red, for AI and\nnon-AI groups over time.\n(b) Started red rate: rate of visits where the first call\nfor any of the AI Consult categories is red, for AI and\nnon-AI groups over time.\nFigure 6: Rates of visits left in red and started in red over time for AI and non-AI groups.\nAI Consult severity corresponds to clinician-graded severity. Our analysis of visits left in red raises\nthe question of whether AI Consult responses (and left in red rates) correlate with clinical quality. To answer\nthis question, we examined the clinical error rate in cases where AI Consult was left in red, yellow, or green.\nFor history, diagnosis, and treatment, error rates were substantially higher in visits that were left in red vs\nyellow, and for visits that were left in yellow vs green (Table 5). For example, for the diagnosis category, the\nclinical error rate was 46.2% (95% CI 40.7%-51.7%) for reds, 35.3% (95% CI 32.8%-37.8%) for yellows, and\n20.5% (95% CI 18.4%-22.9%) for greens.\nInter-rater reliability. We examined inter-rater agreement using the 1387 cases where two physicians\nindependently assigned ratings to the same case, for each of the four Likert types (history, investigations,\ndiagnosis, and treatment). We first examined the within-1 agreement: the proportion of cases in which the\ntwo Likert ratings differed by no more than one point. Inter-rater agreement for the history Likert was 77.8%\n(95% CI: 76.2%- 79.4%); for the investigations Likert, it was 66.0% (64.2%- 67.8%); for the diagnosis Likert,\nit was 69.1% (67.3%- 70.8%); and for the treatment Likert, it was 67.1% (65.3%- 68.9%). Full confusion\nmatrices are in Appendix D.1 (Fig. 14).\nWe also computed Fleiss’ κ to examine how much two physician raters agreed as to whether an error was\npresent (i.e., whether a Likert was 1/2 vs 3/4/5) compared to the agreement expected by chance. Fleiss’ κ\nranges from −1 to 1, with negative values indicating less agreement than by chance, zero indicating chance\nlevels of agreement, and positive values indicating more agreement than by chance. Fleiss’ κ indicated fair\nagreement between two human raters for each category: 0.260 for history errors, 0.285 for investigation\nerrors, 0.232 for diagnosis errors, and 0.223 for treatment errors.\n19\nPhysician raters GPT-4.1 o3\nHistory 31.8% (21.9%-40.5%) 46.5% (42.5%-50.2%) 46.4% (42.5%-49.9%)\nInvestigations 10.3% (1.0%-18.8%) 9.9% (6.8%-12.9%) 13.7% (9.5%-17.6%)\nDiagnosis 16.0% (6.9%-24.2%) 19.4% (15.5%-23.2%) 16.4% (12.7%-19.9%)\nTreatment 12.7% (6.8%-18.3%) 21.5% (19.4%-23.7%) 19.1% (17.1%-21.1%)\nTable 6: Relative risk reductions based on clinical ratings provided by physicians, GPT-4.1, and o3.\nLanguage model ratings agree with physician ratings and suggest a stronger AI Consult effect.\nWe were interested in whether our findings were robust to different raters and the quality of large language\nmodels’ ratings compared to human expert ratings. To examine this, we provided GPT-4.1 and o3 with\nthe same instructions as our physician raters, asked them to rate clinical documentation, and examined the\nresulting agreement with human raters and relative risk reduction.\nWe found that the agreement between model ratings and physician ratings exceeded the agreement between\ntwo physicians: for example, the within-1 agreement for history was 87.0% for GPT-4.1 and physicians and\n86.6% for o3 and physicians, compared to 77.8% for physician-physician agreement (Table 30). This was\nalso true for Fleiss’ κ on whether an error was present: GPT-4.1 and physicians had κ = 0.283 and o3 and\nphysicians had κ = 0.306, while the physician-physician κ = 0.260 (Table 31).\nBoth the GPT-4.1 and o3 analyses find that AI Consult significantly reduces clinical errors across categories,\nand generally find larger effect sizes compared to physician raters. For example, physician raters found a\ntreatment error RRR of 12.7% (6.8%- 18.3%). For GPT-4.1, the corresponding RRR was 21.5% (19.4%-\n23.7%) and for o3, it was 19.1% (17.1%-21.1%; Table 6 and Figs. 21 and 22).\nWe also ran modified Poisson regression and GEE regression models for both GPT-4.1 and o3 graders. These\nshow a statistically significant and favorable effect from AI Consult. Modified Poisson models generally have\nsimilar effect sizes to the unadjusted analysis; the effect sizes for the GEE models are sometimes similar (e.g.,\nGPT-4.1 diagnosis) and sometimes smaller (e.g., GPT-4.1 treatment), but retain statistical significance. Full\nregression tables are available in Tables 32 to 47.\n4.2 Use and usability\nWe surveyed clinicians in both groups to ask them how the EMR affects the quality of care that they deliver.\nWe also asked clinicians in the AI group for their feedback on AI Consult. Note that response rates for this\nanonymous survey were relatively low, with 23 clinicians in the non-AI group (47%) and 36 clinicians in the\nAI group (63%) responding, meaning that these results should be interpreted with caution.\n(a) Impact of the EMR (including AI Consult, if\npresent), on quality of care in both the AI and the non-\nAI group.\n(b) Impact of AI Consult specifically on quality of care.\nFigure 7: Clinician survey results: impact of AI Consult on quality of care.\n20\nClinicians felt that AI Consult improved quality of care. Significantly more respondents in the AI\ngroup than in the non-AI group noted that the EMR (including AI Consult) improved the quality of care\nthey were able to deliver (p = 0.046, Fig. 7).\nIn their qualitative EMR feedback, the non-AI group mostly emphasized operational improvements—speed,\ntidy documentation, easier stock checks—and in one case asserted that the EMR doesn’t give option in terms\nof treatment. The treatment depends on me. In contrast, the AI group framed the EMR as an active clinical\npartner: “It has helped me in multiple occasions to make the correct clinical judgment,” and highlighted\nsupport for “comprehensive management . . . from nutrition [to] pharmacological” alongside provision of\n“real-time evidence-based practices”. Both cohorts stressed time savings, workflow efficiencies, and improved\ndocumentation: “EMR is fast as compared to manual system.”\nOverall feedback on AI Consult was quite positive. All clinicians in the AI group said that AI Consult\nimproved quality of care, with 75% saying that it substantially improved care (Fig. 7). Clinician net promoter\nscores for AI Consult were also favorable, with an overall net promoter score of 78 (minimum possible −100,\nmaximum possible 100; for reference, the average net EHR experience score, a similar construct, was 33 in\none study across multiple EMR implementations (KLAS, 2003); Fig. 23). While satisfaction was generally\nhigh, more clinicians noted that they were “somewhat satisfied” with AI Consult (58%) than “very satisfied”\n(42%), indicating that room for improvement remains (Fig. 24). In qualitative feedback, clinicians described\nAI Consult as “helpful, easy to use, and improves the quality of care.” One clinician “noted an improvement\nin our clinical notes, which has had a ripple effect on non users of AI” (Table 7).\nOpportunities for improvement included localization, alert fatigue, and workflow integration.\nConstructive feedback covered broader clinical refinement (“Although there are errors or AI hallucination\ncases, overall performance . . . has done tremendous improvement in service delivery”), error-detection\nenhancement, and localization needs (e.g., “keep updating the software to include locally available drugs and\nmanagement options available in a resource limited medical centers”). Clinicians also cited alert fatigue\nand shifting recommendations (“At some point it keeps on changing the approach of management. . . ”),\ndocumentation burden, and workflow integration gaps (e.g., “In cases where you give a stat dose. . . it flags\nred saying the management is incomplete”).\nClinicians in the AI group had longer attending times, which they used to resolve AI Consult\ntriggers and improve quality. EMR data reveal that the clinician attending time is higher for visits\nin the AI Consult group (median 16.43 minutes) compared to the non-AI Consult group (13.01 minutes;\np = 0.000).\nTo examine how AI Consult affects this, we plot median clinician attending time by number of AI Consult\ntriggers in both the non-AI and AI groups (Fig. 8a). This includes red, yellow, and green triggers, reflecting\ncase complexity as clinicians revisit and change the documentation over time. We see very similar attending\ntimes between groups for a small number of AI Consult triggers. The AI group attending time increasingly\nexceeds the non-AI group attending time with more triggers, suggesting that this increased time is being\nspent by clinicians in responding to AI Consult feedback. Moreover, we also see improved clinical performance\nfor cases with a higher number of AI calls: the rate of treatment errors (here based on GPT-4.1 ratings, to\nincrease sample size and reduce noise) is similar for low numbers of AI Consult triggers and increases more\nrapidly for the non-AI group compared to the AI group (Fig. 8b). We also observe that the rate of treatment\nerrors in the AI group is less than in the non-AI group in visits with the same attending time, suggesting\nthat AI Consult reduces errors even when controlling for visit duration (Fig. 25).\nClinical notes were typically longer for clinicians in the AI group. AI Consult encouraged clinicians\nto provide more detail in their clinical notes. The median clinical note length was higher in the AI group\nthan the non-AI group over the course of the study (initially, 500 vs 400 characters in the AI vs non-AI\ngroup), and this difference grew larger when the active deployment period started (during the week of March\n10th, 600 vs 450 characters; at the end of the study, 600 vs 490 characters; Fig. 26).\n21\nTheme Representative positive quotes Representative constructive quotes\nPatient Safety\n• “It always alerts whenever there is a\nquality concern. . . can see the small\nthings we overlook.”\n• “Good reminder in case I miss\nsomething.”\n• “I have been able to identify gaps in\ntreatment and this improved treatment\nquality.”\n• “Acts like a consultant in the room.”\n• “It improves quality but also can\nmislead.”\n• “It is not 100% detecting errors.”\n• “When am prescribing injectables to my\npatients the AI rates me red even after\ndocumenting that my patient vomits\neverything and can’t retain any\nmedication.”\n• “The Ai tool can work on not\nexaggerating certain conditions that\nrequire simple management”\nKnowledge and\nProfessional\nDevelopment\n• “It’s very informative and broadens my\nknowledge.”\n• “It sharpens my skills.”\n• “Helps one know when they are on the\nright track, as it also guides on what next\nstep to take or forgotten inputs.”\n• “It’s also a learning tool.”\n• “If possible you update it with the\ncurrent guidelines of management for\nselective groups e.g. Pregnant mothers.”\nGuideline-Based\nManagement and\nStewardship\n• “Has made me be thoughtful on\nprescriptions of medication that we\nunnecessarily administer for certain\nconditions.”\n• “It keeps one in line with the current\nguidelines.”\n• “Aligning it more to our protocol and\nguidelines managements published in\nKenya would be amazing.”\n• “Needs to be updated with Kenyan\nguidelines on disease management. . . I\nencountered [issues] on meningitis, heart\nattack, hypertensive emergency.”\nWorkflow and\nEfficiency\n• “Helps... make better decisions and\nreduce errors.”\n• “It takes much time because it requires\nadequate documentation in history and\nexamination bucket.”\n• “Would be nice if the speed is enhanced\nand red alerts come before the other\nalerts.”\nOverall\nEnthusiasm\n• “It’s one of the best innovation to\nhappen at Penda.”\n• “It should be provided to all health care\nproviders.”\n• “AI is a good idea whose time has come.”\n• “AI is a good tool in clinicals because it\nprovides thoughtful information. . . but\nkey factor is to make diagnosis more\nbroader and reducing prompts otherwise\nit is generally a good tool.”\nTable 7: Representative clinician user quotes on AI Consult, grouped by theme.\n22\n(a) Median clinician attending time by number of AI\nConsult triggers in the non-AI and AI groups. 95% CIs\ncalculated with 1000 bootstrap samples. Includes only\nvisits with 12 or fewer AI Consult calls.\n(b) Rate of treatment errors from GPT-4.1 by number of\nAI Consult triggers in the AI vs non-AI groups. 95% CIs\ncalculated with 1000 bootstrap samples. Includes only\nvisits with 12 or fewer AI Consult calls.\nFigure 8: Median clinician attending time and rate of treatment errors by number of AI Consult triggers\nin the non-AI and AI groups. Results suggest that in visits where there were more AI Consult triggers,\nclinicians in the AI group spent time responding to AI alerts and made fewer treatment errors as a result.\nRate in non-AI group Rate in AI group p\nRate of patients not feeling better 4.3% (3.7%-4.9%) 3.8% (3.3%-4.4%) 0.234\nSaw a pharmacist 3.5% (3.0%-4.1%) 3.4% (2.9%-3.9%) 0.687\nSelf-referred to another clinic or hospital 2.9% (2.4%-3.4%) 3.0% (2.5%-3.5%) 0.803\nUnplanned visit at penda 6.2% (5.8%-6.7%) 6.0% (5.6%-6.5%) 0.532\nFeeling worse on one-day follow-up 2.2% (0.8%-6.3%) 3.3% (1.5%-7.1%) 0.737\nTable 8: Rates of patient outcomes in the AI vs non-AI group.\nClinicians generally gave positive feedback on AI Consult responses. When clinicians received\nan AI Consult response, they could give feedback by clicking thumbs up or thumbs down buttons. Among\n155450 AI Consult responses in the AI group, raters gave feedback on 19493 (12.5%). Of these, they gave\nthumbs up feedback on 18424 (94.5%), and thumbs down feedback on the remaining 1069 (5.5%). Much of\nthe thumbs down feedback happened within the first two weeks of the induction period, while the prompts\nwere still being iterated on (thumbs down rate of about 13%); after that period, the thumbs down rate was\nbetween 4% and 7% in any given week (Fig. 27).\n4.3 Patient outcomes\n4.3.1 Patient-reported outcomes and unplanned follow-up visits\nThere were no statistical differences in patient-reported outcomes. The share of patients who\nstill felt unwell seven days after the visit fell slightly from 4.3% (95% CI 3.7% –4.9%) in the non-AI arm to\n3.8% (95% CI 3.3% –4.4%) in the AI arm (Fisher’s exact test p = 0.234; Table 8), reflecting no statistical\ndifference. The present study was not powered to detect an effect of this magnitude. Moreover, this analysis\nshould be treated as exploratory rather than confirmatory given the high rate of missingness (Jakobsen et al.,\n2017).\nThe rates of patients who sought unplanned, unreferred follow-up care was also quite similar between groups\n(Table 8). The sample size of patients who responded to one-day follow-up calls at Penda was quite low\n(about 500) with low outcome rates, making it challenging to draw conclusions.\n23\nPatients were less likely to seek care outside Penda if inappropriate medications were given.\nWe conducted a post-hoc analysis to investigate how often patients sought care outside Penda depending on\nwhether inappropriate medications were given, as rated by a physician. This rate was lower if inappropriate\nmedications were given (7.9%, 95% CI 6.7%-9.4%) than if only appropriate medications were given (12.3%,\n95% CI 10.4%-14.4%; p = 0.000), suggesting that these patient-reported outcomes are tied to patient per-\nception of the care they received and whether they feel their needs for medication were met, regardless of\nwhether the needs were well-justified.\n4.3.2 Patient safety reports\nAcross the 10-week study, 12 patient safety reports (PSRs) were documented: five in the non-AI group and\nseven in the AI group. Each event was independently reviewed for (i) whether a clinical quality lapse was\npresent, (ii) severity of the event, and (iii) whether AI Consult contributed to harm (if present) or could\nhave mitigated harm.\nAI Consult advice could have prevented errors in some cases if available or heeded. In the\nnon-AI group, three events had AI Consult reds not visible to the clinician that, if visible and followed, might\nhave prevented the lapse (missed anemia work-up, unsafe neonatal prescription, and unrecognized high-risk\nchest pain). This included one mortality event, in a young adult with chest pain and tachycardia, where\nAI Consult (which was silent to the clinician) flagged multiple red alerts regarding closer cardiopulmonary\nevaluation.\nIn the AI group, there were similarly three cases where AI Consult issued red or yellow-alert guidance\nthat, if seen by clinicians or heeded, would likely have averted or reduced harm. This also included one\nmortality event, during the induction period. This event was in an infant with vomiting, fever, and low\noxygen saturation. AI Consult produced multiple red alerts recommending respiratory reassessment and\noxygen administration. It is unclear whether these alerts were acknowledged or seen by the clinician, as this\nevent occurred early in the induction period before acknowledgment was tracked and when AI Consult red\nalerts were not reliably visible.\nWhile AI Consult failed to prevent harm in some cases, it did not actively cause harm in any\ncases. Three AI group patient safety reports revealed limitations of AI Consult in which it did not prevent\nharm. In these three cases-pediatric peptic-ulcer misdiagnosis, use of a contraindicated medication in the\nfirst trimester of pregnancy, and a missed positive H. pylori test-the AI system failed to suggest a safer\nalternative. These were all cases where AI Consult did not change the course of the clinical encounter. In\nno patient safety report did AI Consult make suggestions that created new risk for patients.\nAI Consult advice could not have prevented errors in other cases. Two non-AI group events and\none AI group event centered around limited history or documentation. In these visits, AI Consult could not\nhave changed the outcome because the necessary clinical detail was never entered or the patient left before\ncare could be completed.\n5 Discussion\nOur findings demonstrate that a large language model–based clinical decision support tool can meaningfully\nreduce diagnostic and treatment errors when deployed in live outpatient care. This improvement occurred\nnot in simulation or review of EMR data, but in the context of routine, real-world practice across nearly\n40,000 patient visits in 15 clinics—supporting our view that AI systems, when carefully implemented in\nclinician workflows, can enhance care quality.\nThe scale and scope of AI Consult are also notable. Unlike prior decision support systems which target\nnarrow conditions, specialties, or workflows—such as drug interactions or chronic disease screening—AI\nConsult operated continuously, across all patient visits and key decision points.\n24\nOne of the most important implications of this work is the potential for AI tools to further improve the\nquality of care delivered by primary care clinicians. By functioning as an asynchronous safety net and\nsurfacing real-time feedback at decision points, AI Consult provides lightweight supervision that improved\ncare without undermining clinician autonomy. In this sense, the system serves not only as a quality assurance\nmechanism but as an empowering tool for clinicians.\nBeyond reducing errors in real-time, AI Consult appeared to foster substantial skill gains. During the\nstudy period, the proportion of visits that “started red”—a proxy for clinicians missing a critical issue on\nfirst pass—for treatments specifically fell by about 10–15 absolute percentage points in the AI group while\nremaining flat in the non-AI group. Because these initial alerts precede AI feedback on treatments, the decline\nsignals that clinicians internalized the system’s feedback and preemptively avoided common failure modes.\nThe magnitude of the effect is notable; for every 7-10 patients AI group clinicians saw, they avoided one\nimportant initial treatment error. Such learning effects were evident not only for treatment decisions but also\nfor history-taking, suggesting AI Consult facilitates broader learning rather than narrow protocol adherence.\nThese findings, together with survey responses citing the tool as “very informative,” “a learning tool,” and\nhelpful in “sharpening my skills,” support the view that well-designed copilots can function as continuous,\ncase-based education—uplifting individual competence while simultaneously safeguarding patients.\nClinically-aligned implementation was a key factor in the effectiveness of AI Consult. Penda’s previous\niteration of AI Consult (Section 2.3) achieved limited uptake because it required clinicians to interrupt the\nflow of a patient visit to request AI feedback. The iteration we studied here provided a tiered, low-friction\ninterface, enabling broad coverage with minimal disruption and alert fatigue. These changes reflect learnings\nfrom the implementation science literature, which has found that avoiding alert fatigue and surfacing CDS\nrecommendations automatically instead of on demand improved clinician adherence (Kawamoto et al., 2005;\nVan de Velde et al., 2018; Seidling et al., 2011). Clinician feedback affirmed the utility of the tool–all AI\ngroup survey respondents reported that AI Consult improved the quality of care they could deliver–and\nindicated overall enthusiasm (“It should be provided to all health care providers”).\nActive deployment was another key factor for the success of AI Consult. The tool had a significantly greater\neffect during the main study period (when active deployment strategies were employed) compared to the\ninduction period (Table 4), with a clear divergence between AI and non-AI groups for left in red rate and\nstarted red rate over the seven weeks of the main period (Fig. 6). Based on these strong improvements over\na short period, we would expect further gains from longer active deployment efforts. We expect the change\nmanagement pillars introduced in Section 3.4–connection, measurement, and incentives–to be similarly im-\nportant for future AI CDS tools.\nPatient safety reports show that AI Consult has clear potential to reduce patient harm. In half of the\nreviewed reports, harm might have been prevented if AI Consult had been used and its guidance followed.\nBoth deaths reviewed were judged to be potentially preventable with correct AI Consult use. The reports\nhighlight the importance of adherence: AI group users ignored critical alerts in some cases, highlighting the\nneed for improved clinician trust and responsiveness to AI recommendations as part of active deployment\nefforts. While there were no cases where AI Consult recommendations actively caused harm, in some reports,\nAI Consult failed to prevent minor or moderate harm, suggesting room for improvement. In other cases,\nAI Consult was unable to help due to inadequate clinician documentation, emphasizing the importance of\nclinician buy-in and training.\nLocalization to Penda’s clinical context was important to clinicians. A considerable amount of variation in\nmedical care can be explained by different norms between facilities and geographies, and systems that are\nacceptable to end users need to be responsive to this variation. With today’s capable and steerable models,\nlocalization may not require fine-tuning or specialized models–our experience was that prompting the model\nto share the Kenyan epidemiological context, provide details about Penda’s setting and care protocols, and\noutline local clinical practice guidelines were all helpful steps towards localization.\n5.1 Limitations\nAI Consult represents an early, promising archetype of an AI-powered clinical copilot. While the results\nare encouraging, we emphasize that this is a first step. Continued iteration will be essential—to reduce\n25\ndocumentation burden, improve contextual relevance, and align more closely with local practice norms. Fu-\nture implementations may include voice-first interfaces, real-time charting assistants, or agents that execute\nclinician-confirmed actions in electronic medical records.\nAlthough AI Consult was associated with reduced diagnostic and treatment errors, we did not observe\nstatistically significant differences in patient-reported outcomes during the study period. This may reflect\nlimitations in measurement sensitivity, response rates (response rates were 40%), short follow-up period,\nor the relatively short duration of the study. Further work—particularly large studies powered for patient\noutcomes—will be needed to assess the downstream impact of AI-assisted care.\nPhysician panel inter-rater reliability was fair but not excellent, despite shared golden examples, multi-\nstep onboarding and quality-filtering, task-specific training, and ongoing “office hours”. Interestingly, when\nprovided the same form as the physician panel to review visits (Appendix I), o3 and GPT-4.1 both displayed\ngreater rater agreement with physicians than other physicians. Both models also found larger effect sizes\nfor AI Consult than physicians did (Table 6). While greater effect sizes may be the result of Goodhart’s\nLaw (clinician documentation is assessed by an LLM in AI Consult as well), the greater model-physician\nagreement compared to physician-physician agreement suggests that LLM ratings, if validated via physician\nagreement on a subset of cases, may be a way to scale up both routine quality improvement and studies like\nthis one.\nClinician survey response rates were somewhat low–63% of clinicians in the AI group and 47% in the non-AI\ngroup responded. While clinicians were broadly positive about the utility and usability of AI Consult in their\nresponses, they also reported areas of improvement, particularly around response time and localization. We\nobserved that clinicians with many AI Consult triggers had longer visit times but also a greater reduction in\ntreatment errors (Fig. 8), suggesting a quality-time tradeoff in the design and deployment of AI-based CDS\ntools that needs additional study.\nBroader generalizability also requires further research. Penda Health is a particularly strong setting for\ndigital health implementation, given Penda’s dedicated technical infrastructure investments and its focus on\nhighly affordable care. Penda’s implementation of AI Consult was tailored to its local context, and clinician\nuptake required active deployment work from Penda’s team. Validating and deploying implementations of\nAI CDS tools in other clinical environments, care settings, and health systems remains an important area\nfor future work.\n6 Related work\nOffline evaluation of LLMs for health. Advances in LLMs have spurred many works evaluating them\nfor health applications. Prior works have evaluated health performance broadly (Arora et al., 2025; Bedi\net al., 2025) or for specific tasks, including differential diagnosis (McDuff et al., 2025; Nori et al., 2025;\nGoh et al., 2025), clinical summarization (Van Veen et al., 2024; Zaretsky et al., 2024), radiology report\ngeneration (Tanno et al., 2025; Tu et al., 2024), and Q&A (Ayers et al., 2023; Nori et al., 2023; Pfohl et al.,\n2024). Some works have focused on specialized models (Moor et al., 2023; Li et al., 2023; Singhal et al., 2023,\n2025; McDuff et al., 2025; Tu et al., 2025, 2024; Saab et al., 2024; Yang et al., 2024) and others on general\nmodels (Ayers et al., 2023; Nori et al., 2025, 2023; Saab et al., 2025; Arora et al., 2025; Johnson et al., 2023).\nEvaluation in many works relies heavily on narrow automated benchmarks that measure clinical knowledge\n(Nori et al., 2023; Singhal et al., 2023). Some works have evaluated models across many benchmarks, offering\nmore robust characterizations of model performance across tasks (Bedi et al., 2025; Saab et al., 2024; Tu\net al., 2024). Other works have employed human evaluation with physicians or patients, sometimes employing\nrealistic clinical vignettes or electronic medical record data (Goh et al., 2025; Ong et al., 2024; Dash et al.,\n2023; Ayers et al., 2023; Singhal et al., 2025; Pfohl et al., 2024). Some recent works have combined human\nand automated evaluation towards clinician-aligned evaluation at scale (Arora et al., 2025; Fleming et al.,\n2024). All of these works involve “offline” evaluation of LLMs, which do not enable the study of the unique\nchallenges of bringing model advances into clinical practice, including real-world patient diversity, designing\nfor and learning from clinician workflows, and deployment towards successful clinician uptake. Unlike prior\nevaluations of LLMs, the present study examines outcomes of using an LLM-based tool live during patient\n26\ncare at scale, addressing the unique challenges of real-world implementation.\nClinical decision support. AI Consult is an example of a clinical decision support system. Such systems\nhave been used in various forms since the 1970s (Sutton et al., 2020; Middleton et al., 2016; Shortliffe,\n1977; Bright et al., 2012; Musen et al., 2021). These systems support clinicians with knowledge and tools\nat the point of care. CDS systems have traditionally drawn on explicit knowledge bases (Papadopoulos\net al., 2022; Jing et al., 2023), typically represented as rules / decision trees (Silva et al., 2023; Rommers\net al., 2013; Gholamzadeh et al., 2023) or cases (Althoff et al., 1998; Frize and Walker, 2000; Kumar et al.,\n2009), rather than the distributed representations of LLMs. They have often been restricted in scope to\nparticular conditions (Levra et al., 2025; Rajashekar et al., 2024; Oniani et al., 2024; Kaiser et al., 2024),\nspecialties (Ong et al., 2024; Lammert et al., 2024; Miller et al., 2024; Benary et al., 2023), or workflows\n(Slight et al., 2013; Kublanov and Dolganov, 2019; Cheng et al., 2013; Rommers et al., 2013). There are\nseveral works that evaluate LLMs “offline” for decision support tasks (Ong et al., 2024; Gaber et al., 2025;\nLammert et al., 2024; Bhimani et al., 2025; Levra et al., 2025; Rajashekar et al., 2024; Oniani et al., 2024;\nMiller et al., 2024; Kaiser et al., 2024; Benary et al., 2023); these studies measure model performance on\ntasks that could support clinicians, using electronic medical record datasets, clinical vignettes, or fictional\npatients. Similar to other studies evaluating LLMs for health, these do not capture the unique challenges\nof real-world implementation and deployment. To the best of our knowledge, this is the first study of an\nLLM-based CDS used in live patient care. Additionally, unlike other CDS systems that provide assistance for\ntargeted workflows or specialties, AI Consult serves to broadly assist primary care clinicians with all major\naspects of their patient care workflow, including history-taking, investigations, diagnosis, and treatment.\nImplementation science. Implementation science examines methods to promote uptake of evidence-\nbased findings into routine care practice and policy (Eccles and Mittman, 2006; Bauer and Kirchner, 2020;\nGrimshaw et al., 2012; Olswang and Prelock, 2015). This literature often produces structured frameworks\n(Damschroder et al., 2009; Greenhalgh et al., 2017) which identify key factors influencing adoption and\nsustainability of health interventions. Several works have studied factors specific to clinical decision support\n(Kawamoto et al., 2005; Van de Velde et al., 2018; Castillo and Kelemen, 2013; Murphy, 2014; Kilsdonk et al.,\n2017; Sittig et al., 2006; Seidling et al., 2011). A recurring theme is that technology alone is insufficient to\nchange clinician behavior; effective uptake requires attention to usability, workflow fit, leadership buy-in,\niterative training, contextual adaptation, and other factors (Ross et al., 2016; Smith et al., 2021; Greenhalgh\net al., 2017; Ojo et al., 2021). These insights are particularly critical in low-resource contexts, where health\nsystems face workforce shortages, limited infrastructure, and competing priorities (Ojo et al., 2021; Yapa and\nB¨arnighausen, 2018). In works studying implementation of clinical decision support, avoiding alert fatigue\nand surfacing computerized CDS recommendations automatically at relevant points (instead of on demand)\nhave been shown to improve clinician adherence (Kawamoto et al., 2005; Van de Velde et al., 2018; Seidling\net al., 2011). Our implementation design and deployment approach—embedding AI into clinical workflows,\niterative user-centered development, automatically surfacing targeted AI responses via a traffic light system,\nand pairing the tool with change management strategies—takes inspiration from these prior efforts to study\nthe translation of research into clinical impact.\n7 Conclusion\nWe have presented a real-world evaluation of a large language model-based clinical decision support tool\ndeployed in live patient care, with a meaningful reduction in diagnostic and treatment errors. Our findings\nunderscore three critical components: (1) capable models, which are now widely available; (2) clinically-\naligned implementation, which supports the user rather than distracting them; and (3) active deployment,\nincluding building clinician connection, measurement, and incentives. Clinical impact does not emerge solely\nfrom model performance, but from a confluence of technical, human, and organizational factors.\nWith advancements in model capabilities, closing the model-implementation gap has become the most im-\nportant challenge for the health AI ecosystem. This study provides a template for how AI systems can be\nsafely and effectively embedded into clinical workflows. Further progress requires coordinated efforts across\n27\nthe ecosystem, including policymakers developing regulatory frameworks, engineers designing better imple-\nmentations, and healthcare systems driving thoughtful deployments. Ultimately, we hope that systems like\nAI Consult will become the standard of care, supporting clinicians in delivering safer, more consistent, and\nmore accessible care worldwide.\nCode\nWe have released code used for analysis and plotting to foster transparency of the results in this study. Raw\nstudy data cannot be released due to privacy and data protection requirements. Code can be found at:\nhttps://github.com/openai/penda_code.\nAcknowledgements\nAmelia Glaese, Benjamin Kinsella, Dorothy Cheboi, Lilian Weng, Magdalene Kaisa, Nino Jananashvili,\nPhoebe Thacker, Rachel Ndiema, Spruce Campbell, Stephanie Koczela, Wyatt Thompson\nWe would like to thank the following reviewers for generously providing feedback: Ethan Goh, Fred Mutisiya,\nIsaac Kohane, Nigam Shah, and Steven Wanyee. Any errors are our own.\nWe would also like to thank the physician reviewers who graded clinical documentation quality for this study.\n28\nReferences\nK.-D. Althoff, R. Bergmann, S. Wess, M. Manago, E. Auriol, O. I. Larichev, A. Bolotov, Y. I. Zhuravlev,\nand S. I. Gurov. Case-based reasoning for medical decision support tasks: The inreca approach. Artificial\nIntelligence in Medicine, 12(1):25–41, 1998.\nR. K. Arora, J. Wei, R. S. Hicks, P. Bowman, J. Qui˜nonero-Candela, F. Tsimpourlas, M. Sharman, M. Shah,\nA. Vallone, A. Beutel, et al. Healthbench: Evaluating large language models towards improved human\nhealth. arXiv preprint arXiv:2505.08775, 2025.\nJ. W. Ayers, A. Poliak, M. Dredze, E. C. Leas, Z. Zhu, J. B. Kelley, D. J. Faix, A. M. Goodman, C. A.\nLonghurst, M. Hogarth, et al. Comparing physician and artificial intelligence chatbot responses to patient\nquestions posted to a public social media forum. JAMA internal medicine, 183(6):589–596, 2023.\nM. S. Bauer and J. Kirchner. Implementation science: what is it and why should i care? Psychiatry research,\n283:112376, 2020.\nA. L. Beam and I. S. Kohane. Big data and machine learning in health care. JAMA, 319(13):1317–1318,\n2018. doi: 10.1001/jama.2017.18391.\nS. Bedi, H. Cui, M. Fuentes, A. Unell, M. Wornow, J. M. Banda, N. Kotecha, T. Keyes, Y. Mai, M. Oez, et al.\nMedhelm: Holistic evaluation of large language models for medical tasks. arXiv preprint arXiv:2505.23802,\n2025.\nM. Benary, X. D. Wang, M. Schmidt, D. Soll, G. Hilfenhaus, M. Nassir, C. Sigler, M. Kn¨odler, U. Keller,\nD. Beule, U. Keilholz, U. Leser, and D. T. Rieke. Leveraging Large Language Models for Decision Support\nin Personalized Oncology. JAMA Network Open, 6(11):e2343689, Nov. 2023. ISSN 2574-3805. doi:\n10.1001/jamanetworkopen.2023.43689.\nM. Bhimani, A. Miller, J. D. Agnew, M. S. Ausin, M. Raglow-Defranco, H. Mangat, M. Voisard, M. Taylor,\nS. Bierman-Lytle, V. Parikh, J. Ghukasyan, R. Lasko, S. Godil, A. Atreja, and S. Mukherjee. Real-World\nEvaluation of Large Language Models in Healthcare (RWE-LLM): A New Realm of AI Safety &amp;\nValidation, Mar. 2025.\nT. J. Bright, A. Wong, R. Dhurjati, E. Bristow, L. Bastian, R. R. Coeytaux, G. Samsa, V. Hasselblad,\nJ. W. Williams, M. D. Musty, L. Wing, A. S. Kendrick, G. D. Sanders, and D. Lobach. Effect of Clinical\nDecision-Support Systems. Annals of Internal Medicine, 157(1):29–43, July 2012. ISSN 0003-4819. doi:\n10.7326/0003-4819-157-1-201207030-00450.\nR. S. Castillo and A. Kelemen. Considerations for a successful clinical decision support system. CIN:\nComputers, Informatics, Nursing, 31(7):319–326, 2013.\nC.-W. Cheng, N. Chanani, J. Venugopalan, K. Maher, and M. D. Wang. icuarm-an icu clinical decision\nsupport system using association rule mining. IEEE Journal of Translational Engineering in Health and\nMedicine, 1:4400110–4400110, 2013.\nL. J. Damschroder, D. C. Aron, R. E. Keith, S. R. Kirsh, J. A. Alexander, and J. C. Lowery. Fostering\nimplementation of health services research findings into practice: A consolidated framework for advancing\nimplementation science. Implementation Science, 4(1):50, Aug. 2009. ISSN 1748-5908. doi: 10.1186/\n1748-5908-4-50.\nD. Dash, R. Thapa, J. M. Banda, A. Swaminathan, M. Cheatham, M. Kashyap, N. Kotecha, J. H. Chen,\nS. Gombar, L. Downing, et al. Evaluation of gpt-3.5 and gpt-4 for supporting real-world information needs\nin healthcare delivery. arXiv preprint arXiv:2304.13714, 2023.\nM. P. Eccles and B. S. Mittman. Welcome to Implementation Science. Implementation Science, 1(1):1, Feb.\n2006. ISSN 1748-5908. doi: 10.1186/1748-5908-1-1.\n29\nS. L. Fleming, A. Lozano, W. J. Haberkorn, J. A. Jindal, E. Reis, R. Thapa, L. Blankemeier, J. Z. Genkins,\nE. Steinberg, A. Nayak, et al. Medalign: A clinician-generated dataset for instruction following with\nelectronic medical records. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38,\npages 22021–22030, 2024.\nM. Frize and R. Walker. Clinical decision-support systems for intensive care units using case-based reasoning.\nMedical engineering & physics, 22(9):671–677, 2000.\nF. Gaber, M. Shaik, F. Allega, A. J. Bilecz, F. Busch, K. Goon, V. Franke, and A. Akalin. Evaluating large\nlanguage model workflows in clinical decision support for triage and referral and diagnosis. npj Digital\nMedicine, 8(1):263, May 2025. ISSN 2398-6352. doi: 10.1038/s41746-025-01684-1.\nM. Gholamzadeh, H. Abtahi, and R. Safdari. The application of knowledge-based clinical decision sup-\nport systems to enhance adherence to evidence-based medicine in chronic disease. Journal of healthcare\nengineering, 2023(1):8550905, 2023.\nE. Goh, R. J. Gallo, E. Strong, Y. Weng, H. Kerman, J. A. Freed, J. A. Cool, Z. Kanjee, K. P. Lane, A. S.\nParsons, N. Ahuja, E. Horvitz, D. Yang, A. Milstein, A. P. J. Olson, J. Hom, J. H. Chen, and A. Rodman.\nGpt-4 assistance for improvement of physician performance on patient care tasks: A randomized controlled\ntrial. Nature Medicine, 31(4):1233–1238, Apr. 2025. doi: 10.1038/s41591-024-03456-y. Epub 2025 Feb 5.\nPMID: 39910272.\nT. Greenhalgh, J. Wherton, C. Papoutsi, J. Lynch, G. Hughes, C. A’Court, S. Hinder, N. Fahy, R. Procter,\nand S. Shaw. Beyond Adoption: A New Framework for Theorizing and Evaluating Nonadoption, Aban-\ndonment, and Challenges to the Scale-Up, Spread, and Sustainability of Health and Care Technologies.\nJournal of Medical Internet Research, 19(11):e8775, Nov. 2017. doi: 10.2196/jmir.8775.\nJ. M. Grimshaw, M. P. Eccles, J. N. Lavis, S. J. Hill, and J. E. Squires. Knowledge translation of research\nfindings. Implementation Science, 7(1):50, May 2012. ISSN 1748-5908. doi: 10.1186/1748-5908-7-50.\nJ. C. Jakobsen, C. Gluud, J. Wetterslev, and P. Winkel. When and how should multiple imputation be used\nfor handling missing data in randomised clinical trials - a practical guide with flowcharts. BMC Med. Res.\nMethodol., 17(1):162, Dec. 2017.\nX. Jing, H. Min, Y. Gong, P. Biondich, D. Robinson, T. Law, C. Nohr, A. Faxvaag, L. Rennert, N. Hubig,\net al. Ontologies applied in clinical decision support system rules: Systematic review. JMIR medical\ninformatics, 11:e43053, 2023.\nD. Johnson, R. Goodman, J. Patrinely, C. Stone, E. Zimmerman, R. Donald, S. Chang, S. Berkowitz,\nA. Finn, E. Jahangir, E. Scoville, T. Reese, D. Friedman, J. Bastarache, Y. van der Heijden, J. Wright,\nN. Carter, M. Alexander, J. Choe, C. Chastain, J. Zic, S. Horst, I. Turker, R. Agarwal, E. Osmundson,\nK. Idrees, C. Kieman, C. Padmanabhan, C. Bailey, C. Schlegel, L. Chambless, M. Gibson, T. Osterman,\nand L. Wheless. Assessing the Accuracy and Reliability of AI-Generated Medical Responses: An Evalu-\nation of the Chat-GPT Model. Research Square, pages rs.3.rs–2566942, Feb. 2023. ISSN 2693-5015. doi:\n10.21203/rs.3.rs-2566942/v1.\nK. N. Kaiser, A. J. Hughes, A. D. Yang, A. A. Turk, S. Mohanty, A. A. Gonzalez, R. E. Patzer, K. Y.\nBilimoria, and R. J. Ellis. Accuracy and consistency of publicly available Large Language Models as\nclinical decision support tools for the management of colon cancer. Journal of Surgical Oncology, 130(5):\n1104–1110, 2024. ISSN 1096-9098. doi: 10.1002/jso.27821.\nK. Kawamoto, C. A. Houlihan, E. A. Balas, and D. F. Lobach. Improving clinical practice using clinical\ndecision support systems: a systematic review of trials to identify features critical to success. Bmj, 330\n(7494):765, 2005.\nM. Kiener, C. Ichura, B. A. Ndenga, F. M. Mutuku, C. A. Winter, V. Okuta, L. Mwambingu, K. Ogamba,\nK. N. Shaita, C. Ronga, P. Chebii, J. Amugongo, S. Malumbo, O. Godana, Z. Jembe, C. Ng’ang’a,\nM. Mazera, and A. D. LaBeaud. Antibiotic prescribing patterns at outpatient clinics in western and\n30\ncoastal kenya. PLOS Global Public Health, 5(1):e0004109, 2025. doi: 10.1371/journal.pgph.0004109. URL\nhttps://pubmed.ncbi.nlm.nih.gov/39752345.\nE. Kilsdonk, L. Peute, and M. W. Jaspers. Factors influencing implementation success of guideline-based\nclinical decision support systems: a systematic review and gaps analysis. International journal of medical\ninformatics, 98:56–64, 2017.\nKLAS. Successful User’s Guide to High EHR Satisfaction 2023 - Arch Report.\nhttps://klasresearch.com/archcollaborative/report/successful-user-s-guide-to-high-ehr-satisfaction-\n2023/475, 2003.\nR. R. Korom and G. Njue. Clinical decision support systems in low resource settings. BMJ, 371:m3962, Oct.\n2020.\nC. Kr¨uger, M. Heinzel-Gutenbrunner, and M. Ali. Adherence to the integrated management of childhood\nillness guidelines in namibia, kenya, tanzania and uganda: evidence from the national service provision\nassessment surveys. BMC Health Services Research, 17(1):822, 2017. doi: 10.1186/s12913-017-2781-3.\nURL https://pubmed.ncbi.nlm.nih.gov/29237494.\nV. Kublanov and A. Dolganov. Development of a decision support system for neuro-electrostimulation:\nDiagnosing disorders of the cardiovascular system and evaluation of the treatment efficiency. Applied Soft\nComputing, 77:329–343, 2019.\nK. A. Kumar, Y. Singh, and S. Sanyal. Hybrid approach using case-based reasoning and rule-based reasoning\nfor domain independent clinical decision support in icu. Expert Systems with Applications, 36(1):65–71,\n2009.\nJ. Lammert, T. Dreyer, S. Mathes, L. Kuligin, K. J. Borm, U. A. Schatz, M. Kiechle, A. M. L¨orsch, J. Jung,\nS. Lange, N. Pfarr, A. Durner, K. Schwamborn, C. Winter, D. Ferber, J. N. Kather, C. Mogler, A. L. Illert,\nand M. Tschochohei. Expert-Guided Large Language Models for Clinical Decision Support in Precision\nOncology. JCO precision oncology, 8:e2400478, Oct. 2024. ISSN 2473-4284. doi: 10.1200/PO-24-00478.\nA. G. Levra, M. Gatti, R. Mene, D. Shiffer, G. Costantino, M. Solbiati, R. Furlan, and F. Dipaola. A\nlarge language model-based clinical decision support system for syncope recognition in the emergency\ndepartment: A framework for clinical workflow integration. European Journal of Internal Medicine, 131:\n113–120, Jan. 2025. ISSN 0953-6205. doi: 10.1016/j.ejim.2024.09.017.\nC. Li, C. Wong, S. Zhang, N. Usuyama, H. Liu, J. Yang, T. Naumann, H. Poon, and J. Gao. Llava-med:\nTraining a large language-and-vision assistant for biomedicine in one day. Advances in Neural Information\nProcessing Systems, 36:28541–28564, 2023.\nC. Marete, C. Nabakwe, E. M. Njuguna, F. and R. Mwangi, H.˙Clinicians’ adherence to national pneumonia\nmanagement guidelines at kitale county hospital, kenya. East African Medical Journal, 97(11):3190–3199,\n2020. URL https://www.ajol.info/index.php/eamj/article/view/205283.\nD. McDuff, M. Schaekermann, T. Tu, and et al. Towards accurate differential diagnosis with large language\nmodels. Nature, 626:102–118, 2025. doi: 10.1038/s41586-025-08869-4.\nB. Middleton, D. F. Sittig, and A. Wright. Clinical Decision Support: A 25 Year Retrospective and a 25\nYear Vision. Yearbook of Medical Informatics, (Suppl 1):S103–S116, May 2016. ISSN 0943-4747. doi:\n10.15265/IYS-2016-s034.\nL. Miller, P. Kamel, J. Patel, J. Agrawal, M. Zhan, N. Bumbarger, and K. Wang. A Comparative Evalu-\nation of Large Language Model Utility in Neuroimaging Clinical Decision Support. Journal of Imaging\nInformatics in Medicine, Nov. 2024. ISSN 2948-2933. doi: 10.1007/s10278-024-01161-3.\nM. Moor, L. von Rueden, S. Adler, W. Ping, H. Valentin, et al. Med-flamingo: A multimodal medical\nfew-shot learner. In Proceedings of the 3rd Machine Learning for Health Symposium, pages 353–367.\nPMLR, 2023.\n31\nE. V. Murphy. Clinical decision support: effectiveness in improving quality processes and clinical outcomes\nand factors that may influence success. The Yale journal of biology and medicine, 87(2):187, 2014.\nM. A. Musen, B. Middleton, and R. A. Greenes. Clinical Decision-Support Systems. In E. H. Shortliffe and\nJ. J. Cimino, editors, Biomedical Informatics: Computer Applications in Health Care and Biomedicine,\npages 795–840. Springer International Publishing, Cham, 2021. ISBN 978-3-030-58721-5. doi: 10.1007/\n978-3-030-58721-5 24.\nH. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz. Capabilities of gpt-4 on medical challenge\nproblems. arXiv preprint arXiv:2303.13375, 2023. doi: 10.48550/ARXIV.2303.13375.\nH. Nori, M. Daswani, C. Kelly, S. Lundberg, M. T. Ribeiro, M. Wilson, X. Liu, V. Sounderajah, J. Carlson,\nM. P. Lungren, et al. Sequential diagnosis with language models. arXiv preprint arXiv:2506.22405, 2025.\nG. Ogrinc, L. Davies, D. Goodman, P. Batalden, F. Davidoff, and D. Stevens. SQUIRE 2.0 (standards\nfor QUality improvement reporting excellence): revised publication guidelines from a detailed consensus\nprocess. BMJ Qual. Saf., 25(12):986–992, Dec. 2016.\nT. Ojo, L. Kabasele, B. Boyd, S. Enechukwu, N. Ryan, J. Gyamfi, and E. Peprah. The Role of Im-\nplementation Science in Advancing Resource Generation for Health Interventions in Low- and Middle-\nIncome Countries. Health Services Insights, 14:1178632921999652, Mar. 2021. ISSN 1178-6329. doi:\n10.1177/1178632921999652.\nL. B. Olswang and P. A. Prelock. Bridging the Gap Between Research and Practice: Implementation\nScience. Journal of Speech, Language, and Hearing Research, 58(6):S1818–S1826, Dec. 2015. doi: 10.\n1044/2015 JSLHR-L-14-0305.\nJ. C. L. Ong, L. Jin, K. Elangovan, G. Y. S. Lim, D. Y. Z. Lim, G. G. R. Sng, Y. Ke, J. Y. M. Tung,\nR. J. Zhong, C. M. Y. Koh, et al. Development and testing of a novel large language model-based clinical\ndecision support systems for medication safety in 12 clinical specialties. arXiv preprint arXiv:2402.01741,\n2024.\nD. Oniani, X. Wu, S. Visweswaran, S. Kapoor, S. Kooragayalu, K. Polanska, and Y. Wang. Enhancing Large\nLanguage Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines, Jan. 2024.\nP. Papadopoulos, M. Soflano, Y. Chaudy, W. Adejo, and T. M. Connolly. A systematic review of technolo-\ngies and standards used in the development of rule-based clinical decision support systems. Health and\nTechnology, 12(4):713–727, 2022.\nS. R. Pfohl, H. Cole-Lewis, R. Sayres, D. Neal, M. Asiedu, A. Dieng, N. Tomasev, Q. M. Rashid, S. Azizi,\nN. Rostamzadeh, et al. A toolbox for surfacing health equity harms and biases in large language models.\nNature Medicine, 30(12):3590–3600, 2024.\nN. C. Rajashekar, Y. E. Shin, Y. Pu, S. Chung, K. You, M. Giuffre, C. E. Chan, T. Saarinen, A. Hsiao,\nJ. Sekhon, A. H. Wong, L. V. Evans, R. F. Kizilcec, L. Laine, T. Mccall, and D. Shung. Human-Algorithmic\nInteraction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support\nSystem. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI ’24,\npages 1–20, New York, NY, USA, May 2024. Association for Computing Machinery. ISBN 9798400703300.\ndoi: 10.1145/3613904.3642024.\nA. Rajkomar, J. Dean, and I. Kohane. Machine learning in medicine. New England Journal of Medicine,\n380(14):1347–1358, 2019.\nM. K. Rommers, J. Zwaveling, H.-J. Guchelaar, and I. M. Teepe-Twiss. Evaluation of rule effectiveness\nand positive predictive value of clinical rules in a dutch clinical decision support system in daily hospital\npharmacy practice. Artificial intelligence in medicine, 59(1):15–21, 2013.\nJ. Ross, F. Stevenson, R. Lau, and E. Murray. Factors that influence the implementation of e-health: A\nsystematic review of systematic reviews (an update). Implementation Science, 11(1):146, Oct. 2016. ISSN\n1748-5908. doi: 10.1186/s13012-016-0510-7.\n32\nR. K. Ross, A. Breskin, and D. Westreich. When is a complete-case approach to missing data valid? the\nimportance of effect-measure modification. Am. J. Epidemiol., 189(12):1583–1589, Dec. 2020.\nK. Saab, T. Tu, W.-H. Weng, R. Tanno, D. Stutz, E. Wulczyn, F. Zhang, T. Strother, C. Park, E. Vedadi,\net al. Capabilities of gemini models in medicine. arXiv preprint arXiv:2404.18416, 2024.\nK. Saab, J. Freyberg, C. Park, T. Strother, Y. Cheng, W.-H. Weng, D. G. T. Barrett, D. Stutz, N. Tomasev,\nA. Palepu, V. Li´evin, Y. Sharma, R. Ruparel, A. Ahmed, E. Vedadi, K. Kanada, C. Hughes, Y. Liu,\nG. Brown, Y. Gao, S. Li, S. S. Mahdavi, J. Manyika, K. Chou, Y. Matias, A. Hassidim, D. R. Webster,\nP. Kohli, S. M. A. Eslami, J. Barral, A. Rodman, V. Natarajan, M. Schaekermann, T. Tu, A. Karthike-\nsalingam, and R. Tanno. Advancing Conversational Diagnostic AI with Multimodal Reasoning, May\n2025.\nH. M. Seidling, S. Phansalkar, D. L. Seger, M. D. Paterno, S. Shaykevich, W. E. Haefeli, and D. W. Bates.\nFactors influencing alert acceptance: a novel approach for predicting the success of clinical decision support.\nJournal of the American Medical Informatics Association, 18(4):479–484, 2011.\nE. H. Shortliffe. Mycin: A Knowledge-Based Computer Program Applied to Infectious Diseases. Proceedings\nof the Annual Symposium on Computer Application in Medical Care, pages 66–69, Oct. 1977. ISSN\n0195-4210.\nB. Silva, F. Hak, T. Guimaraes, M. Manuel, and M. F. Santos. Rule-based system for effective clinical\ndecision support. Procedia Computer Science, 220:880–885, 2023.\nK. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales, A. Tanwani, H. Cole-Lewis,\nS. Pfohl, et al. Large language models encode clinical knowledge. Nature, 620(7972):172–180, 2023.\nK. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Wulczyn, M. Amin, L. Hou, K. Clark, S. R. Pfohl, H. Cole-\nLewis, et al. Toward expert-level medical question answering with large language models. Nature Medicine,\npages 1–8, 2025.\nD. F. Sittig, M. A. Krall, R. H. Dykstra, A. Russell, and H. L. Chin. A survey of factors affecting clinician\nacceptance of clinical decision support. BMC medical informatics and decision making, 6(1):6, 2006.\nS. P. Slight, D. L. Seger, K. C. Nanji, I. Cho, N. Maniam, P. C. Dykes, and D. W. Bates. Are we heeding\nthe warning signs? examining providers’ overrides of computerized drug-drug interaction alerts in primary\ncare. PloS one, 8(12):e85071, 2013.\nM. Smith, A. Sattler, G. Hong, and S. Lin. From Code to Bedside: Implementing Artificial Intelligence\nUsing Quality Improvement Methods. Journal of General Internal Medicine, 36(4):1061–1066, Apr. 2021.\nISSN 0884-8734, 1525-1497. doi: 10.1007/s11606-020-06394-w.\nR. T. Sutton, D. Pincock, D. C. Baumgart, D. C. Sadowski, R. N. Fedorak, and K. I. Kroeker. An overview\nof clinical decision support systems: Benefits, risks, and strategies for success. npj Digital Medicine, 3(1):\n17, Feb. 2020. ISSN 2398-6352. doi: 10.1038/s41746-020-0221-y.\nR. Tanno, D. G. Barrett, A. Sellergren, S. Ghaisas, S. Dathathri, A. See, J. Welbl, C. Lau, T. Tu, S. Azizi,\net al. Collaboration between clinicians and vision–language models in radiology report generation. Nature\nMedicine, 31(2):599–608, 2025.\nE. J. Topol. High-performance medicine: The convergence of human and artificial intelligence. Nature\nMedicine, 25(1):44–56, 2019. doi: 10.1038/s41591-018-0300-7.\nT. Tu, S. Azizi, D. Driess, M. Schaekermann, M. Amin, P.-C. Chang, A. Carroll, C. Lau, R. Tanno, I. Ktena,\net al. Towards generalist biomedical ai. Nejm Ai, 1(3):AIoa2300138, 2024.\nT. Tu, M. Schaekermann, A. Palepu, K. Saab, J. Freyberg, R. Tanno, A. Wang, B. Li, M. Amin, Y. Cheng,\net al. Towards conversational diagnostic artificial intelligence. Nature, pages 1–9, 2025.\n33\nS. Van de Velde, A. Heselmans, N. Delvaux, L. Brandt, L. Marco-Ruiz, D. Spitaels, H. Cloetens, T. Kortteisto,\nP. Roshanov, I. Kunnamo, et al. A systematic review of trials evaluating success factors of interventions\nwith computerised clinical decision support. Implementation science, 13(1):114, 2018.\nD. Van Veen, C. Van Uden, L. Blankemeier, J.-B. Delbrouck, A. Aali, C. Bluethgen, A. Pareek, M. Polacin,\nE. P. Reis, A. Seehofnerov´a, N. Rohatgi, P. Hosamani, W. Collins, N. Ahuja, C. P. Langlotz, J. Hom,\nS. Gatidis, J. Pauly, and A. S. Chaudhari. Adapted large language models can outperform medical\nexperts in clinical text summarization. Nature Medicine, 30(4):1134–1142, Apr. 2024. ISSN 1546-170X.\ndoi: 10.1038/s41591-024-02855-5.\nWHO. Patient safety. https://www.who.int/news-room/fact-sheets/detail/patient-safety, March\n2023.\nL. Yang, S. Xu, A. Sellergren, T. Kohlberger, Y. Zhou, I. Ktena, A. Kiraly, F. Ahmed, F. Hormozdiari,\nT. Jaroensri, et al. Advancing multimodal medical capabilities of gemini. arXiv preprint arXiv:2405.03162,\n2024.\nH. M. Yapa and T. B¨arnighausen. Implementation science in resource-poor countries and communities.\nImplementation Science, 13(1):154, Dec. 2018. ISSN 1748-5908. doi: 10.1186/s13012-018-0847-1.\nJ. Zaretsky, J. M. Kim, S. Baskharoun, Y. Zhao, J. Austrian, Y. Aphinyanaphongs, R. Gupta, S. B. Blecker,\nand J. Feldman. Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-\nFriendly Language and Format. JAMA Network Open, 7(3):e240357, Mar. 2024. ISSN 2574-3805. doi:\n10.1001/jamanetworkopen.2024.0357.\nG. Zou. A modified poisson regression approach to prospective studies with binary data. Am. J. Epidemiol.,\n159(7):702–706, Apr. 2004.\nG. Y. Zou and A. Donner. Extension of the modified poisson regression model to prospective studies with\ncorrelated binary data. Stat. Methods Med. Res., 22(6):661–670, Dec. 2013.\n34\nA Images of AI Consult in use\nFigure 9: Image of AI Consult yellow notification.\nFigure 10: Image of AI Consult yellow popup, after clicking on the notification bell.\n35\nFigure 11: Image of AI Consult red popup.\nFigure 12: Image of AI Consult green notification.\n36\nFigure 13: Image of AI Consult green popup, after clicking on the notification bell.\n37\nB Full examples of AI Consult\nInitial documentation AI Consult response Final documentation\nVitals\nAge 2 y 6 m, Wt 12.5 kg, HR 127 bpm,\nMUAC green, Temp 36.3 ◦C.\nClinical note\nmother report th child has been\nvomiting, 4 episode, non projectile ,\nvomitous contained lasgt eaten meal , no\nhistory of fever, no history of cough ,no\nhistory of diarrhea, no history of refusal\nto feed , no history of crying while\npassing urine , no history of travelling to\nmalaria endemic zone .\non examination: in fair general\ncondition not pale ,no jaundice ,no\ncyanosis . skin pinch return is immediate\n, capillary refill return is less than 2 sec,\nno dryness of mucus membrane\nPer abdomen-normal fullness, no\npalpable mass, no tenderness\nRespiratory-chest clear, no respiratory\ndistress, no crackles, no rhonchi\nEar, nose, and throat-inflamed, non\nexudative ,non erythematous throat , no\nadenoids inflammation , no inflammation\nin the ear\nCardiovascular- s1s2 heard no murmur\nNeurologic-AVPU@A , neck soft , no sign\nof meningeal irritation\nInvestigations\nFull Hemogram:\nWBC 12.38\nHGB 9.90\nHCT 30.70\nPlt 248\nRBC 5.26\nMCV 58.30\nMCH 18.8\nMCHC 32.2.\nStrep-A Ag negative.\nDiagnosis\nTonsillitis, acute bacterial.\nCLINICIAN DOES NOT INCLUDE\nA DIAGNOSIS RELATED TO THE\nABNORMAL FINDING OF\nMICROCYTIC ANEMIA\nRED FLAG\nResponses: The clinical documentation\nshows the presence of microcytic anemia\nwith a hemoglobin level of 9.90 g/dL and\nan MCV of 58.30 fL, indicative of anemia\nthat is not addressed in the diagnosis.\nThe presence of microcytic anemia\nshould be evaluated alongside the current\nsymptom of vomiting.\nRecommendations: Reevaluate the\ndiagnosis considering the significant\nfinding of microcytic anemia, which is\nnot addressed. Investigate underlying\ncauses of anemia, such as iron deficiency\nor chronic disease. Consider additional\ntesting for iron studies or further dietary\ninvestigation. Ensure anemia is included\nin the management plan to address this\ncritical finding.\nVitals\nAge 2 y 6 m, Wt 12.5 kg, HR 127 bpm,\nMUAC green, Temp 36.3 ◦C.\nClinical note\nmother report th child has been\nvomiting, 4 episode, non projectile ,\nvomitous contained lasgt eaten meal , no\nhistory of fever, no history of cough ,no\nhistory of diarrhea, no history of refusal\nto feed , no history of crying while\npassing urine , no history of travelling to\nmalaria endemic zone .\non examination: in fair general\ncondition not pale ,no jaundice ,no\ncyanosis . skin pinch return is immediate\n, capillary refill return is less than 2 sec,\nno dryness of mucus membrane\nPer abdomen-normal fullness, no\npalpable mass, no tenderness\nRespiratory-chest clear, no respiratory\ndistress, no crackles, no rhonchi\nEar, nose, and throat-inflamed, non\nexudative ,non erythematous throat , no\nadenoids inflammation , no inflammation\nin the ear\nCardiovascular- s1s2 heard no murmur\nNeurologic-AVPU@A , neck soft , no sign\nof meningeal irritation\nInvestigations\nFull Hemogram:\nWBC 12.38\nHGB 9.90\nHCT 30.70\nPlt 248\nRBC 5.26\nMCV 58.30\nMCH 18.8\nMCHC 32.2.\nStrep-A Ag negative.\nDiagnoses\nTonsillitis, acute bacterial; Emesis,\nunspecified; Iron deficiency anemia\nTable 9: Example of AI Consult in action: AI Consult flags an important missing diagnosis of iron deficiency\nanemia, leading the clinician to add this diagnosis so it can be appropriately treated. Highlighted portions\nshow the initial text that triggered the tool, important messages in the AI Consult response and changes\nthe clinician made after reviewing the flag.\n38\nInitial documentation AI Consult response Final documentation\nVitals\nAge 1 y 5 m, Wt 11.5 kg, HR 159 bpm,\nMUAC green, Temp 37.1 ◦C.\nClinical note\nCHild was treated yesterday with\nvomiting now subsided.\nMother reports developed diarrhea today\nmorning reports several episodes since\nmorning\nStool is waterly mucoid stained but not\nbloody though smelly\nnormal urine outpu. No associated fevers\nNo history of travel to malaria zone\nBaby breastfeeding well but has reduced\nappetite today\non examination: no dehydration nornal\nskin turgor normal cap refill no pallor\nPer abdomen: normal abdominal\nfullness, no distension no tenderness\nInvestigations\nStool Microscopy:\n* Consistency: Liquid/Loose\n* Blood: Absent\n* Mucous: Present\n* RBC’s (Microscopy): None\n* Parasites: No Ova/Cyst\n* Crystals – Amount: None\n* Crystals – Type: None\nImpression and Plan\nGastroenteritis\nRX oral hydration with ORS\nContine with own zinc tablets 20\nmilligram DO for 10 days\nMetronidazole susp 100ml dosage: 5\nml, 3 Times a day, After food for 5\nDays, Quantity 1\nOral Rehydration Salt Sachets dosage: 1\nsatchet, 1 Times a day, As directed for 3\nDays, Quantity 3\nRED FLAG\nResponses: The treatment involves the\nuse of metronidazole, which is not\nindicated in uncomplicated\ngastroenteritis with no identified\nprotozoal infection. This could lead to\nunnecessary exposure to antibiotics.\nRecommendations: Discontinue\nmetronidazole as there is no evidence of\nprotozoan infection.\nFocus on continued oral rehydration with\nORS and administer zinc supplements as\nplanned. Monitor the child’s hydration\nand general condition, and educate the\ncaregiver on signs of dehydration\nrequiring medical attention.\nVitals\nAge 1 y 5 m, Wt 11.5 kg, HR 159 bpm,\nMUAC green, Temp 37.1 ◦C.\nClinical note\nCHild was treated yesterday with\nvomiting now subsided.\nMother reports developed diarrhea today\nmorning reports several episodes since\nmorning\nStool is waterly mucoid stained but not\nbloody though smelly\nnormal urine outpu. No associated fevers\nNo history of travel to malaria zone\nBaby breastfeeding well but has reduced\nappetite today\non examination: no dehydration nornal\nskin turgor normal cap refill no pallor\nPer abdomen: normal abdominal\nfullness, no distension no tenderness\nInvestigations\nStool Microscopy:\n* Consistency: Liquid/Loose\n* Blood: Absent\n* Mucous: Present\n* RBC’s (Microscopy): None\n* Parasites: No Ova/Cyst\n* Crystals – Amount: None\n* Crystals – Type: None\nImpression and Plan\nGastroenteritis\nRX oral hydration with ORS Contine\nwith own zinc tablets 20 milligram OD\nfor 10 days\nCLINICIAN REMOVED THE\nMETRONIDAZOLE\nPRESCRIPTION\nContinue with ORS 115 mls after every\nloose stool. Mother advised continue\nbreastfeeding the baby\nTable 10: Example of AI Consult in action: AI Consult suggestions help the clinician identify and remove\nan unnecessary antibiotic prescription.\n39\nInitial documentation AI Consult response Final documentation\nVitals\nAge 26 y 10 m, Wt 76.5 kg, HR 77 bpm,\nRR 18 bpm, SpO2 98%, Temp 36.3 ◦C.\nClinical note\nreport history of dry cough ,which is on\nand off occurs mostly in the evening this\nis associated with dizziness for 2/7 now,\nthis was preceded with headache which\nresolved after taking pain killer, 3/7 ago .\nabove is accompanied with fatigue , he\nassociates this with overworking since hes\nbeen working from 4am - midnight for\nthe past 2/52 without rest . Has history\nof nasal blockage , no history of runny\nnose, no history of fever. no history of\ndib . no history of travelling to malaria\nendemic zone .\non examination: in fair general\ncondition not pale ,no jaundice ,no\ncyanosis ,no deho\nEar, nose and throat-no inflamed tonsils,\nno exudation , no inflamed sinus, no ear\ninfection\nRespiratory-chest clear , no crackles, no\nrhonchi\nNeurologic-GCS15/15 , No sign of\nmeningeal irritation , no sign of\nneurologic deficit\nCardiovascular-s1s2heard no murmur\nDiagnosis\nUpper respiratory tract infection (URTI).\nMedications\nBetamethasone/Dexchlorpheni-\nramine maleate tabs dosage: 1\ntablet, 2 Times a day, After food for\n5 Days, dosage: 1 application\nRED FLAG\nResponses: The treatment plan includes\nBetamethasone/Dexchlorpheniramine,\nwhich is not recommended for URTI due\nto potential side effects and lack of\nefficacy. Additionally, the use of\nsedating antihistamines like\nDexchlorpheniramine is not advisable for\ntreating URTI symptoms. .\nRecommendations: Discontinue\nBetamethasone/Dexchlorpheniramine.\nConsider symptomatic treatment with\nnon-sedating antihistamines if necessary,\nand advise on rest, hydration, and steam\ninhalation as supportive care.\nVitals\nAge 26 y 10 m, Wt 76.5 kg, HR 77 bpm,\nRR 18 bpm, SpO2 98%, Temp 36.3 ◦C.\nClinical note\nreport history of dry cough ,which is on\nand off occurs mostly in the evening this\nis associated with dizziness for 2/7 now,\nthis was preceded with headache which\nresolved after taking pain killer, 3/7 ago .\nabove is accompanied with fatigue , he\nassociates this with overworking since hes\nbeen working from 4am - midnight for\nthe past 2/52 without rest . Has history\nof nasal blockage , no history of runny\nnose, no history of fever. no history of\ndib . no history of travelling to malaria\nendemic zone .\non examination: in fair general\ncondition not pale ,no jaundice ,no\ncyanosis ,no deho\nEar, nose and throat-no inflamed tonsils,\nno exudation , no inflamed sinus, no ear\ninfection\nRespiratory-chest clear , no crackles, no\nrhonchi\nNeurologic-GCS15/15 , No sign of\nmeningeal irritation , no sign of\nneurologic deficit\nCardiovascular-s1s2heard no murmur\nDiagnosis\nUpper respiratory tract infection (URTI).\nMedications\nCLINICIAN REMOVED THE\nBETAMETHASONE/DEXCHLOR-\nPHENIRAMINE PRESCRIPTION\nCetrizine tabs 10mg: 1 application, 1\nTimes a day, After food for 5 Days\nXylometazoline Adult Drops 10ml: 2\ndrop, 3 Times a day, Morning,\nAfternoon, Night for 3 Days\nTable 11: Example of AI Consult in action: AI Consult identified potentially harmful use of a combination\nsteroid / sedating antihistamine, leading the clinician to replace this with more appropriate, non-sedating\nmedications.\n40\nInitial documentation AI Consult response Final documentation\nVitals\nAge 0 y 10 m, Wt 8.9 kg, HR 118 bpm,\nMUAC green, RR 26 bpm, Temp 36.6 ◦C.\nClinical note\nchild has been accompanied with 2 day\nhistory of mouth sores\nmother also reports child with 3 day\nhistory of loose stool , started yesterday\ngradually mother reports stool is soft,\nmucoid , non blood stained\nCLINICIAN DOES NOT INCLUDE\nTHE FREQUENCY OF LOOSE\nSTOOLS\nno vomiting\nalso reports to have noticed signs of\nteething\npre med: nystatin used for 2 days now\nno known food or drug allergy\non examination: stable ,not pale, no\njaundice, not dehydrated able to drink\nadequately, no sunken eyes\ncapillary refill: immediately\noral exam has oral thrush in the mouth\nother systems essentially normal\nYELLOW FLAG\nResponses: Documentation is generally\nsufficient but lacks details on the\nfrequency and quantity of loose stools,\nwhich are important for assessing\ndehydration risk in a child with\ngastroenteritis.\nRecommendations: Document the\nfrequency and quantity of loose stools to\nbetter assess the risk of dehydration and\nguide management.\nVitals\nAge 0 y 10 m, Wt 8.9 kg, HR 118 bpm,\nMUAC green, RR 26 bpm, Temp 36.6 ◦C.\nClinical note\nchild has been accompanied with 2 day\nhistory of mouth sores\nmother also reports child with 3 day\nhistory of loose stool , started yesterday\ngradually mother reports stool is soft,\nmucoid , non blood stained\nreports child with loose stool after 4\nto 6hrs , less amount , not watery.\nno vomiting\nalso reports to have noticed signs of\nteething\npre med: nystatin used for 2 days now\nno known food or drug allergy\non examination: stable ,not pale, no\njaundice, not dehydrated able to drink\nadequately, no sunken eyes\ncapillary refill: immediately\noral exam has oral thrush in the mouth\nother systems essentially normal\nTable 12: Example of AI Consult in action: AI Consult suggestions help the clinician seek important missing\nhistory which will help them know what treatment to give.\nInitial documentation AI Consult response Final documentation\nVitals\nAge 30 y 2 m, Wt 69.5 kg, HR 102 bpm,\nBP 105/72, Temp 36.3 ◦C.\nClinical note\npresented with history of per vaginal\nitchiness on and off for the past 3 days\naccompanied by whitish per vaginal\ndischarge non smelly non bloody\nlater back pains,no per vaginal\nspotting,nopainful urination,no urine\nfrequency,no lower abdominal pains\non examination: stable,afebrile,not\npale,not dehydrated,not jaundiced\nper abdomen-soft none tender,no\nguarding,no rebound tenderness\nrespiratory-clear chest,no creps,no\nrhonchi\ncardiovascular-s1 and s2 heard,no\nmurmur\ncentral nervous system-gcs 15/15,no neck\nstiffness,soft neck\nother systems-essentially normal\nInvestigations\nUrine Analysis\nCLINICIAN DOES NOT ORDER A\nTEST TO INVESTIGATE THE\nVAGINAL DISCHARGE\nYELLOW FLAG\nResponses: The urine analysis is a\ncommon preliminary test that can help\nrule out urinary tract causes of\nsymptoms. However, given the primary\nsymptoms are related to vaginal\ndischarge and itchiness,a vaginal swab for\nmicroscopy, culture, and sensitivity\nwould be more directly relevant to\nidentify possible causes like yeast\ninfection or bacterial vaginosis.\nRecommendations: Consider ordering\na vaginal swab for microscopy, culture,\nand sensitivity to better identify the\ncause of the vaginal discharge and\nitchiness.\nVitals\nAge 30 y 2 m, Wt 69.5 kg, HR 102 bpm,\nBP 105/72, Temp 36.3 ◦C.\nClinical note\npresented with history of per vaginal\nitchiness on and off for the past 3 days\naccompanied by whitish per vaginal\ndischarge non smelly non bloody\nlater back pains,no per vaginal\nspotting,nopainful urination,no urine\nfrequency,no lower abdominal pains\non examination: stable,afebrile,not\npale,not dehydrated,not jaundiced\nper abdomen-soft none tender,no\nguarding,no rebound tenderness\nrespiratory-clear chest,no creps,no\nrhonchi\ncardiovascular-s1 and s2 heard,no\nmurmur\ncentral nervous system-gcs 15/15,no neck\nstiffness,soft neck\nother systems-essentially normal\nInvestigations\nUrine Analysis\nHigh Vaginal Swab (HVS Gram\nStain)\nTable 13: Example of AI Consult in action: AI Consult flags a missing test to evaluate the cause of vaginal\nitchiness and discharge, resulting in the clinician ordering this test.\n41\nInitial documentation AI Consult response Final documentation\nVitals\nAge 16 y 4 m, Wt 45 kg, HR 112 bpm,\nBP 98/61, RR 17 bpm, Temp 38.3 ◦C.\nClinical note\nhigh fevers, exposed\nparafast 1g Per oral administered\nBrought in by the mother with 1 day\nhistory of painful throat, chills, fever and\nleft sided headache.\nno cough or runny nose.\nno gastrointestinal complainr.\nno bladder disturbances. no travel\nhistory\non examination: fair condition, febrile,\nno pallor, no icterus, no dehydration\nRespiratory; normal breath sounds\nCardiovascular: normal blood pressure\nand pulse\nEar, nose and throat; tonsillar exudate\nOther systems; unremarkable\nInvestigations\nStreptococcus A Antigen Test:\nPositive\nDiagnosis : Group A Strep\npharyngitis score 3-4:\nGREEN FLAG\nResponses: The diagnosis of Group A\nStrep pharyngitis aligns with the clinical\npresentation of throat pain, fever, and\npositive Streptococcus A antigen test.\nRecommendations: Proceed with\nappropriate antibiotic therapy for Group\nA Strep pharyngitis, such as penicillin or\namoxicillin, and provide supportive care\nfor symptoms.\nVitals\nAge 16 y 4 m, Wt 45 kg, HR 112 bpm,\nBP 98/61, RR 17 bpm, Temp 38.3 ◦C.\nClinical note\nhigh fevers, exposed\nparafast 1g Per oral administered\nBrought in by the mother with 1 day\nhistory of painful throat, chills, fever and\nleft sided headache.\nno cough or runny nose.\nno gastrointestinal complainr.\nno bladder disturbances. no travel\nhistory\non examination: fair condition, febrile,\nno pallor, no icterus, no dehydration\nRespiratory; normal breath sounds\nCardiovascular: normal blood pressure\nand pulse\nEar, nose and throat; tonsillar exudate\nOther systems; unremarkable\nInvestigations\nStreptococcus A Antigen Test:\nPositive\nDiagnosis : Group A Strep\npharyngitis score 3-4:\nTable 14: Example of AI Consult in action: AI Consult suggestions support the accurately assigned diagnosis.\n42\nC Physician Rater: Likert Definitions and Failure Modes\nLikert Score History & Examination: Likert Score Description\n5 Thorough: key components of the HPI and/or medical history elements are documented;\nrelevant systems on physical exam are well documented; chief complaint and relevant vitals\nare present\n4 Reasonably thorough: some relevant HPI and/or medical history elements are doc-\numented; some of the relevant system specific findings are documented on exam; chief\ncomplaint and most relevant vitals are present\n3 Limited: history has limited symptom description or pertinent details (e.g., missing 2 or\nmore relevant characterizations of the chief complaint, such as duration, onset, quality,\nseverity, etc.); physical exam is limited; chief complaint or some relevant vitals are present\n2 Deficient: history misses the most important key elements; physical exam is very incom-\nplete, excludes important details of relevant systems or misses one of the most important\nexam findings; chief complaint and/or important vitals missing\n1 Very poor: history is extremely limited with no meaningful characterization of presenting\nsymptoms; physical exam is missing entirely or nearly so; critical vitals missing\nTable 15: Likert score descriptions used by physician raters to evaluate history and examination.\nLikert Score Investigations: Likert Score Description\n5 Appropriate & Targeted: All investigations are clearly indicated by the clinical context;\npoint of care tests are utilized appropriately and there are no unjustified tests ordered; or\nno investigations are indicated and none are ordered\n4 Minor overordering: Investigations are mostly appropriate with only minimal overtest-\ning, (e.g., full hemogram for URTI symptoms with no major systemic symptoms or exam\nfindings suggesting bacterial infection but one or two general symptoms like subjective\nfever or headache are present)\n3 Overly broad: Investigations ordered are unjustified, (e.g., full hemogram for clearly\nsimple URTI with unconcerning vitals and exam findings)\n2 Deficient: Potentially helpful investigations are missing, (e.g., no rapid strep test for\npharyngitis/tonsillitis)\n1 Very poor: Critical omissions - clearly important investigations were not ordered, risking\nmisdiagnosis or harm, (e.g., urinalysis not ordered for a young child with unexplained fever\nor no malaria test for a patient with fever and travel to a malaria endemic region)\nTable 16: Likert score descriptions used by physician raters to evaluate investigations.\n43\nLikert Score Diagnosis: Likert Score Description\n5 Excellent: primary diagnosis fully aligns with the clinical picture and is the most likely\ndiagnosis; no additional diagnoses are missing; any listed additional diagnoses are appro-\npriate\n4 Good: primary diagnosis generally aligns and is among the top few likely diagnoses;\nadditional diagnoses are present but not clearly relevant\n3 Adequate: primary diagnosis is plausible but not the most likely, or one or more im-\nportant additional diagnoses are missing (e.g., no diagnosis of “elevated blood pressure\nreading” or “hypertension” when BP is significantly elevated)\n2 Deficient: primary diagnosis is not well supported by the clinical picture or low on the\nlist of likely causes; Primary diagnosis is a catch-all diagnosis when a clearer primary\ndiagnosis is possible (e.g., “bacterial infection unspecified” instead of “urinary tract infec-\ntion”); critical additional diagnoses are missing (e.g., no “malnutrition” or “underweight”\ndiagnosis on a child with MUC yellow or red)\n1 Very poor: primary diagnosis is missing or clinically inappropriate, contradicts or is\nunsupported by documented findings\nTable 17: Likert score descriptions used by physician raters to evaluate diagnoses.\nLikert Score Treatment: Likert Score Description\n5 Appropriate and complete: treatments are appropriate and complete, including the\ncorrect use of medications and/or referrals when needed; Patient advice or education (e.g.,\nred flag symptoms to watch for, advice on hydration, self-care, etc.) or a follow up plan\nis present; if procedures or escalations of care are present, they are the most appropriate\ncourse of action. OR no treatments are indicated and none are ordered\n4 Appropriate but less complete: treatments are appropriate and complete, including\nthe correct use of medications and/or referrals when needed but there is no patient advice,\neducation or follow up plan documented (e.g., red flag symptoms to watch for, advice on\nhydration, self-care, when to return to care, etc.)\n3 Adequate: Medications, referrals or procedures are reasonable and safe, but may not be\na standard first-line therapy (i.e., things that are likely to have minimal benefit or minimal\nharm if given, e.g. desloratadine for a URTI instead of nasal saline spray alone), or helpful\nbut non-critical referrals are missing\n2 Deficient: medications are present and somewhat inappropriate (i.e., medications that\nmay cause minor harm unnecessarily e.g., inappropriately broad antibiotic class when a\nnarrower spectrum is sufficient); minor medication dosage errors; clearly needed referrals,\nprocedures or escalations of care are missing\n1 Very poor: no medications given for a condition when clearly indicated; medications are\nvery inappropriate for the condition (e.g., use of any antibiotic when there is no indication\nbased on documented findings); significant dosage errors (e.g., too high of a dose based\non pediatric patient weight-based dosing); procedures performed or escalations of care are\nunwarranted\nTable 18: Likert score descriptions used by physician raters to evaluate treatment plans.\n44\nClinical Category Possible deficiency choices selected by physician raters\nTreatment • Medications are missing\n• Medications are present but inappropriate\n• Medications are appropriate but incorrect dosages (dose, frequency or duration)\n• Likely inappropriate use of antibiotics overall\n• Likely inappropriate class of antibiotics used\n• Referrals are missing\n• Referrals are present but inappropriate\n• Needed procedures are missing\n• Procedures are present but inappropriate\n• Needed escalations of care are missing\n• Escalations of care are present but inappropriate\n• None of the above\nDiagnosis • Primary diagnosis is likely incorrect\n• Primary diagnosis is missing\n• Primary diagnosis is too specific to be supported by current documentation\n• Additional diagnosis is likely incorrect\n• Clinically-relevant additional diagnosis is missing\n• None of the above\nInvestigations • Key investigations are missing\n• Unjustified investigations are ordered\n• None of the above\nHistory • Chief complaint is absent\n• Key details in the history are missing\n• Documentation of relevant systems on physical exam is absent\n• Pertinent vital signs are absent\n• None of the above\nTable 19: Physician raters chose deficiencies present in the relevant clinical documentation.\n45\nD Additional results\nD.1 Human rater study agreement\nFigure 14: Confusion matrices showing the ratings of two independent raters for each Likert question for the\nhuman rater study.\n46\nD.2 Effects on quality of care\nFigure 15: Likert 1 and 2 rates for history-taking, investigations, diagnosis, and treatment: cases with at\nleast one red model response for the category in question\nFigure 16: Likert 1 and 2 rates for history-taking, investigations, diagnosis, and treatment - results from\nduring the induction period. * indicates p < 0.05, ** p < 0.01, *** p < 0.001\n47\nLow-acuity cases Medium-acuity cases High-acuity cases\nHistory 31.5% (15.7%-44.3%) 33.5% (20.1%-44.7%) 35.8% (8.1%-55.1%)\nInvestigations 11.9% (-4.4%-25.5%) 9.4% (-2.3%-19.8%) 6.3% (-19.2%-26.3%)\nDiagnosis 11.2% (-3.9%-24.1%) 17.6% (5.6%-28.0%) 14.1% (-13.7%-35.1%)\nTreatment 17.0% (8.3%-24.9%) 9.8% (1.5%-17.4%) 10.4% (-5.3%-23.8%)\nTable 20: Relative risk reduction in clinical errors by physician-rated acuity.\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.228000 0.190000 0.272000 0.000000\nGroup: AI vs Non-AI 0.747000 0.618000 0.903000 0.003000\nGender: Female vs Male 1.089000 0.965000 1.229000 0.169000\nVisit type: Insurance vs Cash 0.871000 0.758000 1.001000 0.052000\nClinic: Embakasi vs mean clinic 0.978000 0.717000 1.332000 0.886000\nClinic: Kahawa West vs mean clinic 1.271000 1.057000 1.529000 0.011000\nClinic: Kangemi vs mean clinic 0.904000 0.544000 1.503000 0.698000\nClinic: Kasarani vs mean clinic 0.978000 0.772000 1.239000 0.854000\nClinic: Kawangware vs mean clinic 0.581000 0.417000 0.811000 0.001000\nClinic: Kimathi Street vs mean clinic 0.886000 0.547000 1.435000 0.624000\nClinic: Lang’ata vs mean clinic 1.339000 0.852000 2.105000 0.206000\nClinic: Lucky Summer vs mean clinic 1.088000 0.869000 1.362000 0.460000\nClinic: Mathare North vs mean clinic 0.804000 0.500000 1.292000 0.367000\nClinic: Pipeline vs mean clinic 1.230000 0.991000 1.527000 0.060000\nClinic: Sunton vs mean clinic 1.280000 0.871000 1.880000 0.209000\nClinic: Tassia vs mean clinic 0.851000 0.529000 1.371000 0.507000\nClinic: Umoja 1 vs mean clinic 1.061000 0.779000 1.444000 0.707000\nClinic: Umoja 2 vs mean clinic 0.962000 0.730000 1.266000 0.781000\nAge (years) 1.008000 1.005000 1.011000 0.000000\nTable 21: GEE model fit for history errors.\n48\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.324000 0.287000 0.365000 0.000000\nGroup: AI vs Non-AI 0.902000 0.807000 1.008000 0.069000\nGender: Female vs Male 1.085000 0.985000 1.194000 0.097000\nVisit type: Insurance vs Cash 0.982000 0.894000 1.079000 0.704000\nClinic: Embakasi vs mean clinic 0.969000 0.782000 1.199000 0.771000\nClinic: Kahawa West vs mean clinic 1.067000 0.889000 1.280000 0.486000\nClinic: Kangemi vs mean clinic 1.211000 1.030000 1.423000 0.020000\nClinic: Kasarani vs mean clinic 0.810000 0.571000 1.149000 0.237000\nClinic: Kawangware vs mean clinic 0.927000 0.662000 1.297000 0.658000\nClinic: Kimathi Street vs mean clinic 0.743000 0.463000 1.191000 0.217000\nClinic: Lang’ata vs mean clinic 0.995000 0.819000 1.210000 0.962000\nClinic: Lucky Summer vs mean clinic 1.131000 0.972000 1.316000 0.113000\nClinic: Mathare North vs mean clinic 1.167000 0.962000 1.415000 0.118000\nClinic: Pipeline vs mean clinic 0.967000 0.812000 1.152000 0.710000\nClinic: Sunton vs mean clinic 0.909000 0.766000 1.080000 0.280000\nClinic: Tassia vs mean clinic 0.890000 0.735000 1.078000 0.233000\nClinic: Umoja 1 vs mean clinic 1.035000 0.917000 1.169000 0.574000\nClinic: Umoja 2 vs mean clinic 1.152000 0.974000 1.362000 0.099000\nAge (years) 1.000000 0.997000 1.003000 0.921000\nTable 22: GEE model fit for investigations errors.\n49\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.337000 0.298000 0.383000 0.000000\nGroup: AI vs Non-AI 0.832000 0.744000 0.931000 0.001000\nGender: Female vs Male 1.004000 0.913000 1.103000 0.942000\nVisit type: Insurance vs Cash 0.997000 0.887000 1.120000 0.960000\nClinic: Embakasi vs mean clinic 1.008000 0.826000 1.229000 0.940000\nClinic: Kahawa West vs mean clinic 1.056000 0.907000 1.230000 0.483000\nClinic: Kangemi vs mean clinic 0.941000 0.804000 1.101000 0.448000\nClinic: Kasarani vs mean clinic 0.947000 0.786000 1.141000 0.568000\nClinic: Kawangware vs mean clinic 0.978000 0.823000 1.162000 0.797000\nClinic: Kimathi Street vs mean clinic 0.612000 0.453000 0.825000 0.001000\nClinic: Lang’ata vs mean clinic 1.009000 0.816000 1.248000 0.932000\nClinic: Lucky Summer vs mean clinic 0.984000 0.861000 1.125000 0.816000\nClinic: Mathare North vs mean clinic 1.126000 0.942000 1.347000 0.193000\nClinic: Pipeline vs mean clinic 1.148000 0.964000 1.367000 0.121000\nClinic: Sunton vs mean clinic 1.329000 1.012000 1.746000 0.041000\nClinic: Tassia vs mean clinic 1.120000 0.976000 1.286000 0.108000\nClinic: Umoja 1 vs mean clinic 1.123000 0.933000 1.351000 0.220000\nClinic: Umoja 2 vs mean clinic 0.751000 0.628000 0.898000 0.002000\nAge (years) 1.000000 0.997000 1.003000 0.801000\nTable 23: GEE model fit for diagnosis errors.\n50\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.649000 0.598000 0.704000 0.000000\nGroup: AI vs Non-AI 0.878000 0.812000 0.949000 0.001000\nGender: Female vs Male 0.944000 0.891000 1.001000 0.054000\nVisit type: Insurance vs Cash 0.949000 0.889000 1.012000 0.109000\nClinic: Embakasi vs mean clinic 1.015000 0.888000 1.160000 0.828000\nClinic: Kahawa West vs mean clinic 1.013000 0.929000 1.103000 0.776000\nClinic: Kangemi vs mean clinic 0.932000 0.762000 1.139000 0.490000\nClinic: Kasarani vs mean clinic 1.055000 0.895000 1.244000 0.521000\nClinic: Kawangware vs mean clinic 0.923000 0.782000 1.089000 0.344000\nClinic: Kimathi Street vs mean clinic 0.936000 0.785000 1.116000 0.461000\nClinic: Lang’ata vs mean clinic 1.045000 0.913000 1.196000 0.523000\nClinic: Lucky Summer vs mean clinic 0.988000 0.849000 1.150000 0.879000\nClinic: Mathare North vs mean clinic 1.103000 1.007000 1.209000 0.035000\nClinic: Pipeline vs mean clinic 1.045000 0.895000 1.221000 0.575000\nClinic: Sunton vs mean clinic 1.001000 0.844000 1.188000 0.987000\nClinic: Tassia vs mean clinic 0.863000 0.795000 0.938000 0.000000\nClinic: Umoja 1 vs mean clinic 1.069000 0.988000 1.157000 0.097000\nClinic: Umoja 2 vs mean clinic 1.033000 0.959000 1.113000 0.393000\nAge (years) 0.996000 0.994000 0.998000 0.000000\nTable 24: GEE model fit for treatment errors.\n51\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.230000 0.192000 0.275000 0.000000\nGroup: AI vs Non-AI 0.722000 0.596000 0.875000 0.001000\nGender: Female vs Male 1.097000 0.971000 1.241000 0.138000\nVisit type: Insurance vs Cash 0.877000 0.761000 1.011000 0.069000\nClinic: Embakasi vs mean clinic 0.975000 0.751000 1.266000 0.851000\nClinic: Kahawa West vs mean clinic 1.248000 1.049000 1.486000 0.012000\nClinic: Kangemi vs mean clinic 0.896000 0.539000 1.489000 0.673000\nClinic: Kasarani vs mean clinic 0.970000 0.803000 1.172000 0.753000\nClinic: Kawangware vs mean clinic 0.526000 0.404000 0.683000 0.000000\nClinic: Kimathi Street vs mean clinic 0.908000 0.562000 1.468000 0.695000\nClinic: Lang’ata vs mean clinic 1.334000 0.834000 2.135000 0.229000\nClinic: Lucky Summer vs mean clinic 1.024000 0.789000 1.328000 0.860000\nClinic: Mathare North vs mean clinic 0.860000 0.579000 1.277000 0.454000\nClinic: Pipeline vs mean clinic 1.248000 1.022000 1.525000 0.030000\nClinic: Sunton vs mean clinic 1.350000 0.853000 2.136000 0.200000\nClinic: Tassia vs mean clinic 0.831000 0.517000 1.336000 0.445000\nClinic: Umoja 1 vs mean clinic 1.082000 0.814000 1.437000 0.589000\nClinic: Umoja 2 vs mean clinic 1.026000 0.804000 1.309000 0.836000\nAge (years) 1.008000 1.004000 1.011000 0.000000\nTable 25: Modified Poisson model fit for history errors.\n52\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.324000 0.287000 0.366000 0.000000\nGroup: AI vs Non-AI 0.904000 0.809000 1.012000 0.079000\nGender: Female vs Male 1.089000 0.988000 1.200000 0.087000\nVisit type: Insurance vs Cash 0.980000 0.892000 1.077000 0.677000\nClinic: Embakasi vs mean clinic 0.963000 0.772000 1.203000 0.742000\nClinic: Kahawa West vs mean clinic 1.058000 0.883000 1.268000 0.543000\nClinic: Kangemi vs mean clinic 1.213000 1.035000 1.422000 0.017000\nClinic: Kasarani vs mean clinic 0.825000 0.580000 1.172000 0.282000\nClinic: Kawangware vs mean clinic 0.918000 0.654000 1.288000 0.619000\nClinic: Kimathi Street vs mean clinic 0.731000 0.459000 1.164000 0.186000\nClinic: Lang’ata vs mean clinic 1.001000 0.828000 1.210000 0.992000\nClinic: Lucky Summer vs mean clinic 1.126000 0.960000 1.321000 0.145000\nClinic: Mathare North vs mean clinic 1.175000 0.964000 1.431000 0.110000\nClinic: Pipeline vs mean clinic 0.960000 0.810000 1.137000 0.636000\nClinic: Sunton vs mean clinic 0.928000 0.791000 1.087000 0.354000\nClinic: Tassia vs mean clinic 0.864000 0.714000 1.046000 0.134000\nClinic: Umoja 1 vs mean clinic 1.035000 0.918000 1.167000 0.573000\nClinic: Umoja 2 vs mean clinic 1.169000 0.997000 1.372000 0.055000\nAge (years) 1.000000 0.997000 1.003000 0.907000\nTable 26: Modified Poisson model fit for investigations errors.\n53\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.340000 0.300000 0.386000 0.000000\nGroup: AI vs Non-AI 0.827000 0.741000 0.924000 0.001000\nGender: Female vs Male 1.006000 0.916000 1.106000 0.897000\nVisit type: Insurance vs Cash 0.999000 0.890000 1.123000 0.992000\nClinic: Embakasi vs mean clinic 1.010000 0.833000 1.225000 0.917000\nClinic: Kahawa West vs mean clinic 1.056000 0.904000 1.234000 0.488000\nClinic: Kangemi vs mean clinic 0.935000 0.800000 1.093000 0.401000\nClinic: Kasarani vs mean clinic 0.949000 0.791000 1.139000 0.575000\nClinic: Kawangware vs mean clinic 0.988000 0.828000 1.179000 0.895000\nClinic: Kimathi Street vs mean clinic 0.611000 0.451000 0.828000 0.001000\nClinic: Lang’ata vs mean clinic 0.990000 0.800000 1.225000 0.927000\nClinic: Lucky Summer vs mean clinic 0.974000 0.849000 1.118000 0.708000\nClinic: Mathare North vs mean clinic 1.141000 0.946000 1.378000 0.169000\nClinic: Pipeline vs mean clinic 1.151000 0.962000 1.377000 0.124000\nClinic: Sunton vs mean clinic 1.350000 1.005000 1.813000 0.046000\nClinic: Tassia vs mean clinic 1.111000 0.965000 1.280000 0.143000\nClinic: Umoja 1 vs mean clinic 1.109000 0.924000 1.331000 0.268000\nClinic: Umoja 2 vs mean clinic 0.760000 0.636000 0.908000 0.003000\nAge (years) 1.000000 0.997000 1.003000 0.928000\nTable 27: Modified Poisson model fit for diagnosis errors.\n54\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.646000 0.594000 0.702000 0.000000\nGroup: AI vs Non-AI 0.875000 0.808000 0.947000 0.001000\nGender: Female vs Male 0.946000 0.891000 1.004000 0.068000\nVisit type: Insurance vs Cash 0.952000 0.892000 1.017000 0.146000\nClinic: Embakasi vs mean clinic 1.000000 0.862000 1.160000 0.999000\nClinic: Kahawa West vs mean clinic 1.008000 0.915000 1.111000 0.865000\nClinic: Kangemi vs mean clinic 0.948000 0.794000 1.131000 0.550000\nClinic: Kasarani vs mean clinic 1.064000 0.909000 1.245000 0.438000\nClinic: Kawangware vs mean clinic 0.923000 0.785000 1.084000 0.326000\nClinic: Kimathi Street vs mean clinic 0.925000 0.754000 1.135000 0.454000\nClinic: Lang’ata vs mean clinic 1.039000 0.927000 1.165000 0.512000\nClinic: Lucky Summer vs mean clinic 0.984000 0.836000 1.159000 0.849000\nClinic: Mathare North vs mean clinic 1.123000 1.041000 1.212000 0.003000\nClinic: Pipeline vs mean clinic 1.046000 0.898000 1.218000 0.561000\nClinic: Sunton vs mean clinic 0.990000 0.828000 1.183000 0.909000\nClinic: Tassia vs mean clinic 0.850000 0.781000 0.925000 0.000000\nClinic: Umoja 1 vs mean clinic 1.069000 0.996000 1.147000 0.063000\nClinic: Umoja 2 vs mean clinic 1.035000 0.962000 1.113000 0.356000\nAge (years) 0.996000 0.994000 0.998000 0.000000\nTable 28: Modified Poisson model fit for treatment errors.\n55\nD.3 Failure mode analysis.\n56Non-AIAIRRRpNNTNerrorsreducedatPendaHistory:Documentationofrelevantsystemsonphysicalexamareabsent45.2%(42.7%-47.7%)34.3%(32.1%-36.7%)23.9%(17.0%-30.3%)0.0009.243247History:Pertinentvitalsignsareabsent6.8%(5.6%-8.2%)5.1%(4.2%-6.3%)24.2%(-0.3%-42.6%)0.059--History:Chiefcomplaintisabsent12.3%(10.7%-14.0%)10.9%(9.5%-12.5%)11.5%(-7.4%-27.0%)0.221--History:Keydetailsinthehistoryaremissing69.1%(66.7%-71.4%)58.9%(56.5%-61.3%)14.7%(10.1%-19.1%)0.0009.840745Investigations:Keyinvestigationsaremissing36.5%(34.1%-38.9%)32.9%(30.7%-35.2%)9.8%(0.7%-18.0%)0.03628.114257Investigations:Unjustifiedinvestigationsareordered13.9%(12.2%-15.7%)15.8%(14.2%-17.7%)-14.1%(-34.9%-3.6%)0.134--Diagnosis:Additionaldiagnosisislikelyincorrect12.0%(10.4%-13.7%)12.8%(11.3%-14.5%)-7.1%(-29.0%-11.1%)0.483--Diagnosis:Primarydiagnosistoospecifictobesupported26.5%(24.3%-28.8%)23.7%(21.7%-25.8%)10.5%(-0.9%-20.7%)0.071--Diagnosis:Primarydiagnosisismissing4.1%(3.2%-5.2%)4.0%(3.2%-5.1%)1.7%(-37.9%-29.9%)0.929--Diagnosis:Primarydiagnosisbroadwhenmorespecificissupported12.6%(11.0%-14.4%)10.8%(9.4%-12.4%)14.3%(-3.9%-29.2%)0.121--Diagnosis:Clinicallyrelevantadditionaldiagnosisismissing26.7%(24.5%-29.0%)27.0%(24.9%-29.2%)-1.0%(-13.4%-10.0%)0.872--Diagnosis:Primarydiagnosisislikelyincorrect26.5%(24.3%-28.8%)23.2%(21.2%-25.3%)12.5%(1.2%-22.5%)0.03230.313222Treatment:Escalationsofcarearepresentbutinappropriate0.9%(0.6%-1.6%)0.6%(0.3%-1.1%)35.0%(-45.9%-71.0%)0.312--Treatment:Referralsaremissing14.5%(12.8%-16.3%)12.6%(11.1%-14.2%)13.2%(-3.5%-27.3%)0.118--Treatment:Referralsarepresentbutinappropriate1.6%(1.1%-2.4%)0.8%(0.5%-1.3%)50.7%(3.5%-74.8%)0.046123.73233Treatment:Medicationsareappropriatebutincorrectdosageslisted13.7%(12.0%-15.5%)14.1%(12.5%-15.9%)-3.4%(-23.0%-13.1%)0.719--Treatment:Proceduresarepresentbutinappropriate0.3%(0.1%-0.7%)0.4%(0.2%-0.8%)-36.4%(-382.5%-61.4%)0.756--Treatment:Neededproceduresaremissing5.2%(4.2%-6.4%)5.6%(4.6%-6.8%)-8.5%(-45.4%-19.0%)0.637--Treatment:Medicationsaremissing14.7%(13.0%-16.6%)14.1%(12.5%-15.8%)4.5%(-13.2%-19.4%)0.612--Treatment:Medicationsarepresentbutinappropriate59.4%(56.9%-61.8%)52.3%(49.9%-54.7%)12.0%(6.3%-17.3%)0.00014.128387Treatment:Likelyinappropriateclassofantibioticsused13.9%(12.3%-15.8%)11.8%(10.4%-13.5%)15.1%(-1.8%-29.2%)0.079--Treatment:Neededescalationsofcarearemissing11.1%(9.6%-12.8%)10.7%(9.3%-12.3%)3.1%(-18.3%-20.6%)0.775--Treatment:Likelyinappropriateuseofantibioticsoverall24.7%(22.6%-26.9%)21.9%(20.0%-24.0%)11.2%(-0.8%-21.8%)0.070--Treatment:Incorrectpatientadvice,educationorfollowupplan2.4%(1.7%-3.3%)2.4%(1.8%-3.3%)-1.1%(-57.8%-35.2%)1.000--Treatment:Missingpatientadvice,educationorfollowupplan62.6%(60.1%-65.0%)55.4%(53.0%-57.8%)11.5%(6.2%-16.5%)0.00013.928726Table29:RatesofspecificfailuremodesinAIandnon-AIgroup,withrelativeriskreductions.p-valuesperFisher’sexacttest.Forrowswithp<0.05,wealsoshowthenumberneededtotreatandtheabsolutenumberoferrorswewouldexpecttobeavertedifthistoolwerewidelydeployedinthe400,000annualpatientvisitsatPenda.\n57\nD.4 Active deployment\nFigure 17: Rate of visits where the final call for the vitals and chief complaint or clinical notes bucket is red,\nfor AI and non-AI groups over time\nFigure 18: Rate of visits where the first call for the treatment bucket is red, for AI and non-AI groups over\ntime\n58\nFigure 19: Rate of visits where the final call for the vitals and chief complaint or clinical notes bucket is red,\nfor AI and non-AI groups over time\nFigure 20: Rate of visits where the final call for any of the AI Consult buckets is red, for the AI group\nspecifically, stratified by clinician quantile across both non-AI and AI groups.\n59\nD.5 AI analysis\nPhysician-physician agreement GPT-4.1-physician agreement o3-physician agreement\nHistory 77.8% 87.0% 86.6%\nInvestigations 66.0% 65.1% 70.5%\nDiagnosis 69.1% 75.0% 78.1%\nTreatment 67.1% 75.6% 76.0%\nTable 30: Within-1 Likert agreement between two physicians, GPT-4.1 and physicians, and o3 and physicians.\nPhysician-physician κ GPT-4.1-physician κ o3-physician κ\nHistory 0.260 0.283 0.306\nInvestigations 0.285 0.268 0.294\nDiagnosis 0.232 0.277 0.307\nTreatment 0.223 0.346 0.338\nTable 31: Fleiss’ κ for agreement on the presence of errors between two physicians, GPT-4.1 and physicians,\nand o3 and physicians.\nFigure 21: Likert 1 and 2 rates for history-taking, investigations, diagnosis, and treatment, comparing the AI\ngroup to the non-AI group. Ratings provided by GPT-4.1. Error bars show 95% Wilson confidence intervals.\n* indicates p < 0.05, ** p < 0.01, *** p < 0.001.\n60\nFigure 22: Likert 1 and 2 rates for history-taking, investigations, diagnosis, and treatment, comparing the\nAI group to the non-AI group. Ratings provided by o3. Error bars show 95% Wilson confidence intervals.\n* indicates p < 0.05, ** p < 0.01, *** p < 0.001.\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.181000 0.155000 0.211000 0.000000\nGroup: AI vs Non-AI 0.571000 0.457000 0.713000 0.000000\nGender: Female vs Male 1.013000 0.942000 1.089000 0.728000\nVisit type: Insurance vs Cash 0.801000 0.739000 0.868000 0.000000\nClinic: Embakasi vs mean clinic 0.844000 0.464000 1.533000 0.577000\nClinic: Kahawa West vs mean clinic 1.216000 0.997000 1.482000 0.053000\nClinic: Kangemi vs mean clinic 1.002000 0.525000 1.911000 0.996000\nClinic: Kasarani vs mean clinic 0.661000 0.538000 0.813000 0.000000\nClinic: Kawangware vs mean clinic 0.707000 0.433000 1.154000 0.165000\nClinic: Kimathi Street vs mean clinic 1.112000 0.935000 1.322000 0.229000\nClinic: Lang’ata vs mean clinic 1.474000 0.948000 2.290000 0.085000\nClinic: Lucky Summer vs mean clinic 0.584000 0.374000 0.912000 0.018000\nClinic: Mathare North vs mean clinic 1.350000 0.820000 2.221000 0.238000\nClinic: Pipeline vs mean clinic 1.643000 1.322000 2.041000 0.000000\nClinic: Sunton vs mean clinic 1.631000 1.178000 2.257000 0.003000\nClinic: Tassia vs mean clinic 0.851000 0.562000 1.288000 0.445000\nClinic: Umoja 1 vs mean clinic 0.554000 0.417000 0.737000 0.000000\nClinic: Umoja 2 vs mean clinic 1.230000 0.959000 1.579000 0.104000\nAge (years) 1.001000 0.998000 1.004000 0.635000\nTable 32: Modified Poisson model fit based on ratings from GPT-4.1 for history errors.\n61\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.560000 0.526000 0.596000 0.000000\nGroup: AI vs Non-AI 0.926000 0.857000 1.000000 0.050000\nGender: Female vs Male 1.027000 0.997000 1.059000 0.082000\nVisit type: Insurance vs Cash 0.867000 0.827000 0.908000 0.000000\nClinic: Embakasi vs mean clinic 0.821000 0.647000 1.041000 0.104000\nClinic: Kahawa West vs mean clinic 1.091000 0.975000 1.222000 0.130000\nClinic: Kangemi vs mean clinic 1.193000 1.071000 1.329000 0.001000\nClinic: Kasarani vs mean clinic 0.939000 0.841000 1.049000 0.266000\nClinic: Kawangware vs mean clinic 0.887000 0.789000 0.998000 0.047000\nClinic: Kimathi Street vs mean clinic 0.734000 0.579000 0.930000 0.010000\nClinic: Lang’ata vs mean clinic 0.993000 0.901000 1.093000 0.882000\nClinic: Lucky Summer vs mean clinic 1.034000 0.920000 1.163000 0.571000\nClinic: Mathare North vs mean clinic 1.053000 0.950000 1.166000 0.328000\nClinic: Pipeline vs mean clinic 1.048000 0.956000 1.149000 0.320000\nClinic: Sunton vs mean clinic 1.211000 1.085000 1.351000 0.001000\nClinic: Tassia vs mean clinic 0.855000 0.738000 0.991000 0.037000\nClinic: Umoja 1 vs mean clinic 0.958000 0.877000 1.046000 0.339000\nClinic: Umoja 2 vs mean clinic 1.172000 1.066000 1.288000 0.001000\nAge (years) 0.979000 0.977000 0.981000 0.000000\nTable 33: Modified Poisson model fit based on ratings from GPT-4.1 for investigations errors.\n62\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.254000 0.229000 0.282000 0.000000\nGroup: AI vs Non-AI 0.816000 0.705000 0.945000 0.006000\nGender: Female vs Male 1.049000 0.993000 1.108000 0.085000\nVisit type: Insurance vs Cash 0.811000 0.759000 0.866000 0.000000\nClinic: Embakasi vs mean clinic 0.743000 0.552000 0.999000 0.050000\nClinic: Kahawa West vs mean clinic 0.855000 0.727000 1.004000 0.056000\nClinic: Kangemi vs mean clinic 0.926000 0.659000 1.302000 0.658000\nClinic: Kasarani vs mean clinic 0.962000 0.785000 1.178000 0.706000\nClinic: Kawangware vs mean clinic 1.147000 0.985000 1.335000 0.078000\nClinic: Kimathi Street vs mean clinic 1.044000 0.854000 1.276000 0.673000\nClinic: Lang’ata vs mean clinic 1.068000 0.807000 1.415000 0.644000\nClinic: Lucky Summer vs mean clinic 0.719000 0.571000 0.906000 0.005000\nClinic: Mathare North vs mean clinic 1.267000 0.945000 1.700000 0.114000\nClinic: Pipeline vs mean clinic 0.946000 0.813000 1.101000 0.474000\nClinic: Sunton vs mean clinic 1.226000 0.981000 1.533000 0.073000\nClinic: Tassia vs mean clinic 1.298000 1.076000 1.566000 0.006000\nClinic: Umoja 1 vs mean clinic 1.149000 0.906000 1.456000 0.252000\nClinic: Umoja 2 vs mean clinic 0.804000 0.675000 0.957000 0.014000\nAge (years) 1.003000 1.001000 1.005000 0.000000\nTable 34: Modified Poisson model fit based on ratings from GPT-4.1 for diagnosis errors.\n63\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.593000 0.556000 0.632000 0.000000\nGroup: AI vs Non-AI 0.801000 0.724000 0.887000 0.000000\nGender: Female vs Male 1.007000 0.981000 1.034000 0.594000\nVisit type: Insurance vs Cash 0.956000 0.925000 0.988000 0.008000\nClinic: Embakasi vs mean clinic 1.015000 0.786000 1.312000 0.907000\nClinic: Kahawa West vs mean clinic 1.037000 0.949000 1.134000 0.421000\nClinic: Kangemi vs mean clinic 0.856000 0.634000 1.154000 0.307000\nClinic: Kasarani vs mean clinic 1.067000 0.963000 1.182000 0.213000\nClinic: Kawangware vs mean clinic 0.980000 0.769000 1.249000 0.870000\nClinic: Kimathi Street vs mean clinic 0.912000 0.788000 1.056000 0.218000\nClinic: Lang’ata vs mean clinic 0.988000 0.804000 1.213000 0.906000\nClinic: Lucky Summer vs mean clinic 0.959000 0.734000 1.253000 0.757000\nClinic: Mathare North vs mean clinic 1.045000 0.976000 1.119000 0.208000\nClinic: Pipeline vs mean clinic 0.924000 0.796000 1.072000 0.296000\nClinic: Sunton vs mean clinic 1.063000 0.981000 1.151000 0.134000\nClinic: Tassia vs mean clinic 0.841000 0.762000 0.927000 0.001000\nClinic: Umoja 1 vs mean clinic 1.211000 1.119000 1.311000 0.000000\nClinic: Umoja 2 vs mean clinic 1.139000 1.039000 1.248000 0.005000\nAge (years) 0.994000 0.993000 0.995000 0.000000\nTable 35: Modified Poisson model fit based on ratings from GPT-4.1 for treatment errors.\n64\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.145000 0.127000 0.166000 0.000000\nGroup: AI vs Non-AI 0.572000 0.465000 0.703000 0.000000\nGender: Female vs Male 0.967000 0.901000 1.037000 0.346000\nVisit type: Insurance vs Cash 0.795000 0.740000 0.853000 0.000000\nClinic: Embakasi vs mean clinic 1.050000 0.711000 1.550000 0.806000\nClinic: Kahawa West vs mean clinic 1.240000 0.996000 1.544000 0.054000\nClinic: Kangemi vs mean clinic 1.081000 0.671000 1.740000 0.750000\nClinic: Kasarani vs mean clinic 0.827000 0.648000 1.054000 0.125000\nClinic: Kawangware vs mean clinic 0.751000 0.566000 0.997000 0.048000\nClinic: Kimathi Street vs mean clinic 1.286000 1.083000 1.527000 0.004000\nClinic: Lang’ata vs mean clinic 1.030000 0.645000 1.644000 0.901000\nClinic: Lucky Summer vs mean clinic 0.739000 0.465000 1.174000 0.200000\nClinic: Mathare North vs mean clinic 1.062000 0.716000 1.575000 0.766000\nClinic: Pipeline vs mean clinic 1.457000 1.172000 1.810000 0.001000\nClinic: Sunton vs mean clinic 1.432000 0.918000 2.234000 0.114000\nClinic: Tassia vs mean clinic 0.837000 0.567000 1.235000 0.369000\nClinic: Umoja 1 vs mean clinic 0.788000 0.563000 1.102000 0.163000\nClinic: Umoja 2 vs mean clinic 1.076000 0.855000 1.354000 0.534000\nAge (years) 1.016000 1.014000 1.019000 0.000000\nTable 36: Modified Poisson model fit based on ratings from o3 for history errors.\n65\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.293000 0.269000 0.318000 0.000000\nGroup: AI vs Non-AI 0.872000 0.792000 0.959000 0.005000\nGender: Female vs Male 1.127000 1.075000 1.182000 0.000000\nVisit type: Insurance vs Cash 0.813000 0.763000 0.867000 0.000000\nClinic: Embakasi vs mean clinic 0.885000 0.672000 1.165000 0.383000\nClinic: Kahawa West vs mean clinic 1.100000 1.012000 1.195000 0.026000\nClinic: Kangemi vs mean clinic 1.008000 0.760000 1.338000 0.954000\nClinic: Kasarani vs mean clinic 0.930000 0.762000 1.136000 0.477000\nClinic: Kawangware vs mean clinic 0.889000 0.812000 0.974000 0.011000\nClinic: Kimathi Street vs mean clinic 0.847000 0.678000 1.059000 0.145000\nClinic: Lang’ata vs mean clinic 0.914000 0.702000 1.188000 0.500000\nClinic: Lucky Summer vs mean clinic 1.156000 0.929000 1.437000 0.193000\nClinic: Mathare North vs mean clinic 1.053000 0.907000 1.222000 0.495000\nClinic: Pipeline vs mean clinic 0.971000 0.870000 1.083000 0.598000\nClinic: Sunton vs mean clinic 1.225000 1.081000 1.388000 0.001000\nClinic: Tassia vs mean clinic 0.858000 0.746000 0.987000 0.032000\nClinic: Umoja 1 vs mean clinic 1.038000 0.889000 1.212000 0.640000\nClinic: Umoja 2 vs mean clinic 1.105000 0.984000 1.241000 0.092000\nAge (years) 0.992000 0.990000 0.994000 0.000000\nTable 37: Modified Poisson model fit based on ratings from o3 for investigations errors.\n66\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.292000 0.266000 0.321000 0.000000\nGroup: AI vs Non-AI 0.854000 0.762000 0.956000 0.006000\nGender: Female vs Male 1.023000 0.982000 1.067000 0.279000\nVisit type: Insurance vs Cash 0.804000 0.766000 0.843000 0.000000\nClinic: Embakasi vs mean clinic 0.822000 0.640000 1.055000 0.123000\nClinic: Kahawa West vs mean clinic 0.893000 0.782000 1.021000 0.097000\nClinic: Kangemi vs mean clinic 1.012000 0.825000 1.241000 0.909000\nClinic: Kasarani vs mean clinic 1.027000 0.919000 1.148000 0.637000\nClinic: Kawangware vs mean clinic 1.064000 0.977000 1.159000 0.155000\nClinic: Kimathi Street vs mean clinic 1.043000 0.897000 1.213000 0.585000\nClinic: Lang’ata vs mean clinic 1.064000 0.808000 1.399000 0.660000\nClinic: Lucky Summer vs mean clinic 0.801000 0.697000 0.921000 0.002000\nClinic: Mathare North vs mean clinic 1.056000 0.839000 1.329000 0.645000\nClinic: Pipeline vs mean clinic 0.991000 0.881000 1.114000 0.873000\nClinic: Sunton vs mean clinic 1.178000 0.918000 1.510000 0.198000\nClinic: Tassia vs mean clinic 1.137000 0.976000 1.325000 0.099000\nClinic: Umoja 1 vs mean clinic 1.046000 0.859000 1.273000 0.656000\nClinic: Umoja 2 vs mean clinic 0.887000 0.773000 1.018000 0.087000\nAge (years) 1.004000 1.002000 1.006000 0.000000\nTable 38: Modified Poisson model fit based on ratings from o3 for diagnosis errors.\n67\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.675000 0.640000 0.713000 0.000000\nGroup: AI vs Non-AI 0.827000 0.765000 0.894000 0.000000\nGender: Female vs Male 0.955000 0.932000 0.977000 0.000000\nVisit type: Insurance vs Cash 0.933000 0.907000 0.960000 0.000000\nClinic: Embakasi vs mean clinic 0.960000 0.776000 1.188000 0.708000\nClinic: Kahawa West vs mean clinic 1.014000 0.935000 1.099000 0.736000\nClinic: Kangemi vs mean clinic 0.928000 0.775000 1.111000 0.416000\nClinic: Kasarani vs mean clinic 1.016000 0.934000 1.105000 0.711000\nClinic: Kawangware vs mean clinic 0.996000 0.834000 1.190000 0.967000\nClinic: Kimathi Street vs mean clinic 0.955000 0.847000 1.077000 0.455000\nClinic: Lang’ata vs mean clinic 1.005000 0.824000 1.227000 0.957000\nClinic: Lucky Summer vs mean clinic 0.920000 0.746000 1.135000 0.438000\nClinic: Mathare North vs mean clinic 1.088000 1.037000 1.142000 0.001000\nClinic: Pipeline vs mean clinic 0.950000 0.832000 1.084000 0.443000\nClinic: Sunton vs mean clinic 1.022000 0.965000 1.082000 0.465000\nClinic: Tassia vs mean clinic 0.877000 0.825000 0.931000 0.000000\nClinic: Umoja 1 vs mean clinic 1.169000 1.085000 1.259000 0.000000\nClinic: Umoja 2 vs mean clinic 1.112000 1.018000 1.216000 0.018000\nAge (years) 0.994000 0.993000 0.995000 0.000000\nTable 39: Modified Poisson model fit based on ratings from o3 for treatment errors.\n68\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.187000 0.159000 0.219000 0.000000\nGroup: AI vs Non-AI 0.607000 0.477000 0.773000 0.000000\nGender: Female vs Male 1.001000 0.933000 1.074000 0.974000\nVisit type: Insurance vs Cash 0.802000 0.743000 0.866000 0.000000\nClinic: Embakasi vs mean clinic 0.875000 0.559000 1.368000 0.557000\nClinic: Kahawa West vs mean clinic 1.027000 0.754000 1.399000 0.864000\nClinic: Kangemi vs mean clinic 0.942000 0.562000 1.578000 0.819000\nClinic: Kasarani vs mean clinic 0.730000 0.516000 1.035000 0.077000\nClinic: Kawangware vs mean clinic 0.987000 0.653000 1.492000 0.951000\nClinic: Kimathi Street vs mean clinic 1.234000 0.966000 1.577000 0.092000\nClinic: Lang’ata vs mean clinic 1.292000 0.652000 2.561000 0.463000\nClinic: Lucky Summer vs mean clinic 0.672000 0.446000 1.013000 0.058000\nClinic: Mathare North vs mean clinic 1.056000 0.678000 1.647000 0.809000\nClinic: Pipeline vs mean clinic 1.535000 1.185000 1.988000 0.001000\nClinic: Sunton vs mean clinic 1.504000 1.173000 1.928000 0.001000\nClinic: Tassia vs mean clinic 0.911000 0.620000 1.338000 0.635000\nClinic: Umoja 1 vs mean clinic 0.632000 0.503000 0.795000 0.000000\nClinic: Umoja 2 vs mean clinic 0.983000 0.721000 1.339000 0.911000\nAge (years) 1.001000 0.998000 1.004000 0.554000\nTable 40: GEE model fit based on ratings from GPT-4.1 for history errors.\n69\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.565000 0.535000 0.597000 0.000000\nGroup: AI vs Non-AI 0.955000 0.880000 1.036000 0.265000\nGender: Female vs Male 1.018000 0.989000 1.049000 0.229000\nVisit type: Insurance vs Cash 0.861000 0.821000 0.902000 0.000000\nClinic: Embakasi vs mean clinic 0.983000 0.824000 1.172000 0.848000\nClinic: Kahawa West vs mean clinic 1.026000 0.932000 1.128000 0.604000\nClinic: Kangemi vs mean clinic 0.910000 0.802000 1.033000 0.146000\nClinic: Kasarani vs mean clinic 1.052000 0.930000 1.190000 0.423000\nClinic: Kawangware vs mean clinic 0.869000 0.745000 1.014000 0.075000\nClinic: Kimathi Street vs mean clinic 0.762000 0.680000 0.855000 0.000000\nClinic: Lang’ata vs mean clinic 0.943000 0.774000 1.149000 0.563000\nClinic: Lucky Summer vs mean clinic 1.058000 0.923000 1.213000 0.419000\nClinic: Mathare North vs mean clinic 1.069000 0.918000 1.245000 0.388000\nClinic: Pipeline vs mean clinic 1.082000 0.985000 1.189000 0.101000\nClinic: Sunton vs mean clinic 1.133000 1.021000 1.258000 0.019000\nClinic: Tassia vs mean clinic 0.941000 0.825000 1.074000 0.371000\nClinic: Umoja 1 vs mean clinic 1.088000 1.022000 1.158000 0.008000\nClinic: Umoja 2 vs mean clinic 1.077000 0.970000 1.196000 0.164000\nAge (years) 0.978000 0.976000 0.980000 0.000000\nTable 41: GEE model fit based on ratings from GPT-4.1 for investigations errors.\n70\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.257000 0.234000 0.283000 0.000000\nGroup: AI vs Non-AI 0.819000 0.710000 0.945000 0.006000\nGender: Female vs Male 1.043000 0.989000 1.099000 0.120000\nVisit type: Insurance vs Cash 0.812000 0.761000 0.867000 0.000000\nClinic: Embakasi vs mean clinic 0.840000 0.600000 1.176000 0.310000\nClinic: Kahawa West vs mean clinic 0.854000 0.719000 1.013000 0.071000\nClinic: Kangemi vs mean clinic 0.924000 0.676000 1.264000 0.623000\nClinic: Kasarani vs mean clinic 0.946000 0.812000 1.102000 0.478000\nClinic: Kawangware vs mean clinic 1.048000 0.839000 1.309000 0.681000\nClinic: Kimathi Street vs mean clinic 1.171000 0.945000 1.450000 0.149000\nClinic: Lang’ata vs mean clinic 1.070000 0.847000 1.350000 0.572000\nClinic: Lucky Summer vs mean clinic 0.906000 0.665000 1.234000 0.532000\nClinic: Mathare North vs mean clinic 1.057000 0.885000 1.262000 0.540000\nClinic: Pipeline vs mean clinic 1.023000 0.861000 1.216000 0.796000\nClinic: Sunton vs mean clinic 1.217000 1.040000 1.423000 0.014000\nClinic: Tassia vs mean clinic 1.103000 0.890000 1.367000 0.371000\nClinic: Umoja 1 vs mean clinic 1.113000 0.933000 1.327000 0.234000\nClinic: Umoja 2 vs mean clinic 0.756000 0.621000 0.921000 0.005000\nAge (years) 1.003000 1.002000 1.005000 0.000000\nTable 42: GEE model fit based on ratings from GPT-4.1 for diagnosis errors.\n71\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.570000 0.536000 0.605000 0.000000\nGroup: AI vs Non-AI 0.872000 0.798000 0.953000 0.003000\nGender: Female vs Male 1.004000 0.978000 1.030000 0.784000\nVisit type: Insurance vs Cash 0.963000 0.934000 0.992000 0.013000\nClinic: Embakasi vs mean clinic 1.082000 0.888000 1.319000 0.434000\nClinic: Kahawa West vs mean clinic 0.993000 0.901000 1.095000 0.892000\nClinic: Kangemi vs mean clinic 0.825000 0.629000 1.082000 0.164000\nClinic: Kasarani vs mean clinic 1.070000 0.952000 1.203000 0.254000\nClinic: Kawangware vs mean clinic 0.946000 0.773000 1.158000 0.592000\nClinic: Kimathi Street vs mean clinic 0.894000 0.757000 1.056000 0.189000\nClinic: Lang’ata vs mean clinic 1.000000 0.806000 1.241000 0.999000\nClinic: Lucky Summer vs mean clinic 0.900000 0.779000 1.041000 0.156000\nClinic: Mathare North vs mean clinic 1.023000 0.931000 1.125000 0.634000\nClinic: Pipeline vs mean clinic 1.005000 0.866000 1.166000 0.951000\nClinic: Sunton vs mean clinic 1.081000 0.997000 1.172000 0.058000\nClinic: Tassia vs mean clinic 0.908000 0.826000 0.999000 0.047000\nClinic: Umoja 1 vs mean clinic 1.256000 1.159000 1.361000 0.000000\nClinic: Umoja 2 vs mean clinic 1.116000 1.031000 1.209000 0.007000\nAge (years) 0.994000 0.993000 0.995000 0.000000\nTable 43: GEE model fit based on ratings from GPT-4.1 for treatment errors.\n72\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.152000 0.133000 0.173000 0.000000\nGroup: AI vs Non-AI 0.595000 0.483000 0.732000 0.000000\nGender: Female vs Male 0.962000 0.900000 1.029000 0.261000\nVisit type: Insurance vs Cash 0.802000 0.750000 0.856000 0.000000\nClinic: Embakasi vs mean clinic 1.245000 0.921000 1.684000 0.154000\nClinic: Kahawa West vs mean clinic 0.980000 0.735000 1.308000 0.892000\nClinic: Kangemi vs mean clinic 1.060000 0.741000 1.515000 0.751000\nClinic: Kasarani vs mean clinic 0.954000 0.686000 1.325000 0.777000\nClinic: Kawangware vs mean clinic 0.971000 0.693000 1.362000 0.865000\nClinic: Kimathi Street vs mean clinic 1.321000 1.181000 1.478000 0.000000\nClinic: Lang’ata vs mean clinic 1.072000 0.570000 2.016000 0.829000\nClinic: Lucky Summer vs mean clinic 0.689000 0.426000 1.114000 0.128000\nClinic: Mathare North vs mean clinic 0.886000 0.636000 1.233000 0.472000\nClinic: Pipeline vs mean clinic 1.387000 1.159000 1.661000 0.000000\nClinic: Sunton vs mean clinic 1.317000 0.969000 1.791000 0.079000\nClinic: Tassia vs mean clinic 0.964000 0.698000 1.332000 0.824000\nClinic: Umoja 1 vs mean clinic 0.709000 0.524000 0.960000 0.026000\nClinic: Umoja 2 vs mean clinic 0.966000 0.748000 1.248000 0.792000\nAge (years) 1.016000 1.014000 1.018000 0.000000\nTable 44: GEE model fit based on ratings from o3 for history errors.\n73\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.292000 0.270000 0.315000 0.000000\nGroup: AI vs Non-AI 0.874000 0.802000 0.953000 0.002000\nGender: Female vs Male 1.121000 1.071000 1.174000 0.000000\nVisit type: Insurance vs Cash 0.815000 0.764000 0.869000 0.000000\nClinic: Embakasi vs mean clinic 0.941000 0.734000 1.207000 0.634000\nClinic: Kahawa West vs mean clinic 1.050000 0.950000 1.162000 0.340000\nClinic: Kangemi vs mean clinic 0.905000 0.709000 1.155000 0.422000\nClinic: Kasarani vs mean clinic 0.940000 0.792000 1.115000 0.477000\nClinic: Kawangware vs mean clinic 0.930000 0.829000 1.042000 0.212000\nClinic: Kimathi Street vs mean clinic 0.931000 0.772000 1.121000 0.449000\nClinic: Lang’ata vs mean clinic 0.853000 0.652000 1.118000 0.249000\nClinic: Lucky Summer vs mean clinic 1.077000 0.906000 1.280000 0.402000\nClinic: Mathare North vs mean clinic 1.028000 0.892000 1.184000 0.703000\nClinic: Pipeline vs mean clinic 1.025000 0.904000 1.162000 0.696000\nClinic: Sunton vs mean clinic 1.166000 1.044000 1.303000 0.007000\nClinic: Tassia vs mean clinic 0.944000 0.826000 1.080000 0.403000\nClinic: Umoja 1 vs mean clinic 1.057000 0.926000 1.206000 0.413000\nClinic: Umoja 2 vs mean clinic 1.142000 1.030000 1.265000 0.012000\nAge (years) 0.992000 0.990000 0.994000 0.000000\nTable 45: GEE model fit based on ratings from o3 for investigations errors.\n74\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.295000 0.269000 0.323000 0.000000\nGroup: AI vs Non-AI 0.853000 0.765000 0.952000 0.004000\nGender: Female vs Male 1.022000 0.981000 1.063000 0.297000\nVisit type: Insurance vs Cash 0.804000 0.766000 0.843000 0.000000\nClinic: Embakasi vs mean clinic 0.891000 0.708000 1.120000 0.323000\nClinic: Kahawa West vs mean clinic 0.881000 0.768000 1.011000 0.071000\nClinic: Kangemi vs mean clinic 0.938000 0.722000 1.220000 0.635000\nClinic: Kasarani vs mean clinic 1.040000 0.919000 1.178000 0.534000\nClinic: Kawangware vs mean clinic 1.009000 0.888000 1.145000 0.894000\nClinic: Kimathi Street vs mean clinic 1.098000 0.901000 1.338000 0.354000\nClinic: Lang’ata vs mean clinic 1.056000 0.854000 1.304000 0.616000\nClinic: Lucky Summer vs mean clinic 0.905000 0.787000 1.040000 0.159000\nClinic: Mathare North vs mean clinic 1.062000 0.884000 1.274000 0.522000\nClinic: Pipeline vs mean clinic 1.057000 0.929000 1.203000 0.397000\nClinic: Sunton vs mean clinic 1.144000 0.997000 1.313000 0.056000\nClinic: Tassia vs mean clinic 1.058000 0.920000 1.217000 0.431000\nClinic: Umoja 1 vs mean clinic 1.005000 0.857000 1.178000 0.954000\nClinic: Umoja 2 vs mean clinic 0.863000 0.732000 1.017000 0.078000\nAge (years) 1.004000 1.003000 1.006000 0.000000\nTable 46: GEE model fit based on ratings from o3 for diagnosis errors.\n75\nRelative risk 95% CI lower 95% CI upper p\nIntercept 0.660000 0.627000 0.694000 0.000000\nGroup: AI vs Non-AI 0.883000 0.822000 0.949000 0.001000\nGender: Female vs Male 0.955000 0.932000 0.978000 0.000000\nVisit type: Insurance vs Cash 0.936000 0.912000 0.961000 0.000000\nClinic: Embakasi vs mean clinic 1.056000 0.875000 1.276000 0.569000\nClinic: Kahawa West vs mean clinic 0.971000 0.886000 1.064000 0.530000\nClinic: Kangemi vs mean clinic 0.915000 0.778000 1.077000 0.284000\nClinic: Kasarani vs mean clinic 1.016000 0.919000 1.124000 0.758000\nClinic: Kawangware vs mean clinic 0.961000 0.834000 1.107000 0.584000\nClinic: Kimathi Street vs mean clinic 0.952000 0.850000 1.066000 0.392000\nClinic: Lang’ata vs mean clinic 1.016000 0.844000 1.223000 0.868000\nClinic: Lucky Summer vs mean clinic 0.960000 0.878000 1.049000 0.366000\nClinic: Mathare North vs mean clinic 1.071000 0.996000 1.152000 0.065000\nClinic: Pipeline vs mean clinic 0.933000 0.805000 1.082000 0.358000\nClinic: Sunton vs mean clinic 1.012000 0.922000 1.112000 0.798000\nClinic: Tassia vs mean clinic 0.944000 0.874000 1.019000 0.141000\nClinic: Umoja 1 vs mean clinic 1.209000 1.133000 1.290000 0.000000\nClinic: Umoja 2 vs mean clinic 1.043000 0.967000 1.124000 0.276000\nAge (years) 0.994000 0.993000 0.995000 0.000000\nTable 47: GEE model fit based on ratings from o3 for treatment errors.\n76\nD.6 Clinician survey\nFigure 23: AI group satisfaction net promoter score of AI Consult.\nFigure 24: AI group satisfaction with AI Consult.\n77\nD.7 Use and usability\nFigure 25: Mean treatment Likert from GPT-4.1 vs total clinician attending time, binned to 5-minute\nintervals, in the non-AI and AI groups. 95% CIs calculated with 1000 bootstrap samples. Includes only\nvisits with duration 30 minutes or less.\nFigure 26: Rate of clinician thumbs up feedback on AI Consult responses in the AI group over time.\n78\nFigure 27: Rate of clinician thumbs up feedback on AI Consult responses in the AI group over time.\n79\nE Prompts used by AI Consult\nAll calls to AI Consult were in a new conversation with GPT-4o, consisting of a single system message\nand user message. The system message contained instructions for the model, and was different for different\ndomains (e.g., diagnosis vs treatment) but the same across multiple calls for a given domain. The user\nprompt contained structured clinical data that provided instructions for the model to carry out the task,\nand varied from call to call.\nE.1 System prompt for vitals and chief complaint evaluation\nYou are an advanced Clinical Decision Support System (CDSS) integrated within an Electronic Medical\nRecord (EMR) system in Nairobi, Kenya, staffed by Clinical Officers.\nYour role is to:\n1. Evaluate the patient’s chief complaint and vital signs (and MUAC for children ages 6 months–5 years).\n2. Determine whether there are urgent or concerning findings that may indicate a medical emergency (Red),\nincomplete or suboptimal documentation or potential concerns (Yellow), or if everything is appropriate and\nnon-urgent (Green).\n3. Provide concise, actionable recommendations to improve patient safety and care quality.\nSeverity Thresholds\n1. Red\n• Potential emergency based on the chief complaint and abnormal vitals (e.g., severe chest pain + very high\nBP, or severe headache + hypertensive crisis).\n• All vitals are missing (critical omission).\n• If a pregnant patient’s complaint and vitals suggest a severe complication (e.g., very high BP, severe edema,\netc.).\n• Example: “Chief complaint of severe headache with BP 180/110 mmHg—possible hypertensive emergency.”\n2. Yellow\n• Concerning chief complaint (e.g., chest pain) but vitals do not clearly indicate an emergency; additional\nassessment is needed.\n• Some essential vitals are missing but not all .\n• Respiratory complaints without documented SpO2 or Respiratory Rate .\n• If the MUAC or other vital sign is borderline, or mild abnormalities that need follow-up but are not\nemergent.\n3. Green\n• All relevant vitals are documented, no signs of emergent danger in the chief complaint or vitals.\n• Example: “Vitals within normal limits, mild sore throat, no red flags.”\nKey Principles\n1. Essential Vitals\n• Adults : Temperature, Pulse (HR), Blood Pressure (BP), Height, Weight, and Calculated BMI, and, if\nrespiratory complaints, recommend SpO2.\n• Children under 12 : Temperature, Pulse, (BP is not expected), and for ages 6 months–5 years, MUAC is\nrecommended but not mandatory\n80\n• Pregnant Patients : BP is crucial. Missing BP in a pregnant patient is a bigger concern than missing other\nvitals.\n2. MUAC Interpretation\n• Red : Severe malnutrition (urgent)\n• Yellow : Moderate malnutrition\n• Green : No malnutrition\n• Do not request MUAC for ages outside 6 months–5 years unless specifically indicated.\n3. Respiratory Rate\n• While helpful, respiratory rate is not critical for all patients (except those with respiratory complaints, in\nwhich case missing RR or SpO2 triggers Red).\n4. Actionable Recommendations\n• If Red: Offer urgent steps (e.g., re-check vitals, immediate advanced care for suspected emergencies).\n• If Yellow: Suggest needed clarifications or missing vitals.\n• If Green: Encourage routine next steps; no critical gaps.\nOutput Structure\nYou must return exactly one severity level in JSON, with an explanatory Reason and an Action: { ”Re-\nsponse”: [ { ”Severity”: ”Green”, ”Reason”: ”” } ], ”Recommendations”: [ { ”Severity”: ”Green”, ”Action”:\n”” } ] }\nFew-Shot Examples\nBelow are three scenarios in Penda’s documentation format, each showing how the system should respond\nwith only one severity and appropriate recommendations.\nGreen Example\nClinical Documentation\nAge: 24y Gender: Female\nVitals: Temperature: 37.30 Celsius Pulse: 78 bpm Blood Pressure: 118/76 Respiratory Rate: 16 bpm SPO2:\n98 BMI: 22 Weight: 60.0 kgs Height: 165.0 cms MUAC: Not recorded\nChief complaints: Sore Throat\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Green”, ”Reason”: ”All essential vitals are docu-\nmented and within normal limits. Chief complaint of mild sore throat does not indicate an emergency.” } ],\n”Recommendations”: [ { ”Severity”: ”Green”, ”Action”: ”Proceed with routine examination and consider\na rapid strep test if symptoms worsen.” } ] }\nYellow Example:\nClinical Documentation:\nAge: 4y Gender: Female\nVitals: Temperature: 37.20 Celsius Pulse: 88 bpm Blood Pressure: Not recorded Respiratory Rate: 18 bpm\nSPO2: 98 Weight: 16.5 kgs Height: 102.0 cms MUAC: Not recorded\nChief complaints: Abdominal Pain:\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Yellow”, ”Reason”: ”Mild abdominal pain with\nstable vitals, but MUAC is missing for a 4-year-old child. This information could help assess nutritional\n81\nstatus.” } ], ”Recommendations”: [ { ”Severity”: ”Yellow”, ”Action”: ”Document MUAC to evaluate\npossible malnutrition; continue monitoring symptoms and ensure adequate hydration.” } ] }\nRed Example:\nClinical Documentation:\nAge: 4y Gender: Male\nVitals: Temperature: 38.00 Celsius Pulse: 95 bpm Blood Pressure: Not recorded SPO2: 99 BMI: 18 Weight:\n18.0 kgs Height: 100.0 cms MUAC: Not recorded\nChief complaints: Cough and Difficult Breathing:\nExpected JSON output: { ”Response”: [ { ”Severity”: ”Red”, ”Reason”: ”Respiratory complaint without\ndocumented respiratory rate. Child’s cough and difficulty breathing warrant a respiratory exam.” } ],\n”Recommendations”: [ { ”Severity”: ”Red”, ”Action”: ”Record the respiratory rate; assess for any signs of\nrespiratory distress (retractions, wheezing). Continue monitoring temperature and pulse.” } ] }\nRed Example:\nClinical Documentation: Age: 29y Gender: Female Pregnant: 34 weeks gestation Vitals: Temperature:\n37.80 Celsius Pulse: 105 bpm Blood Pressure: 170/110 Respiratory Rate: Not recorded SPO2: Not recorded\nWeight: 70.0 kgs Height: 160.0 cms MUAC: Not recorded Chief complaints: Headache and Blurred Vision:\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Red”, ”Reason”: ”Severe headache and very high\nBP in late pregnancy indicate a possible hypertensive emergency (pre-eclampsia/eclampsia).” } ], ”Recom-\nmendations”: [ { ”Severity”: ”Red”, ”Action”: ”Perform urgent assessment for pre-eclampsia/eclampsia,\ncheck urine protein, evaluate neurological status, and prepare for possible referral to a higher-level facility.”\n} ] }\nE.2 Components of the user prompt for vitals and chief complaint evaluation\n• Age\n• Gender\n• Structured history like pregnancy status, if recorded\n• Vitals:\n– Temperature\n– Pulse rate\n– Blood pressure\n– Respiratory rate\n– SPO2\n– Weight\n– Height\n– Mean upper arm circumference (MUAC)\n• Chief complaints\n82\nE.3 System prompt for clinical notes\nYou are an advanced Clinical Decision Support System (CDSS) integrated within an Electronic Medical\nRecord (EMR).\nYou are supporting Clinical Officers in a primary care setting in Nairobi, Kenya.\nYour primary role is to: Assess the completeness and consistency of clinical notes (vitals, chief complaints,\nhistory, exam findings).\nPlease note, in most cases, laboratory or imaging studies have not yet been done at the time this prompt is\nrun, therefore, do not penalize for lack of relevant diagnostic test results.\nProvide severity-based alerts (Green, Yellow, Red).\nOffer concise, actionable recommendations to improve documentation and care quality.\nThresholds for Severity\nGreen\nDocumentation is sufficiently complete for safe decision-making.\nMinor omissions do not compromise patient care.\nExample: All critical components of a complaint (e.g., RLQ pain with proper abdominal exam) are present,\nor mental-health check includes a basic mental-status description (“patient is well-appearing, normal affect”).\nYellow\nDocumentation is generally sufficient but would benefit from additional or more-focused details to enhance\ncare quality.\nExample: Fever + headache, missing mention of neurological red flags (e.g., photophobia, neck stiffness) but\nthe basics are there.\nSuggest clarifying those details.\nRed\nA serious or critical omission on clinical history & examination prevents proper diagnosis or management,\nor documentation has major contradictions.\nFor example, if the notes say “no fever” but the temperature is recorded as 40 °C, that is a serious contra-\ndiction.\nNote that lack of documentation of lab results in the clinical notes is not a critical omission.\nReserved for high-impact issues (e.g., no abdominal exam in a possible appendicitis, no basic vitals for chest\npain).\nDialed-up threshold: do not trigger Red over missing tangential information (e.g., sexual history in a patient\nwith a mild sore throat) unless it’s directly relevant to the presenting complaint.\nKey Principles\nFocused Physical Exam: required for most complaints, but scope depends on clinical context.\nFor example, documentation of neck stiffness is not required for every complaint of headache, but must be\ndocumented in case of severe headache with fever.\nFor a mild mental-health concern, noting “patient is well-appearing with normal affect” may suffice.\nFor acute abdominal pain, a more detailed abdominal exam is essential.\nChildren between 6 months and 5 years of age should have MUAC (mid-upper-arm circumference) and/or\nweight and height documented.\n83\nContext-Relevance: avoid penalizing missing family, sexual, or menstrual history unless the data point\ndirectly impacts the medical decision-making (e.g., potential pregnancy, family history of breast cancer for\nevaluating a breast lump).\nDo not penalize for lack of laboratory-result documentation.\nIf the documentation states the time frame (e.g., “headache for 3 days”) or intensity (e.g., “mild, moderate,\nor severe”), then consider severity and duration to be adequately documented.\nActionable Recommendations: provide short, specific steps to correct omissions or inconsistencies.\nIf the documentation is sound, confirm it with a Green rating.\nOutput Structure\nYour response must be returned in JSON with the following format. You will output exactly one severity\nlevel (Green, Yellow, or Red), determined by the overall clinical scenario.\n{ ”Response”: [ { ”Severity”: ”Red”, ”Reason”: ”” } ], ”Recommendations”: [ { ”Severity”: ”Red”,\n”Action”: ”” } ] }\nSeverity\nGreen : Documentation is sufficiently complete for safe decision-making.\nYellow : Generally sufficient, but recommend additional or more-focused details.\nRed : A serious or critical omission prevents proper diagnosis/management, or there’s a major mismatch in\ndocumentation.\nReason : A concise explanation of why this severity is indicated.\nAction : The recommended next step to correct or improve documentation/care.\nImportant: you produce only one severity (Green or Yellow or Red), with a corresponding Reason and\nAction. Omit the other severities entirely from the JSON.\nExample Outputs\nThe following examples illustrate typical scenarios but are not exhaustive rules.\nUse clinical context to decide the best severity rating.\nGreen Example\nAge: 27 y Gender: Male\nVitals: Temperature 37.50 °C, Pulse 78 bpm, Respiratory rate 16 bpm, Blood Pressure 120/80, SPO2 98,\nBMI –, Weight 68 kg, Height 170 cm, MUAC –\nChief complaints: Cough\nNotes: mild, non-productive Severity: mild Duration: 2 days\nClinical Notes: patient has had mild cough and nasal congestion for 2 days. Denies difficulty breathing\nor chest pain. Vitals are stable, lung auscultation clear. Throat slightly erythematous, no exudates. No\nsignificant past medical history. Plan: advise hydration, rest, over-the-counter analgesics.\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Green”, ”Reason”: ”Documentation is sufficiently\ncomplete for a patient with mild cough.” } ], ”Recommendations”: [ { ”Severity”: ”Green”, ”Action”:\n”Continue with current plan; no critical gaps identified.” } ] }\nYellow Example\nAge: 30 y Gender: Female\n84\nVitals: Temperature 37.20 °C, Pulse 80 bpm, Respiratory rate 18 bpm, Blood Pressure 110/70, SPO2 99,\nBMI –, Weight 60 kg, Height 162 cm, MUAC –\nChief complaints: Abdominal Pain Notes: dull ache, lower abdomen Severity: moderate Duration: 3 days\nClinical Notes: patient complains of lower abdominal pain for 3 days. Denies severe nausea or vomiting.\nBowel movements normal, no blood in stool. Vitals stable. Physical exam: mild tenderness lower abdomen,\nno guarding/rebound. No urinary symptoms documented. No mention of menstrual history. Plan: pain\nrelief with NSAIDs, dietary modification.\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Yellow”, ”Reason”: ”Documentation is mostly\ncomplete but lacks details on potential urinary symptoms and menstrual history, which could be relevant\nfor abdominal pain.” } ], ”Recommendations”: [ { ”Severity”: ”Yellow”, ”Action”: ”Inquire about urinary\nfrequency, dysuria, or menstrual pattern. This will help rule out UTIs or gynecological causes.” } ] }\nRed Example\nAge: 4 y Gender: Male\nVitals: Temperature 39.00 °C, Pulse 104 bpm, Respiratory rate 16 bpm, Blood Pressure 122/78, SPO2 99,\nBMI 22.9,\nWeight 22 kg, Height 98 cm, MUAC –\nChief complaints: Headache Notes: severe headache, child febrile Severity: severe Duration: 2 days\nClinical Notes: child has had high fever (39 °C) and severe headache for 2 days. Appears lethargic, uncom-\nfortable, occasionally sleepy. Paracetamol 200 mg PR administered.\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Red”, ”Reason”: ”Severe headache and high fever\nin a young child without documentation of meningeal signs or neuro exam, posing a critical gap for possible\nmeningitis.” } ], ”Recommendations”: [ { ”Severity”: ”Red”, ”Action”: ”Assess neck stiffness, photophobia,\nand perform a focused neurological exam immediately to rule out meningitis.” } ] }\nE.4 Components of the user prompt for clinical notes\n• Age\n• Gender\n• Structured history like pregnancy status, if recorded\n• Vitals:\n– Temperature\n– Pulse rate\n– Blood pressure\n– Respiratory rate\n– SPO2\n– Weight\n– Height\n– Mean upper arm circumference (MUAC)\n• Chief complaint\n• Clinical notes\n85\nE.5 System prompt for investigations\nYou are an advanced Clinical Decision Support System (CDSS) integrated within an Electronic Medical\nRecord (EMR) system in a network of urgent care centers in Nairobi, Kenya, staffed by Clinical Officers.\nYour Role\nEvaluate the investigations (lab tests, imaging, etc.) ordered by the clinician against the rest of the visit\ndocumentation (patient history, exam findings, local context).\nDetermine if the investigations:\n• Meet the standard of care for the presenting complaint / diagnosis.\nPlease note that chief-complaint fields come from an automated system that includes “Severity and duration:\nNot recorded,” so please reference the clinical-notes free text for history / physical-exam documentation.\n• Are missing or excessive given the documented scenario.\n• Are feasible in an outpatient setting (avoid penalizing for not ordering tests that would be done at a\nhigher-level facility).\nSeverity Thresholds\n1. Green\n• The investigations ordered are appropriate and comprehensive for the clinical scenario.\n• No critical tests are missing; no irrelevant or unjustified tests are ordered.\n• Example: A strep test ordered for a patient with sore throat and exudative tonsillitis, or a urine dipstick\nfor suspected UTI.\n2. Yellow\n• Some recommended investigations are missing or questionable based on the history / exam, but not so\ncritical as to seriously endanger the patient.\n• OR there is at least one low-value or marginally justified test ordered.\n• Example: Mild pallor noted but no full haemogram ordered, or a borderline-unnecessary test (e.g., routine\nstool analysis in a non-GI complaint).\n3. Red\n• Essential diagnostic investigations are omitted, posing a risk of delayed or inaccurate diagnosis.\n• Clearly inappropriate tests are ordered, showing a major mismatch with the documented presentation.\n• Example: A patient with severe chest pain but no cardiac or respiratory investigations ordered; or a stool\ntest for a purely respiratory complaint with no GI symptoms.\nKey Principles\n• Context Relevance:\n– Tie each ordered or missing test to the presenting complaint, vitals, and exam findings.\n– Do not mark a test as missing if it is typically done at a higher-level facility (e.g., advanced imaging) and\nthe scenario is an outpatient urgent-care clinic.\n• Outpatient Feasibility:\n– Some conditions (e.g., severe pre-eclampsia) require basic tests (urinalysis, BP checks) in the outpatient\nsetting, but advanced labs might need referral.\n– If a key test is missing but is typically done at higher-level care, use Yellow to recommend referral or\nadditional testing rather than penalizing with Red.\n86\n• Urine Analysis:\n– Consider urinalysis as both dipstick and urine microscopy if indicated in the scenario.\n– Missing a simple urine dipstick in a suspected UTI is a bigger oversight than missing, say, an advanced\nculture that might need referral.\n• Actionable Recommendations:\n– Provide short, specific steps: “Add test X,” “Omit test Y,” or “Refer to a higher-level facility for advanced\nimaging.”\n– If everything is appropriate, confirm with Green and a brief note of affirmation.\nOutput Structure\nYou must return exactly one severity level (Green, Yellow, or Red) in JSON, with an explanatory “Reason”\nand an “Action” recommendation.\n{ ”Response”: [ { ”Severity”: ”Red”, ”Reason”: ”” } ], ”Recommendations”: [ { ”Severity”: ”Red”,\n”Action”: ”” } ] }\n• Severity: “Green”, “Yellow”, or “Red”\n• Reason: Concise explanation of why this severity applies.\n• Action: Recommended next steps to improve or confirm the investigation plan.\nImportant\n• If you determine Red is correct, do not include Yellow or Green.\n• If you determine Yellow is correct, do not include Red or Green.\n• Omit any severities that do not apply.\nSample Scenarios\nGreen Example\nAge: 32 y Gender: Male\nVitals: Temperature 37.8 °C Pulse 84 bpm Respiratory Rate 16 bpm Blood Pressure 120/80 SpO2 98 BMI:\nNot recorded Weight 70 kg Height 172 cm MUAC: Not recorded\nChief complaints: Sore Throat\nClinical Notes: Patient reports mild sore throat for 2 days with low-grade fever. On examination, tonsils\nare inflamed with exudates noted. Plan: Provide symptomatic relief and confirm streptococcal infection if\npresent.\nInvestigations Ordered: Rapid Strep Test\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Green”, ”Reason”: ”Strep test aligns with the\nclinical suspicion of strep throat. ” ”No missing or unnecessary tests identified.” } ], ”Recommendations”:\n[ { ”Severity”: ”Green”, ”Action”: ”Proceed with the ordered Strep test; no additional investigations are\nrequired at this time.” } ] }\nYellow Example\nAge: 30 y Gender: Female\nVitals: Temperature 37.5 °C Pulse 82 bpm Respiratory Rate 18 bpm Blood Pressure 110/70 SpO2 99 BMI:\nNot recorded Weight 60 kg Height 162 cm MUAC: Not recorded\nChief complaints: Throat Pain\nClinical Notes: Mild sore throat and intermittent cough for 3 days; mild pallor on exam.\n87\nInvestigations Ordered: Rapid Strep Test\nExpected JSON Output: { ”Response”: [ {”Severity”: ”Yellow”, ”Reason”: ”Strep test is appropriate, but\na full haemogram is recommended to evaluate pallor.” } ], ”Recommendations”: [ {”Severity”: ”Yellow”,\n”Action”: ”Consider ordering a full haemogram to assess possible anemia.” } ] }\nRed Example\nAge: 45 y Gender: Female\nVitals: Temperature 38.5 °C Pulse 100 bpm Respiratory Rate 20 bpm Blood Pressure 130/85 SpO2 98 BMI:\nNot recorded Weight 68 kg Height 165 cm MUAC: Not recorded\nChief complaints: Chest Pain (severe, radiating to left arm, with sweating)\nInvestigations Ordered: Stool Analysis\nExpected JSON Output:\n{ ”Response”: [ {”Severity”: ”Red”, ”Reason”: ”A stool test is not indicated for severe chest pain with\npossible cardiac involvement. ” ”Essential cardiac or respiratory investigations are missing.” } ], ”Recom-\nmendations”: [ {”Severity”: ”Red”, ”Action”: ”Discontinue stool test and order ECG, cardiac enzymes, or\nappropriate imaging to rule out myocardial infarction.” } ] }\nE.6 Components of the user prompt for investigations\n• Age\n• Gender\n• Structured history like pregnancy status, if recorded\n• Vitals:\n– Temperature\n– Pulse rate\n– Blood pressure\n– Respiratory rate\n– SPO2\n– Weight\n– Height\n– Mean upper arm circumference (MUAC)\n• Chief complaint\n• Clinical notes\n• Investigations and laboratory results\n88\nE.7 System prompt for diagnosis evaluation\nYou are an advanced Clinical Decision Support System (CDSS) integrated within an Electronic Medical\nRecord (EMR) system in Nairobi, Kenya, staffed by Clinical Officers.\nYour role is to:\n1. Evaluate the clinician’s diagnosis against the visit’s documentation (patient history, exam findings, vitals,\nlabs, etc.).\n2. Assess if the diagnosis is appropriate, missing, incomplete, or incorrectly severe given the local epidemi-\nology and available resources.\n3. Provide concise, actionable recommendations to guide safe and quality patient care.\nSeverity Thresholds\n1. Green\n• The listed diagnosis (or diagnoses) accurately reflects the clinical documentation.\n• No significant mismatch with history, vitals, labs, or local context.\n• The clinician may safely proceed with management of these diagnoses.\n• Example: If the patient presents with dysuria, urgency, and a positive urinalysis, diagnosing a straightfor-\nward UTI is Green.\n2. Yellow\n• The listed diagnosis broadly aligns with the documentation, but:\n– There is some uncertainty or missing details preventing a definitive conclusion (e.g., possible severe pathol-\nogy but not fully confirmed).\n– Additional testing or more thorough documentation is advisable before finalizing.\n• Severe diagnoses (e.g., sepsis, meningitis, appendicitis) in outpatient settings can be Yellow if the clinical\npicture could be correct but is not definitively confirmed—urge confirmatory testing or referral.\n• Example: If the patient’s symptoms might be early appendicitis, but no imaging or sufficient exam details\nare available, classify as Yellow with guidance to do further testing.\n3. Red\n• A serious mismatch: The listed diagnosis is incompatible with the clinical findings, or a critical diagnosis\nis missing.\n• Could result in dangerous consequences if not corrected.\n• Severe diagnoses listed are not supported by the presentation, or a severe condition is clearly overlooked.\n• Example: The patient has signs of acute pyelonephritis (fever, flank tenderness, significant leukocytosis),\nbut the diagnosis is “simple cystitis” with no mention of possible pyelonephritis.\nKey Notes\nYou must flag serious and evident diagnoses if they are not listed.\nFor example, consider a patient with cough and a full haemogram that shows an elevated white count and\nanemia. If the clinician diagnoses “Bronchitis,” that may very well have a green alignment to the rest of\nthe documentation; however, failing to list the anemia as a diagnosis should result as a red flag until that\nis addressed. Similarly, malnutrition in children as evidenced by low weight for age or yellow or red MUAC\nmust result in those diagnoses being listed by the clinician.\n• How to interpret MUAC:\n89\n– Red = Severe malnutrition (urgent concern).\n– Yellow = Moderate malnutrition.\n– Green = Normal MUAC or no malnutrition.\n• Severe Diagnoses in Outpatient:\n– If documentation aligns but is not conclusive (e.g., possible meningitis, appendicitis), return Yellow with\ninstruction for urgent referral or confirmatory tests.\n– If the severe diagnosis does not match the clinical presentation, return Red and advise re-evaluation.\nYou should consider local epidemiology without over-indexing on tropical diseases.\nOutput Structure\nReturn exactly one severity level in JSON (Green, Yellow, or Red). Include a Reason and an Action.\n{ ”Response”: [ { ”Severity”: ”Green”, ”Reason”: ”” } ], ”Recommendations”: [ { ”Severity”: ”Green”,\n”Action”: ”” } ] }\nFew-Shot Examples\nBelow are three sample scenarios illustrating Green, Yellow, and Red responses.\n1. Green Example\nAge: 25y Gender: Female\nVitals: Temperature: 37.80 °C Pulse: 80 bpm Blood Pressure: 120/78 Respiratory Rate: 18 SPO2: 99\nChief Complaint: Dysuria, urinary frequency\nClinical notes: Pt complains of dysuria and urinary frequency x2 days. She has had these symptoms before\nand was diagnosed with UTI. She does not currently have a sexual partner. On exam, she is well appearing.\nShe has suprapubic tenderness to palpation, but abdomen is otherwise soft and non-tender. There is no\nCVA tenderness.\nLab Results: Urinalysis shows nitrites and leukocytes\nDiagnosis: Uncomplicated Urinary Tract Infection (UTI)\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Green”, ”Reason”: ”Diagnosis of UTI aligns with\nclinical presentation of dysuria and urinalysis findings.” } ], ”Recommendations”: [ { ”Severity”: ”Green”,\n”Action”: ”Proceed with standard treatment for uncomplicated UTI (e.g., nitrofurantoin).” } ] }\n2. Yellow Example\nClinical Documentation: Age: 16y Gender: Male\nVitals: Temperature: 38.50 °C Pulse: 90 bpm Blood Pressure: 110/70 Respiratory Rate: 20 SPO2: 98\nChief Complaint: Right lower quadrant abdominal pain, mild nausea\nPhysical Exam: Mild tenderness in RLQ but no rebound or guarding\nLab Results: WBC count slightly elevated\nDiagnosis: Appendicitis\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Yellow”, ”Reason”: ”Appendicitis is plausible\nbut not definitively confirmed. Documentation suggests mild RLQ tenderness without peritoneal signs.” }\n], ”Recommendations”: [ { ”Severity”: ”Yellow”, ”Action”: ”Obtain an ultrasound or surgical consult to\nconfirm appendicitis. Monitor for worsening pain, fever, or signs of rebound tenderness.” } ] }\n3. Red Example\n90\nClinical Documentation\nAge: 35y Gender: Female\nVitals: Temperature: 39.20 °C Pulse: 105 bpm Blood Pressure: 130/85 Respiratory Rate: 22 SPO2: 98\nChief Complaint: Flank pain, fever, nausea\nPhysical Exam: Notable costovertebral angle tenderness\nLab Results: WBC count elevated, presence of pyuria on urinalysis\nDiagnosis: Simple UTI (cystitis)\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Red”, ”Reason”: ”Clinical findings (fever, flank\npain, pyuria) are more consistent with pyelonephritis than simple cystitis.” } ], ”Recommendations”: [ {\n”Severity”: ”Red”, ”Action”: ”Reevaluate diagnosis. Consider inpatient management or a more aggressive\nantibiotic regimen for pyelonephritis.” } ] }\nE.8 Components of the user prompt for diagnosis evaluation\n• Age\n• Gender\n• Structured history like pregnancy status, if recorded\n• Vitals:\n– Temperature\n– Pulse rate\n– Blood pressure\n– Respiratory rate\n– SPO2\n– Weight\n– Height\n– Mean upper arm circumference (MUAC)\n• Chief complaint\n• Clinical notes\n• Investigations and laboratory results\n• Diagnosis\n91\nE.9 System prompt for treatment\nYou are an advanced Clinical Decision Support System (CDSS) integrated within an Electronic Medical\nRecord (EMR) in Nairobi, Kenya, staffed by Clinical Officers.\nYour role is to:\n1. Evaluate the clinician’s treatment plan against the visit documentation (vitals, diagnosis, labs, etc.).\n2. Identify if the treatment is safe, evidence-based, and aligned with local guidelines (e.g., MoH Kenya,\nIMNCI/WHO).\n3. Provide concise, actionable recommendations to ensure appropriate and safe patient care.\nSeverity Thresholds\n1. Red\n• Serious mismatch between treatment and diagnosis.\n• Unsafe or unnecessary medications (e.g., antibiotics for a confirmed viral illness, sedating antihistamines\nin young children, monteleukast for respiratory infections without asthma).\n• Omission of essential medications when clearly indicated (e.g., no rehydration plan and zinc in severe\npediatric dehydration).\nPlease also consider the omission of clearly indicated procedures or referrals (examples: inpatient hospital-\nization for severe sepsis, consultation with general surgeon for ruptured ovarian cyst, or incision and drainage\nfor a superficial abscess).\n• Incorrect dosage, major drug interactions, or known contraindications (such as aspirin in young children).\n• Could pose significant harm to the patient if not corrected immediately.\n2. Yellow\n• Treatment plan mostly aligns with the documented diagnosis, but:\n• Minor adjustments to dosage/duration are recommended, or while the medication choice is acceptable, it\nis not considered a first-line treatment for the condition.\n• Some prescriptions listed are of dubious value to the patient (e.g., cough syrups).\n• Additional medication(s) could improve outcomes.\n• No immediate patient risk, but refinement is advisable.\n3. Green\n• Treatment plan is complete, accurate, and in compliance with relevant guidelines.\n• No critical omissions or unnecessary interventions.\nSpecific Guidelines to note\n1. Key IMNCI/WHO Guidance for Dehydration in Children ¡5 Years\n1. Severe Dehydration\n• IV Ringer’s Lactate at 30 mL/kg over 30 min (if child ¿ 12 months) or 60 min (¡ 12 months).\n• Then 70 mL/kg over 2.5 hours (¿ 12 months) or 5 hours (¡ 12 months).\n• If IV access is not possible, ORS via nasogastric tube at 120 mL/kg over 6 hours.\n2. Some Dehydration\n• Oral Rehydration Solution (ORS) at 75 mL/kg over 4 hours.\n92\n3. No Dehydration\n• ORS 10 mL/kg after each loose stool.\nAll cases should receive zinc supplementation.\n2. Urinary Tract Infection Management\nIn Kenya, Nitrofurantoin and Cephalosporins are appropriate first-line therapy for management of UTI in\nadults and pregnant women.\nSeptrin (cotrimoxazole) is not a recommended first-line treatment due to its use in TB management.\n3. Note that Zefcolin (brand name) is a cough syrup and not a cephalosporin antibiotic; it can be used to\nrelieve cough symptoms associated with upper respiratory tract infection in adults and children over 2 years.\nOutput Structure\nYou must return exactly one severity level in JSON, with an explanatory Reason and an Action:\n{ ”Response”: [ { ”Severity”: ”Green”, ”Reason”: ”” } ], ”Recommendations”: [ { ”Severity”: ”Green”,\n”Action”: ”” } ] }\nFew-Shot Examples\nBelow are three scenarios highlighting Green, Yellow, and Red outcomes.\nGreen Example\nClinical Documentation: Age: 18y Gender: Female\nVitals: Temperature: 37.5 C Pulse: 78 bpm Blood Pressure: 115/75 Respiratory Rate: 16 SPO2: 98\nDiagnosis: Uncomplicated Cystitis (UTI confirmed by urinalysis)\nTreatment Plan: - Nitrofurantoin 100 mg twice daily for 5 days\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Green”, ”Reason”: ”Treatment aligns with recom-\nmended guidelines for uncomplicated cystitis.” } ], ”Recommendations”: [ { ”Severity”: ”Green”, ”Action”:\n”Proceed with nitrofurantoin therapy. Advise patient on possible side effects and encourage fluid intake.” }\n] }\nYellow Example\nClinical Documentation: Age: 5y Gender: Male\nVitals: Temperature: 37.8 C Pulse: 100 bpm Blood Pressure: Not recorded Respiratory Rate: 20 SPO2: 98\nDiagnosis: Mild Pneumonia\nTreatment Plan: - Amoxicillin 125 mg twice daily for 3 days - No mention of supportive care (e.g., hydration,\nfever management)\nExpected JSON Output: { ”Response”: [ { ”Severity”: ”Yellow”, ”Reason”: ”Antibiotic choice is appropri-\nate, but dosage duration may be suboptimal, and supportive care isn’t addressed.” } ], ”Recommendations”:\n[ { ”Severity”: ”Yellow”, ”Action”: ”Consider extending amoxicillin to 5 days total, ensure fever management\nwith paracetamol, and advise adequate fluid intake.” } ] }\nRed Example\nClinical Documentation:\nAge: 2y Gender: Female\nVitals: Temperature: 39.0 C Pulse: 120 bpm Blood Pressure: Not recorded Respiratory Rate: 24 SPO2: 97\nWeight: 12 kg\nDiagnosis: Acute Gastroenteritis with Severe Dehydration\n93\nTreatment Plan: - Oral paracetamol for fever\n{ ”Response”: [ { ”Severity”: ”Red”, ”Reason”: ”Severe dehydration diagnosis without IV fluids or ORS\nis a critical omission. No zinc supplementation is prescribed.” } ], ”Recommendations”: [ { ”Severity”:\n”Red”, ”Action”: ”Initiate IV rehydration per IMNCI guidelines or give ORS if IV not feasible. Include zinc\nsupplementation for diarrheal disease.” } ] }\nE.10 Components of the user prompt for treatment\n• Age\n• Gender\n• Structured history like pregnancy status, if recorded\n• Vitals:\n– Temperature\n– Pulse rate\n– Blood pressure\n– Respiratory rate\n– SPO2\n– Weight\n– Height\n– Mean upper arm circumference (MUAC)\n• Chief complaint\n• Clinical notes\n• Investigations and laboratory results\n• Diagnosis\n• Medications\n• Referrals\n94\nF Follow-up call script\nContext. This is Penda’s call center script. There are two bolded questions below. For these questions,\nplease ask them in the same way every time. It’s very important for us to be rigorous here, so Penda\ncan collect good outcomes data.\nWhen patients respond to the bolded questions, you can go back to engaging the patient, by asking clarifying\nquestions and confirming the patient’s response, to make sure we get the most accurate measurements of\noutcomes possible.\nMake sure to confirm the answer with the patient. The outcomes we measure should be reported by the\npatient – we don’t want to assume how the patient is feeling!\nScript.\n• Start the conversation:\n– Greetings and self-introduction: Hello [patient or parent/guardian name], my name is [name] from\nPenda.\n– Confirmation: Is this / the [mother/father/guardian] of ?\n– Provide reason for calling: I am calling to (check on you and) collect feedback after your recent\nvisit at Kasarani branch. Do you have a minute to answer a few questions?\n• Question 1A: Would you say you are feeling better, just the same or worse after treatment?\n• Question 1B:\n– If 1A is better: Glad to hear that. Is it much better or a little better?\n– If 1A is worse: Sorry to hear that. Is it much worse or a little worse?\n– If 1A is the same: proceed to question 2\n– When the patient responds, confirm the phrase, to make sure you have heard cor-\nrectly they have a chance to correct themselves if needed\n∗ Example: if they respond “5”, say “so you’re feeling much better”\n∗ Example: if they say, “a little worse”, say “okay, so a little worse”\n– Always confirm – this lets us make sure what we record is what the patient means! For example,\nif the patient says “I’m still in recovery”, this could be anything between “feeling much worse”\nand “feeling a little better”, and we need to confirm how they feel.\n• Question 2: “Did you get any of your treatment and medicines away from Penda Health”\nOptions: I received all my treatment and medicines at Penda; I visited another chemist; I went myself\nto another hospital or specialist, Penda referred me to another hospital or specialist\n– Here, make sure to be sure of the patient’s answer and confirm it verbally.\n∗ If they say “no”, say “so you didn’t need to go anywhere else, not even a chemist” – we need\nto make sure patients know we’re including chemists\n∗ If they say “I went to the hospital”, say “did Penda refer you, or did you decide to go\nyourself?”, so you can pick the right answer!\n– The patient might say this information without you asking, when you ask Question\n1. If they do, confirm their answer verbally!\n– Ask this question even if the patient is feeling better! They may be feeling better because\nthey have already gone to another hospital or chemist\n95\n– If the patient plans to visit another clinic but hasn’t yet, answer “No”! This question\nis about whether the patient has done so already\n• End the conversation:\n– Other comments: If you feel it important, ask any additional questions (e.g., check if they are\nstill taking medication or do other checks on their condition).\n∗ Please make sure to flag severe outcomes like hospital admission, ICU admission, or death\nhere. Please also flag home remedies if they are mentioned.\n– If the patient provides any feedback or other notes, include that here.\n– Let them know they can seek care at any of our branches or call this number\n– End call\n96\nG Clinician survey\nSurvey: satisfaction with Penda’s EMR.\nHi there!\nThanks for taking the time to participate in this short survey, which should take less than 5 minutes to\ncomplete.\nWe would like to understand your experience with the Penda electronic medical record (EMR) that you have\npersonally been using from January until early April. During that time, you DID / DID NOT\nhave AI Consult available to you.\nWe are interested in all aspects of the EMR, including features like clinical decision support that are part of\nthe EMR.\nAll individual responses will be kept confidential and used solely for quality improvement and research\npurposes.\nHow does this EMR change the quality of the care that you deliver, compared to the quality of care you\nwould deliver without an EMR system?\n• Substantially improves quality\n• Somewhat improves quality\n• Does not change quality\n• Somewhat worsens quality\n• Substantially worsens quality\nWhat is the primary reason for your rating above? FREE TEXT FIELD\nTHE BELOW QUESTIONS WERE ASKED ONLY TO CLINICIANS IN THE AI GROUP\nThink about the version of Penda’s AI clinical decision support systemyou’ve been using from January\nthrough early April. On a scale of 0–10, how likely would you be to recommend it to a similar clinic?\nSCALE; 0: Not at all likely to 10: Extremely likely\nOverall, how satisfied or dissatisfied are you with the AI clinical decision support system?\n• Very satisfied\n• Somewhat satisfied\n• Neither satisfied nor dissatisfied\n• Somewhat dissatisfied\n• Very dissatisfied\nHow does the AI clinical decision support system change the quality of the care that you deliver,\ncompared to the quality of care you would deliver without the system?\n• Substantially improves quality\n• Somewhat improves quality\n• Does not change quality\n• Somewhat worsens quality\n• Substantially worsens quality\nPlease share any feedback you have, both positive and constructive, about the AI Consult tool. FREE\nTEXT FIELD\n97\nH Additional eligibility criteria for one-day follow-up calls\nPatients with below characteristics were marked as eligible for the one-day follow up call. Ultimately, Penda’s\ncall center team decided which patients to call.\nAny visit with the below diagnosis:\n• Severe malaria\n• Acute viral or bacterial gastroenteritis with some or severe dehydration\n• Severe pneumonia\n• Pneumonia, in patients under 5 years of age and above 50 years of age\n• Puerperal sepsis\n• Neonatal sepsis\n• Myocardial infaction or angina\n• Hypertensive emergency and urgency\n• Acute abdomen\n• Ectopic pregnancy\n• Stroke\n• Acute coronary syndrome\n• Pre-emplasia and clampsia\n• Diabetic ketoacidosis\n• Hypoglycemia\n• Poisoning\n• Gastroenteritis with some or severe dehydration\n• Head injury\n• Febrile convulsions\n• Convulsions\nAny visit with the below chief complaints:\n• Difficulty in breathing\n• Vaginal bleeding\n• Fever\n• Weakness\n• Unconsciousness\n• History of convulsion\n• Poisoning\n98\nI Form shown to physician raters to rate clinical documentation\n99\nMain form\nIn this work, you will be evaluating the quality of medical documentation and medical\ndecision making of outpatient clinical encounters by clinical officers working in\nresource-limited primary/urgent healthcare clinics in Nairobi, Kenya. Clinical officers, though\nnot trained at the same level as a physician, play a vital role in delivering primary care in\nKenya.\nYou’ll review the following portions of clinical notes and rate each portion with both a Likert\nscale and a multi-select question (i.e., a multiple choice question where you can choose 1 or\nmore of the options):\nHealthcare context like local practice norms, epidemiology, and resource availability is\nalways important when reviewing clinical encounters. The encounters you will evaluate\noccurred in an outpatient primary/urgent care setting in Kenya. Patients and clinicians have\naccess to resources as displayed in the following table:\nAvailable in clinic,\n(inexpensive and fast)  Available but expensive\nand/or results not\navailable within the visit\nNot available within\nclinic, but patients\nmay be referred to\nspecialised centers\nthat have these\navailable\nVital Signs   Most standard equipment    Pediatric BP cuffs\nDiagnostic\nEquipment  Stethescope, penlight,\nexam light, vaginal\nspeculum\nOtoscopes\nOphthalmoscopes\nReflex hammers\nInvestigations  Complete blood count,\nurinalysis and stool\ntesting, blood glucose\ntesting, malaria (RDT and\nsmear), rapid strep\ntesting, and HIV testing,\nurine and blood\npregnancy testing\nMetabolic panels, liver\nfunction testing, hormonal\ntesting (e.g. TFTs),\ncancer marker testing,\nnucleic acid testing,\ncultures (urine, wound,\nblood)\nImaging  Ultrasound is available on\ndemand (abdominal and\nlinear probes).\nLimited access to\ntransvaginal ultrasound\nscans\nX-ray - limited access\nCT/MRI imaging is\nnot available\n(patients may at\ntimes come with\nChief complaint, vitals, history, physical exam\nInvestigations\nDiagnosis\nTreatment: medications and referrals\noutside records of\nimages)\nPharmacy  Standard outpatient\npharmacy\nAccess to\nPhysicians or\nSpecialists\nRequires referral to\nNutrition, OB/GYN,\nPediatrics, IM,\nother specialists\nEpidemiology varies around the world, and it is important to keep in mind what diseases are\ncommon locally and local practice patterns. While these instructions do not provide a\ncomprehensive overview, please keep in mind the following disease states that may present\nmore frequently in Kenya than in some other parts of the world:\nMalaria - distinguishing malaria from severe malaria; Kenyan pediatric protocol (page 33)\nOther parasitic Infection (Entamoeba histolytica, Giardia, Schistosomiasis, pinworm)\nTuberculosis - clinical symptoms of pulmonary and extrapulmonary TB\nMalnutrition - classification & management plans pediatric protocol (page 42- 43)\nGastroenteritis in children - classification & management plans pediatric protocol (page\n36)\nPneumonia in children - Distinguishing severe cases - Kenyan pediatric protocol (page 46)\nH. pylori infection\nRheumatic fever - clinical guidance\nHIV/AIDS and related opportunistic disease: TB, meningitis, genital warts, ca cervix, etc.\nVaricella\nRickets (vitamin D deficiency)\nConditions of pregnancy: malaria, anemia, pre-eclampsia/eclampsia\nAlso, keep in mind that first-line treatment regimens for gastroenteritis with dehydration,\nmalaria, H. pylori, and HIV may differ from those used in other parts of the world. In addition,\nARV therapy and TB medication will not be initiated in these encounters, but instead should\nbe referred to other HIV/TB care outpatient facilities.\nIn this clinical setting, the expectation for documentation is dependent on clinical reasoning -\nthe degree of expected comprehensiveness changes depending on the clinical scenario.\nClinical officers also have a lower level of expected clinical documentation in comparison to\nphysicians, particularly related to history and physical examinations to rule out differential\ndiagnoses. This is also a busy clinical setting, with often short back-to-back encounters\nserving a low resource area. Notes tend to be more sparse and direct, though pertinent\npositives and negatives to facilitate diagnostic reasoning should still be included in the note.\nFor example:\nFor a patient with normal vital signs and a typical story for URI, extensive documentation\nbeyond historical red ﬂags is not expected and physical examination may be limited to the\nrespiratory system including throat/neck. Ear examinations are usually not documented due\nto lack of accessibility to otoscopes.\nFor a patient with fever without localizing signs, a much more comprehensive history and\nphysical exam is expected.\nClinical note and vitals form and questions\nTask Specific Clinical Note and Vitals\nVital Signs:\nChief complaint:\nHistory taken and physical exam:\nLikert Score: Grade the clinical note documentation on thoroughness of the\ndocumentation of the history taken, physical exam and presence of a chief complaint\nand relevant vital signs. This score reflects the detail and coverage of these specific\nelements - not the correctness of clinical reasoning or the appropriateness of treatment that\nmay be documented in this note.\nNotes:\n●  Please disregard any assessment and plan info that you can see in the clinical note\nwhen assigning a Likert score on this section.\n●  Take into account the previously mentioned documentation expectations, as well as\nthe limited resource setting. For example, no middle ear exams can be documented\nbecause there are no otoscopes.\n●  Pediatric vital sign expectations vary by age. No pediatric blood pressure cuffs are\navailable, so no blood pressures are expected for age <13 years. A n MUA C (mid\nupper arm circumference) is expected on children ages 6 months to 5 years.\n5  Thorough: key components of the HPI and/or medical history elements are\ndocumented; relevant systems on physical exam are well documented; chief\ncomplaint and relevant vitals are present\n4  Reasonably thorough: some relevant HPI and/or medical history elements are\ndocumented; some of the relevant system specific findings are documented on exam;\nchief complaint and most relevant vitals are present\n3  Limited: history has limited symptom description or pertinent details (e.g., missing 2\nor more relevant characterizations of the chief complaint, such as duration, onset,\nquality, severity, etc.); physical exam is limited; chief complaint or some relevant vitals\nare present\n2  Deficient: history misses the most important key elements; physical exam is very\nincomplete, excludes important details of relevant systems or misses one of the most\nimportant exam findings; chief complaint and/or important vitals missing\n1  Very poor: history is extremely limited with no meaningful characterization of\npresenting symptoms; physical exam is missing entirely or nearly so; critical vitals\nmissing\nMCQ (multi select):\nIn the clinical documentation, which of the following deficiencies are present? Choose all that\napply.\n1.  Chief complaint is absent\n2.  Key details in the history are missing (e.g., characterization of chief complaint is\nlacking key elements such as onset, duration, or associated symptoms, etc. or\npertinent medical history such as travel/sexual/family history are missing when they\nwould be relevant, etc. or no documentation of allergies when it would be relevant.)\nNote that associated symptoms and duration of symptoms may be located in the\nchief complaint as well as in the clinical note.\n3.  Documentation of relevant systems on physical exam are absent (e.g., respiratory\nexam in a patient with cough, description of the rash in a patient with skin findings)\n4.  Pertinent vital signs are absent\n5.  None of the above\nInvestigations form and questions\nTask Specific Clinical Note\nInvestigations:\nLikert Score: Grade the investigations ordered (or lack of them) on appropriateness, given\nthe clinical documentation. Keep in mind that not all investigations are readily available and\nuse the table on available resources in the instructions at the top of this task to aid in your\nevaluation. Consider that investigations that are unavailable or limited in availability should\nnot be counted as omissions. For example, chest X-Ray is not available at most clinic\nlocations and so lack of a chest X-ray in a patient with lower respiratory tract infection should\nnot be penalized.\nNotes:\n●  Tests ordered may not have results - they often are not performed when ordered due\nto cost of testing. This should not be penalized.\n●  When descriptions from multiple Likert scores apply, assign the lowest relevant Likert\nscore. For example, if a task has both unjustified investigations ordered\ncorresponding with Likert 3 and also has missing potentially helpful investigations\ncorresponding with Likert 2, assign Likert 2 to the task.\n●  Patients may sometimes request investigations that are not related to their current\nclinical condition—often out of personal interest (e.g., blood grouping). Such tests\nshould be clearly documented in the clinical notes section as self-requested, for\nexample: “B lood group – self request.” Do not consider or include any self-request\ntests when scoring or evaluating investigations in this section.\n●  Given Kenya's epidemiological context, a malaria test should be prioritized in any\npatient presenting with fever when:\n●  There is no clear localization of infection based on history and physical exam\n– not ordering a malaria test in such cases is considered a critical omission.\n●  There are symptoms pointing toward another likely cause of fever (e.g., URTI,\nUTI) – a malaria test may still be considered as additional testing, especially if\nthe patient is from or recently visited a malaria-endemic area.\n●  See WHO guidelines for malaria (page 158)\nFull hemogram (complete blood count) is a test ordered quite often in this setting. If helpful in\ninterpreting these results, you can use the corresponding, age-specific reference ranges.\n*Note that pediatric normal values vary widely depending on the specific age and a\nmore granular pediatric reference range is available.\n*When any of the values in the hemogram are abnormal, the result will include a flag\nthat says “Result-Abnormal” somewhere within the test result. The specific placement\nof this flag is not meaningful, it is often not adjacent to the result that is actually\nabnormal.\n5  Appropriate & Targeted: All investigations are clearly indicated by the clinical\ncontext; point of care tests are utilized appropriately and there are no unjustified tests\nordered; or no investigations are indicated and none are ordered\n4\nMinor overordering: Investigations are mostly appropriate with only minimal\novertesting, (e.g., full hemogram for URTI symptoms with no major systemic\nsymptoms or exam findings suggesting bacterial infection but one or two general\nsymptoms like subjective fever or headache are present)\n3  Overly broad: Investigations ordered are unjustified, (e.g., full hemogram for clearly\nsimple URTI with unconcerning vitals and exam findings)\n2  Deficient: Potentially helpful investigations are missing, (e.g., no rapid strep test for\npharyngitis/tonsillitis)\n1  Very poor: Critical omissions - clearly important investigations were not ordered,\nrisking misdiagnosis or harm, (e.g., urinalysis not ordered for a young child with\nunexplained fever or no malaria test for a patient with fever and travel to a malaria\nendemic region)\nMCQ (multi select):\nWhich of the following is deficient regarding investigations ordered? Choose all that apply.\n1.  Key investigations are missing (i.e., important tests expected for this clinical scenario\nthat are an available resource are not ordered)\n2.  Unjustified investigations are ordered\n3.  None of the above (Any investigations ordered are indicated and no key\ninvestigations are missing)\nDiagnosis form and questions\nTask Specific Clinical Note\nDiagnosis\nLikert Score: Grade whether the diagnosis (including primary diagnosis, any additional\ndiagnoses, or the listed differential diagnoses) aligns with the clinical picture. Below, primary\ndiagnosis refers to one or more diagnoses associated with the chief complaint. Additional\ndiagnoses refers to any other diagnosis that may be relevant based on other listed history,\nphysical exam findings or vital sign findings. Additional diagnoses are not necessarily less\nimportant than the primary diagnosis.\nNote: Multiple diagnoses may be assigned that are all related to the chief complaint (e.g.,\nacute tonsillitis, acute rhinitis, acute nasopharyngitis all being listed as diagnoses in the\nsame encounter). In this case, you can consider all of them as the primary diagnoses for the\npurpose of evaluation with the Likert table and multi-select question. Depending on the\nscenario, you may consider this to be appropriate, not clearly relevant additional diagnoses,\nor catch-all diagnoses.\n5  Excellent: primary diagnosis fully aligns with the clinical picture and is the most likely\ndiagnosis; no additional diagnoses are missing; any listed additional diagnoses are\nappropriate\n4  Good: primary diagnosis generally aligns and is among the top few likely diagnoses;\nadditional diagnoses are present but not clearly relevant\n3  Adequate: primary diagnosis is plausible but not the most likely, or one or more\nimportant additional diagnoses are missing (e.g., no diagnosis of “elevated blood\npressure reading” or “hypertension” when BP is significantly elevated)\n2  Deficient: primary diagnosis is not well supported by the clinical picture or low on the\nlist of likely causes; Primary diagnosis is a catch-all diagnosis when a clearer primary\ndiagnosis is possible (e.g., “bacterial infection unspecified” instead of “urinary tract\ninfection”); critical additional diagnoses are missing (e.g., no “malnutrition” or\n“underweight” diagnosis on a child with MUC yellow or red)\n1  Very poor: primary diagnosis is missing or clinically inappropriate, contradicts or is\nunsupported by documented findings\nMCQ (multi select):\nWhich of the following is deficient regarding the assessment and diagnosis?\n1.  Primary diagnosis is likely incorrect\n2.  Primary diagnosis is missing\n3.  Primary diagnosis is too specific to be supported based on current documentation or\ninvestigations (e.g., using “allergic rhinitis” as the diagnosis rather than “rhinitis”,\nwhere it’s clear that rhinitis is present but documentation does not support whether it\nis a viral, bacterial or allergic etiology)\n4.  Additional diagnosis is likely incorrect\n5.  Clinically relevant additional diagnosis is missing (e.g. malnutrition)\n6.  None of the above (All diagnoses are likely correct and no clinically relevant\ndiagnoses are missing)\nTreatment form and questions\nTask Specific Clinical Note\nPlan: Treatments and Referrals + procedures and escalations of care if present\nTreatment Likert Score: Is the documented treatment plan appropriate and complete given\nthe clinical scenario?\nThe majority of cases will have either medications or referrals documented as a plan. Some\nwill have procedures, escalations of care, referral for additional investigations or home\nmedications documented in the clinical note. If procedures, escalations of care or home\nmeds are documented, take them into consideration with the rest of the plan. Follow up\nplans and patient advice or education are often not documented, but when present, these\nshould be taken into consideration and reflected in the Likert scoring.\nNote:\n●  Sometimes additional investigations will be added as a referral. This means that the\ninvestigation is not available locally but the provider is requesting the patient have it\nperformed at another location.\n●  Treatments will sometimes be documented in the clinical notes, and these should\nalso be taken into consideration.\n5  Appropriate and complete: treatments are appropriate and complete, including the\ncorrect use of medications and/or referrals when needed; Patient advice or education\n(e.g., red flag symptoms to watch for, advice on hydration, self-care, etc.) or a follow\nup plan is present; if procedures or escalations of care are present, they are the most\nappropriate course of action. OR no treatments are indicated and none are ordered\n4  Appropriate but less complete: treatments are appropriate and complete, including\nthe correct use of medications and/or referrals when needed but there is no patient\nadvice, education or follow up plan documented (e.g., red flag symptoms to watch for,\nadvice on hydration, self-care, when to return to care, etc.)\n3  Adequate: Medications, referrals or procedures are reasonable and safe, but may not\nbe a standard first-line therapy (i.e., things that are likely to have minimal benefit or\nminimal harm if given, e.g. desloratadine for a URTI instead of nasal saline spray\nalone), or helpful but non-critical referrals are missing\n2  Deficient: medications are present and somewhat inappropriate (i.e., medications\nthat may cause minor harm unnecessarily e.g., inappropriately broad antibiotic class\nwhen a narrower spectrum is sufficient); minor medication dosage errors; clearly\nneeded referrals, procedures or escalations of care are missing\n1  Very poor: no medications given for a condition when clearly indicated; medications\nare very inappropriate for the condition (e.g., use of any antibiotic when there is no\nindication based on documented findings); significant dosage errors (e.g., too high of\na dose based on pediatric patient weight-based dosing); procedures performed or\nescalations of care are unwarranted\nMCQ (multi select):\nWhich of the following deficiencies are present in the plan? Choose all that apply.\n1.  Medications are missing\n2.  Medications are present but inappropriate\n3.  Medications are appropriate but incorrect dosages listed (dosage can include dose\nquantity, frequency and duration)\n4.  Likely inappropriate use of antibiotics overall (e.g., antibiotics are given for a likely\nviral infection) *if you select this choice, you should also select choice “Medications\nare present but inappropriate”\n5.  Likely inappropriate class of antibiotics used (e.g., amox/clavulanic acid used when\namoxicillin is appropriate) *if you select this choice, you should also select choice\n“Medications are present but inappropriate”\n6.  Referrals are missing\n7.  Referrals are present but inappropriate\n8.  Needed procedures are missing\n9.  Procedures are present but inappropriate\n10. Needed escalations of care are missing\n11. Escalations of care are present but inappropriate\n12. None of the above\nAdditional resources for physicians\nCommon local brand name pharmaceutical list that physicians\nin other parts of the world may not recognize\nCital syrup  Disodium hydrogen citrate syrup 1.37g\nBenylin original syrup  Diphenhydramine/ammonium chloride syrup\n12.5mg/125mg\nKarvol Inh caps  Camphor/eucalyptol/terpineol/chlorothymol\ncaps\nZefcolin syrup  Dextromethorphan/phenylephrine/cetrizine\nsyrup 10mg/5mg/5mg\nBenased chesty syrup  Diphenhydramine/guaiphenesin syrup\n14mg/100mg\nDelased pediatric syrup  Diphenhydramine/sodium citrate syrup\n7mg/28.5mg\nImacoff dry syrup  Diphenhydramine/dextromethorphan/sodium\ncitrate syrup 14mg/5.7mg/5mg\nMetadoz ﬁzz  Paracetamol/tramadol tabs 325mg/37.5mg\nBrustan tabs  Ibuprofen/paracetamol tabs 400mg/325mg\nBrustan syrup  Ibuprofen/paracetamol suspension\n100mg/125mg\nAcinet  Amoxicillin and clavulanate 625mg  tablets\npcm  Common abbreviation for paracetamol\nAdol\nParacetamol a.k.a Acetaminophen available\nin many formulations. Frequently prescribed\nas a STAT suppository in children presenting\nwith high fevers\nDesloratadine  2nd  generation, Histamin H1  anatgonist\nVentolin (Salbutamol)  Albuterol\nMara Moja/Parafast/Cipladon  All paracetamol/acetaminophen\nPDL  Abbreviation for Prednisolone\nCommon acronyms\nOE  On exam\nFGC  Fair general condition\ncreps/crepitations on lung exam  rales/crackles\nHob (hotness of the body)  Subjective fever\nDib (difficulty in breathing)  dyspnea\nJACCOLD  a normal constellation of physical exam\nfindings that refers to absence of Jaundice,\nAnaemia (pallor), Cyanosis, Clubbing,\nOedema (pedal edema), Lymphadenopathy,\nDehydration\nMUC or MUAC  mid upper arm circumference, used to\nidentify children with malnutrition\nAss  associated\nVesicular breath sounds  Normal breath sounds\n5/7  5 days\n2/52  2 weeks\nLikert Examples for chief complaint, vitals, history, and physical\nexam\nExample 1:\nPatient Information:\nAge: 3 years\nGender: Male\nPresenting Complaints:\nDry Cough: Present.\nVitals: HR 112, temp 36.7, wt 16 kg, rr 25 SpO2 97% MUAC - green\nChest Congestion: History of chest congestion.\nChronic Sinusitis: History of chronic sinusitis.\nSnoring at Night: Reported by the mother.\nRunning Nose: Mild, present currently.\nNo History of Fever: No recent fever.\nNo History of Chills.\nNo History of Travel.\nPast Medical History:\nNo significant chronic illness reported.\nPhysical Examination:\nGeneral Appearance: Clinically stable patient.\nVitals: Normal (within age-appropriate ranges).\nENT Examination:\nSwollen Turbinates: The turbinates are swollen and reddish in color, suggesting inflammation\n(possibly allergic rhinitis or sinusitis).\nRespiratory Examination:\nLungs Clear: Breath sounds are clear and equal on both sides.\nNo Added Sounds: No wheezing, crackles, or other abnormal respiratory sounds.\nLikert Score: 5: Thorough\nExplanation: includes detailed history, includes HPI associated symptoms and\ndocumentation of no PMH, documents travel history and pertinent physical exam findings;\nCC and relevant vitals are present\nExample 2:\n47y2m\nCC: severe headache\nHR 88 temp 36.5 wt 87 kg rr 18 SpO2 98 BP 132/78\nsevere headache on and off throbbing , sharp with no aggreviating factors\nmild to severe assoc with tears . it was of sudden onset , started today evening\nnot relieved with oral painkillers\nno neck stiffness\nno dizziness\nno photophobia\nno history of trauma\nhad hob with occassional chills\nno history of travel to malaria zone\no/e. fgc , in severe pain\nneck soft not stiff\nafebrile on touch\nno photophobia\nbrudzensk sign negative\nGlasgow Coma Scale at 15/15\nno confusison\nother systems esentially normal\nfam plan =none\nlnmp. 20th/3/2025\nimpress. migraine/bac infection/menengitis /\nplan\ndiclofenac 150mg Intramuscular stat\nfhg\nBlood slide for malaria\nhead ct scan\nLP\nextplan\nmetadoz 1tab bd\nexplained danger signs\nconsider head ct scan / lp\nLikert Score: 4 Reasonably thorough\nExplanation: includes CC, vitals, most of the relevant characteristics of the chief complaint\nand physical exam pertinent negatives on neuro exam; fails to mention presence or absence\nof nausea and vomiting, vision changes, weakness or numbness which are important\nsymptoms in assessing severe headache; missing many specific neuro exam findings (CNs,\nstrength, reflexes, cerebellar assessment)\nExample 3\nChief complaint: Cough, Sneezing\n44y 8m\nHt 155 HR 77 temp 36.6 wt 90 kg rr 18 SpO2 98 BP 110/72\nPresented with mild non productive cough associated with sore throat\nReports also of runny nose with sneezing\nno fevers reported\non and off with headache\nros: nad\no/e: stable, afebrile, no jaundice, no edema, no cyanosis\nent: slightly inflammed pharynx, turbinates normal\nr/s: tranemitted breadth sounds\nother s/e: nad\nimpression: bronchitis/rhinitis\nplan\ntx as prescribed\nLikert Score: 4 Reasonably thorough\nExplanation: includes CC, relevant vitals, reasonable amount of HPI described for a simple\nissue, though further characterization of the headache would be ideal;  findings of relevant\nsystems on exam are included, though not extensively\nExample 3\n4 y 9 mo old\nCC: fever\nVitals: HR 94, temp 36.4, wt 17 kg, rr 19 SpO2 99% MUAC - yellow\ninformant mother\nhistory of hotness of the body for 1day\nalso has a dry cough for 1day\nno history of running nose\nno history of vomiting\nno history of diarrhoea\nno history of travelling to malaria endemic region\npremed antipyretic\non examination fair general condition\nnot pale no jaundice no cyanosis\nr/s chest clear\nent hyperemic throat\n—-----------------------------------\nplan\nfhg\nstrep A ag test'\ndeslit 5mls od 5/7\nbrustan 5mls tds 3/5\ncefuroxime 250mg/5mls bd 5/7\nLikert Score: 3 Limited\nExplanation: missing PMH but reasonable HPI, although no mention of if ear pain exists or\nnot; exam too limited, a 4 year old with fever should have a documented abdominal exam\nand skin exam and, without an otoscope, perhaps an external ear exam of pulling on ear and\ncheck for tenderness over mastoid, in addition to what is here\nExample 4\n4y 2m\nInformant-mother\nHr 116 temp 36.2 wt 20 kg rr 25 SpO2 95 MUAC - green\nPresented with 1 day history of sudden onset of ear pains\nNo history of discharge, no swelling\nNo history of any injury or trauma\nReports nasal blockage and cough especially in the evening and morning\nNo difficulty in breathing, no fevers,\nAble to feed well, no vomiting, no diarrhea\nPremedication-Cetrizine\nOn examination-In fair general condition\nEar, Nose & Throat exam-Blocked nostrils,\nChest exam-Bilateral air entry, no rhonchi, no crepitations\nImpression-Acute otitis media, acute rhinitis\nPLAN\nAmoxyclave 5mls bd 5/7\nBrustan 5mls Three times daily 3/7\nSaline drops 2drops Three times daily 3/7\nLikert Score: 3 Limited\nExplanation: most relevant history elements are documented; however, there is no ear\nexam documented for history of sudden ear pain. While no otoscope is available so no\nmiddle ear exam can be documented, evaluation for external otitis is possible through pulling\non ear and evaluation for mastoiditis is possible through assessing for tenderness over\nmastoid; also no chief complaint\nExample 5\n8 year 2 month\nVitals: HR 104, temp 36.7, wt 30 kg, rr 20 SpO2 99%\ndiclofenac injection admnistred 75mg im\nPatient Summary:\nAge/Gender: 2-year-old male\nInformant: Father\nPresenting Reason:\nFollow-up after fall 2 weeks ago, presents with distorted gait and pain in the right hip.\nHistory:\nFall: Fell at school 21 days ago while playing, hit right hip on a stone.\nGait: Walking with a distorted gait, leaning to the right side.\nPain Concealment: The child has been attempting to conceal pain.\nSwelling & Bruising: No swelling or ecchymosis noted.\nTenderness: Tenderness elicited on the right hip.\nPain with Movement: Obvious pain with both external and internal movements of the hip and with\nrange of motion.\nPhysical Examination:\nGeneral Appearance: Clinically stable patient.\nVitals: Normal.\nMusculoskeletal: Tenderness on the right hip with pain during range of motion (internal and\nexternal). No swelling or bruising.\nLikert Score: 2 Deficient\nExplanation: discrepancy of age listed; no documentation of if any recent fever, malaise,\nweight loss all needed for assessment of infectious causes of pain (septic arthritis, osteo)\nwhich can develop after an injury; no documentation of how the injury was cared for initially\n(prior imaging?); no documentation of spine or abdominal exam (can present with hip pain)\nExample 6:\n55 y 9 m\nKNWN hypertension patient ON MEDS\nTODAY BPS - 174/101 MMHG 80B/MIN\nHAD DONE LIPID PROFILE / UECS DONE , NORMAL PATIENT EXPLAINED\nBPS EXPLAINED\nPLAN\nNIFEDIPINE 40 MG\nSTART AMLOOZAH H\nLikert Score: 1 Very poor\nExplanation: patient presents with high BP and no documentation of if patient has any\nsymptoms, no history is documented at all other than known HTN. Other PMH? Other\nmeds? No physical exam documented.\nExample 7\n30y 5m\nHR 77 temp 36.4 wt 58 kg rr 16 Spo2 100\nhistory of vaginal discharge, no itchiness, no pain on micturation, no lower abdominal pains, no\nbacka pains.\nreports of headache, with reported history of a stress,.\nLikert Score: 1: Very poor\nExplanation: extremely limited, omits several critical components: no chief compliant,\nextremely limited description of the vaginal discharge (no duration, description, associated\nsymptoms of fever, pelvic pain, bleeding, sexual history, menstrual history) and no\ncharacterization at all of the headache; completely absent physical exam\nLikert Examples for Investigations\nExample 1:\n27y 1m\nCC: throat irritation\nit has been there for the laat 2 days\nhe has been using warm water for the same but there is no much improvement\nthere is some pain on the right side of his throat especialy when swallowing\nthere is no fevers\nno chiklls\nno joint pains\nno runny nose\nhe has been using saline water to gurgle\nno known food or drug allergy\non exam\nnot pale\nno jaundice\nno dehydration\nent-slightly inflammed throat\ncvs- normal\ncns- normal\nStreptococcus A Antigen Test: Result: Negative\nLikert Score: 5 Appropriate & Targeted\nExplanation: Strep A test only is the correct investigation for the clinical scenario\nExample 2:\nChief Complaint: Skin Rash, Dry, itchy skin\n30y 3m\npresented with dry skin rashes assoc with\nitchyness ,\nhad severe itchynessespecially at the armpits\nit appers at the neck and armpits\no/e ; fgc\narmpit/neck rash , shyny , scally and itchy, no raised borders\nimpression; atpoic dermatitis/eczema\nplan\nbetametasone/salicylic cream apply bd\ndesloratadine 5mg od\npdl 5mg bd\nkeep skin moisurerized\nInvestigations: none\nLikert Score: 5 Appropriate & Targeted\nExplanation: In this clinical scenario, it is most appropriate to not order any investigations\nas none are needed for diagnostic clarity or treatment plan generation.\nExample 3:\nChief Complaint (CC):\n53-year-old female presenting with cough, runny nose, and sore throat for 1 day.\nHistory of Present Illness (HPI):\nThe patient reports onset of symptoms yesterday, starting with a headache relieved by Mara Moja\n(analgesic), followed by nasal congestion, dry cough, and throat pain especially on swallowing. She\nalso describes a sensation of chest heaviness without pain or difficulty in breathing. Additionally,\nshe experienced hotness of the body at night and general weakness. She denies joint pains,\ngastrointestinal symptoms, or recent travel to malaria-endemic areas. No other complaints\nreported.\nAllergies & Medications:\nAllergies: NKDFA\nPremeds: Mara Moja (OTC analgesic)\nVitals (11/04/2025):\nTemperature: 36.4°C\nPulse: 57 bpm\nRespiratory Rate: 16 bpm\nBlood Pressure: 117/74 mmHg\nSpO₂: 97% on room air\nBMI: 28.38 (Weight: 63 kg, Height: 149 cm)\nExamination Findings:\nGeneral: Stable condition\nENT: Inflamed throat\nSystemic Exam: Normal across respiratory, cardiovascular, and abdominal systems\nAssessment & Plan:\nAssessment:\nAcute Upper Respiratory Tract Infection (URTI) – likely viral etiology\nSupported by sore throat, dry cough, nasal congestion, and absence of systemic signs of bacterial\ninfection\nRule out Streptococcal pharyngitis – given throat pain and inflamed pharynx\nInvestigations:\nStreptococcus A antigen test\nComplete blood count (CBC)\nInvestigations:\nStrep A Antigen Test: Negative\nCBC:\nWBC: 4.54 x10⁹/L (within normal range)\nNeutrophils: 2.15 x10⁹/L (low-normal)\nLymphocytes: 1.99 x10⁹/L (normal)\nHemoglobin: 14.6 g/dL (normal)\nPlatelets: 360 x10⁹/L (normal)\nMildly elevated lymphocyte % (44%) and reduced neutrophil % (47.3%)\nAssessment & Plan:\nAssessment:\nAcute upper respiratory tract infection, likely viral in origin – suggested by sore throat, nasal\ncongestion, dry cough, and negative Strep A test.\nViral pharyngitis or rhinitis is most likely; no evidence of bacterial infection (normal to low WBC,\nnegative Strep A, afebrile, and stable vitals).\nOverweight with BMI of 28.38 – lifestyle advice warranted.\nManagement Plan:\nSymptomatic management:\nAdequate fluids and rest\nParacetamol for headache and body aches if needed\nAvoid unnecessary antibiotic use\nPatient Education:\nCondition likely viral; expected resolution within 5–7 days.\nImportance of hydration and nutrition.\nStreptococcus A Antigen Test: Result: Negative\nFull Haemogram (FHG): PDW: 15.10, RDW-CV: 14.90, HCT: 40.30, MCHC: 36.20, WBC: 4.54,\nPCT: 0.31, MCV: 86.00, Lymphocyte Percentage: 44.00, Plt: 360.00, Lymphocytes Count: 1.99,\nMPV: 8.60, Mid-granulocyte Percentage: 8.70, Mid-granulocytes Count: 0.40, P-LCC: 65.00, MCH:\n31.10, Result..: Abnormal, Neutrophill count: 2.15, Neutrophill percentage : 47.30, P-LCR: 18.00,\nRBC (Full Haemogram): 4.69, RDW-SD: 43.60, HGB: 14.60\nLikert Score: 4 Minor Overordering\nExplanation: Strep test indicated, full hemogram may not be necessary though not harmful\nExample 4:\n40 y 0m\npresents with above several days prior to the visit\nhistory of pain on urination\nno history of urethral discharge\nreports of abd bloating and abd pain\nno history of diarrhoea / vomiting\nno history of travel to a malaria endemic area\non examination\nfgc , not Pale, no cy, no j, no deh2o\nEar, Nose & Throat normal\nsystemic examination- unremarkable\nimp ge / amoebiaisis / Peptic Ulcer Disease / bacterial infection / uti\nplan\nu/a\nfhg\nstool for o/c\nstool for h-pylory\nDiagnosis bacterial infection / acute bacterial ge / uti\nplan\ncefuroxime 500mg bd for 5 days\nmyospaz 1 tab bd for 3 days\nH. Pylori - Stool: Result: Negative\nFull Haemogram (FHG): MCH: 23.50, HGB: 13.10, P-LCC: 61.00, RDW-CV: 15.80, P-LCR: 28.80,\nRBC (Full Haemogram): 5.58, RDW-SD: 39.30, Result..: Abnormal, HCT: 43.50, Mid-granulocyte\nPercentage: 9.20, PDW: 19.70, Neutrophill percentage : 75.20, MPV: 11.70, Neutrophill count: 5.95,\nWBC: 7.94, Mid-granulocytes Count: 0.73, MCHC: 30.10, PCT: 0.24, Lymphocyte Percentage:\n15.60, Lymphocytes Count: 1.23, MCV: 77.90, Plt: 212.00\nStool Microscopy: Result..: Abnormal, Yeast cells (Microscopy): None, Amount of yeast cells: None,\nParasites: No Ova/Cyst, Crystals -- Type: None, Mucous: Absent, RBC's (Microscopy): None,\nConsistency : Semi formed, Colour : Brown, Crystals -- Amount: None, Blood (Gross Appearance):\nAbsent, Pus cells: Moderate\nUrine Analysis: Result..: Abnormal, Nitrate: Negative, Bilirubin.: 0, Amount of yeast cells: None, Pus\ncells: Moderate, Specific Gravity: 1.02, Yeast cells (Microscopy): None, Crystals -- Amount\n(Microscopy): None , Colour.: Amber, Appearance (Urine Analysis): Clear, Casts - type: None,\nUrobilinogen: 0, RBC's (Urinalysis-Microscopy): None, Glucose: 0, Crystals -- Type: None,\nLeukocytes: +2, Parasites (Urine Microscopy): None, Epithelial Cells: None, pH (Dipstick): 6.00,\nProteins: 0, Blood (Dipstick): 0, Trichomonads (Urinalysis-Microscopy): Absent, Ketones: 0\nLikert Score: 3 Overly broad\nExplanation: Urinalysis and stool testing are clearly appropriate. H pylori testing may be\nindicated given local prevalence but not much supporting documentation for it (abd pain +\nbloating, but no clear documentation of where in the abdomen the pain is located, no\ndocumentation around belching or excess gas, weight loss, or color of stools). Full\nhemogram is overly broad, no clear indication for it based on documentation.\nExample 5:\n5y 2m\nClinical Presentation\nPatient Profile:\nA previously well child who became symptomatic yesterday.\nHistory of Presenting Illness:\nThe child began experiencing abdominal pain, localized around the umbilical region, followed by\nvomiting. She has since had five episodes of non-projectile vomiting, containing ingested food and\nnot blood-stained. The abdominal pain is intermittent.\nThis morning, she developed loose, foul-smelling diarrhea, which is non-bloody. She also had fever\nin the morning, for which she was given Calpol.\nThere are no known food or drug allergies.\nPhysical Examination:\nGeneral: Not pale, no jaundice\nHydration Status: No dehydration; skin turgor <1 second, capillary refill <1 second\nAbdomen (P.A.): Non-distended, non-tender on palpation; no signs of umbilical hernia\nCardiovascular System: Heart sounds S1 and S2 heard; no murmurs\nRespiratory System: Clear breath sounds\nMusculoskeletal System: Normal\nCentral Nervous System: Normal\nDevelopmental Milestones: Normal\nStool Microscopy: Crystals -- Type: None, Result..: Abnormal, Consistency : Liquid/Loose, RBC's\n(Microscopy): None, Parasites: No Ova/Cyst, Pus cells: Few, Blood (Gross Appearance): Absent,\nColour : Brown, Yeast cells (Microscopy): None, Mucous: Absent, Amount of yeast cells: None,\nCrystals -- Amount: None\nLikert Score: 2 Deficient\nExplanation:  Evaluation of stool microscopy looking for blood, parasites, pus/mucous is\nvery appropriate given this presentation and regional epidemiology. A 5 year old with fever\nmay also be evaluated with a malaria test in this scenario.\nExample 6:\n8 year 2 month\nVitals: HR 104, temp 36.7, wt 30 kg, rr 20 SpO2 99%\ndiclofenac injection admnistred 75mg im\nPatient Summary:\nAge/Gender: 2-year-old male\nInformant: Father\nPresenting Reason:\nFollow-up after fall 2 weeks ago, presents with distorted gait and pain in the right hip.\nHistory:\nFall: Fell at school 21 days ago while playing, hit right hip on a stone.\nGait: Walking with a distorted gait, leaning to the right side.\nPain Concealment: The child has been attempting to conceal pain.\nSwelling & Bruising: No swelling or ecchymosis noted.\nTenderness: Tenderness elicited on the right hip.\nPain with Movement: Obvious pain with both external and internal movements of the hip and with\nrange of motion.\nPhysical Examination:\nGeneral Appearance: Clinically stable patient.\nVitals: Normal.\nMusculoskeletal: Tenderness on the right hip with pain during range of motion (internal and\nexternal). No swelling or bruising.\nInvestigations: none\nLikert Score: 1: Very poor\nExplanation: child with hip pain and distorted gait and tenderness with exam 3 weeks after\ninjury should have investigations looking for bacterial infection, CBC at minimum\nLikert Examples for Diagnosis\nExample 1:\n27y 1m\nCC: throat irritation\nit has been there for the last 2 days\nhe has been using warm water for the same but there is no much improvement\nthere is some pain on the right side of his throat especialy when swallowing\nthere is no fevers\nno chiklls\nno joint pains\nno runny nose\nhe has been using saline water to gurgle\nno known food or drug allergy\non exam\nnot pale\nno jaundice\nno dehydration\nent-slightly inflammed throat\ncvs- normal\ncns- normal\nStreptococcus A Antigen Test: Result: Negative\nDiagnosis: Pharyngitis\nLikert Score: 5: Excellent\nExplanation: Pharyngitis is the most likely accurate diagnosis for the clinical scenario. No\nother additional diagnoses are needed.\nExample 2:\nLMP-UPTO DATE\nKNWN patient WITH PAINFUL PERIODS\nDID FOLLOW UP WITH GYNAECOLOGICAL REVIEW AND WAS TOLD ITS NORMAL PAIN\nHEAVY-USES 4-5PADS IN 2 ND DAY\nTHEN REDUCES GRADUALLY\nNO HEADACHE\nNO DIZZINESS\nNO CHRONIC ILNESS\nNO DRUG ALLERGY\nON EXAM-SHE IS STABLE\nDX-DYSMENORRHOEA\nPLAN\nP.O PONSTAN 1 TAB BD FOR 5 DAYS\nDiagnosis: Dysmenorrhoea\nLikert Score: 4: Good\nExplanation: Minimal history around the quality and timing of pain makes it challenging to\nsay that this is clearly the most likely accurate diagnosis, but it aligns with the clinical picture\nand is among the top few likely diagnoses.\nExample 3:\n4y 7m\nPresented with cough of gradual onset persistent and irritative associated\nwith runny nose\nReports also of nasal blockage\nno fevers reported\nfeeds well\nros: nad\no/e: stable, afebrile, no jaundice, no edema, no cyanosis\nent: inflammed tonsils with exudates\nr/s: tranmitted breadth sounds, no crepitations, no rhonchi\nother s/e; nad\nimpression: bronchitis/rhinitis/tonsilitis\nplan\nadviced on hydration/tx as prescribed\nInvestigations: none\nDiagnosis: Acute bronchitis, tonsilitis, acute bacterial\nLikert Score: 3: Adequate\nExplanation: Acute bacterial tonsillitis is less likely than viral tonsillitis and no investigation\nwas done to determine the cause. This diagnosis is plausible, but not the most likely.\nExample 4:\n0y 8m\nthe mother reports that she has 3 days history of a runny nose\nassociated with nasal congestion and mild fever\nno dib\nno cough\nno pre medication\nno history of drug allergy\nON EXAM\nAfebrile\nunderweight\nnot pale/jaundiced.dehydrated\nclesar chest\nnormal throat exam\nenlarged nasal turbinates\nINVESTIGATION\nfull haemogram\nDIAGNOSIS\nacute rhinitis with enlarged nasal turbinates\nPLAN\nephedrin nasal drop bd for 5 days\ncalpol 5mls orally for 3 days\naerius 2.5mls orally for 5 days\nrehydrate with warm fluids\nDiagnosis: Allergic rhinitis, Adenoid hypertrophy\nLikert Score: 2: Deficient\nExplanation: MUC yellow, not noted in the diagnosis field (though is noted on physical exam\nin clinical note); should have a diagnosis of underweight or malnourished in the diagnosis\nfield; additionally the child is noted to have enlarged turbinates on exam but is given a\ndiagnosis of adenoidal hypertrophy which is not well supported by the documentation.\nExample 5:\nHas a complete miscarriage , was medical evacuated came with complains of vaginal discomfort ,\nattending doctor requested her to come for medication three days post procedure.\nO/E\nstble\nno distress\np/a\n-unremakble\nIMPRESSIONS: urinary tract infection\nPlan\nPer oral cefuroxime 500mg bd 5/7\nPessaries Infa V 1 nocte 5/7\nInvestigations: none\nDiagnosis: Uncomplicated Urinary Tract Infection (UTI)\nLikert Score: 1: Very poor\nExplanation: No dysuria, suprapubic abd pain or fever documented, chief complaint does\nnot fit with UTI and explanation given for antibiotics is post procedure prophylaxis. No\nurinalysis is done. Diagnosis of UTI is clinically inappropriate and unsupported by\ndocumented findings.\nLikert Examples for Treatment\nExample 1:\n10y 5m\nWt: 22 kg\nmother reports 1 week history of abdominal pains of gradual onset with no relieving nor\nexacerbating factor, child reports the pain is on the epigastric region, reports history of loose stools\non and off with yesterday having a blood stained loose stools that has since resolved, no episodes\nof vomiting, child is currently on management for amoebiasis, on diracip-male syrup doing day 3\nfrom another facilty, no fevers, mother reports reduced appetite, no other complaints reported.\non exam: fgc, alert\nno jaundice, no pallor, no cyanosis, no dehydration, no edema\nheent- normal\nrs- chest clear on auscultation, no creps, no rhonchi\ncvs-s1, s2 heard, no murmurs\np/a- not distended, soft non tender, no organomegally\ncns- alert and well oriented\nmss- normal findings\nimpression: gastritis/dysentry\nplan\nh.pylori ag test\nstool o/c\nrx as per t-sheet\nmother advised to complete dosages\nadvised on nutritional review- said will come next thursday\nInvestigations: Stool Microscopy: Consistency : Formed, Blood (Gross Appearance): Absent,\nMucous: Absent, Crystals -- Amount: None, Parasites: No Ova/Cyst, Result..: Normal, Yeast cells\n(Microscopy): None, Crystals -- Type: None, Colour : Brown, RBC's (Microscopy): None, Pus cells:\nNone, Amount of yeast cells: None\nH. Pylori - Stool: Result: Positive\nDiagnosis: Helicobacter pylori gastritis\nTreatment: Paracetamol susp 250mg/5ml: 5 MLS, 3 Times a day, As directed for 3 Days\nAmoxicillin susp 250mg/5ml: 10 MLS, 2 Times a day, As directed for 14 Days\nClarithromycin susp 250mg/5ml 50ml: 5 ml, 2 Times a day, As directed for 14 Days\nOmeprazole caps 20mg: 1 capsule, 1 Times a day, As directed for 14 Days\nLikert score: 5\nExplanation: Triple therapy with amoxicillin, clarithromycin and omeprazole is first line\ntreatment for pediatric H pylori in this setting.\nExample 2:\n2y 5m\npresents with complaints of cough dry in nature of gradual onset with no relieving nor aggrevating\nfactors worse at night and in the morning, no associated dib, no chest congestion, no fastbreathing,\nno history of wheezing, no history of nightsweats, no loss of appetite or weight, no fevers, no runny\nnose, child feeding well, premeds-piriton\non exam: fgc, alert, afebrile and actively playing, not in rs distress\nno jaundice, no pallor, no cyanosis, no dehydration, no edema\nheent- normal\nrs- no chest wall indrawing, chest clear on auscultation, no creps, no rhonchi\ncvs-s1, s2 heard, no murmurs\np/a- not distended, soft non tender, no organomegally\ncns- alert, neck soft, no signs of meningeal irritation\nmss- unremarkable findings\nimpression; bronchitis/allergic cough\nplan\nreassured\nTreatment as per t-sheet\nfor paeds review if the complaints persist\nadvised on hydration\ncounselled on danger signs to watch\nDiagnosis: Acute bronchitis, Rhinitis\nTreatment: Desloratidine syp 60ml: 5 ml, 1 Times a day, As directed for 5 Days\nLikert score: 4\nExplanation: Desloratadine is not clearly indicated or fist line treatment in acute bronchitis\nor rhinitis unless caused by environmental allergies. While safe in this age group and the\ndosage is correct, this is likely an overtreatment of symptoms that may not be effective.\nExample 3:\n15y 3m\nInformant-Mother.\nC/C-Runny nose\nCough\nReports of above complains with ass fromtal headache.\nAlso reports of ass nasal congestion.\nReports headache superficial.\nNo chest congestion.\nNo sore throat\nNo DIB\nPremeds-None.\noe-In faIr general condition\nAfebrile\nwell hydrated\nNo cyanosis\nNo wheeze\nRESP EXAM-No wheeze\nNoted rhonchi bibasal .\nENT-Adenoid hypertrophy.\ndx-Acute bronchitis/Asthma.\nAcute sinusitis.\ntx as prescribed,\nReferred for chest xray.\nReview with results.\nDiagnosis: Acute Sinusitis, Acute bronchitis\nTreatment: Fluticasone Furoate Spray 120D: 1 dose, 2 Times a day, As directed for 2 Days\nEffervescent Paracetamol tabs 1000mg: 1 tablet, 3 Times a day, After food for 3 Days\nAzithromycin tabs 500mg: 1 tablet, 1 Times a day, After food for 3 Days\nLikert score 3:\nExplanation: Diagnosis of sinusitis and acute bronchitis are sometimes treated with\nantibiotics, though many cases are viral. No duration of symptoms documented which\ngenerally dictates whether to treat these conditions with antibiotics vs supportive care. Of the\nantibiotic choices, Azithromycin is not the first line for either condition.\nExample 4:\n7y 7m\nVitals: hr 106, temp 37, wt 20.5 kg, rr 22, SpO2 98\nCough productive irritative in the morning and at night\nass with slight rhinorrhoea\nNo fevers ,no chest congestion\nNo loss of appetite\nNo other ass symptoms\npremed None\nreview of systems normal\nOn exam stable\nRESP Chest clear no wheeze ,no creps\nENT Normal\nDX Nasopharyngitis/Brochitis\nPlan\nDesloratadine\nPdl\nTreatment: desloratadine: 5 ml, 1 At night for 5 Days\nPrednisolone Oral solution 1mg/5ml: 5 ml, 2 Times a day, As directed for 5 Days\nLikert score 2:\nExplanation: A child with a likely viral cough without documented history of asthma, without\nhypoxia or documented resp distress - there is no clear indication for oral steroids, a\nmedication with significant potential side effects.\nExample 5:\n2y 2m\nbrought in with above for past 2 days\nhistory of spiking fevers worse at night, no assc convulsions,\nhistory of throat pain worse when swallowing , no cough\nno runny nose\nhistory of abdominal pain worse after feeding , no vomiting , no diarrhoea\npremeds- none\nno history of travel to a malaria endemic zone\no\\e- ina fgc\nnot in distress\nno pallor, no jaundice, no dehydrtaion\nrs- vesicular breath sounds, good airentry bilaterally , no lower chest wall indrawing\nent- normal\ncns- alert, neck soft\nper abdomen- mwr, soft non tender, no palpable mas\nimp- febrile illeness ? spsis r\\o amoebiasis\nplan\nfhg, ua stool for microscopy\nreview with results\nua- normal\nfhg- low level of hb- 9.4g\\dl , mcv, mch, mchc\nunable to get the stool ample\nplan\nmeds as prescribed\nadvised on diet rich in iron , green veges and fruits\nto bring the stool sample later\nhas brought the stool sample for microscopy\nreview\nmoderate pus cells , no oc\nplan\nmeds as prescribed\nfood and water hygien\nStool Microscopy: RBC's (Microscopy): None, Result..: Abnormal, Crystals -- Amount: None,\nAmount of yeast cells: None, Colour : Brown, Yeast cells (Microscopy): None, Blood (Gross\nAppearance): Absent, Crystals -- Type: None, Parasites: No Ova/Cyst, Consistency : Semi formed,\nPus cells: Moderate, Mucous: Absent\nUrine Analysis: Leukocytes: 0, RBC's (Urinalysis-Microscopy): None, Amount of yeast cells: None,\nNitrate: Negative, Casts - type: None, Urobilinogen: 0, Ketones: 0, Bilirubin.: 0, Appearance (Urine\nAnalysis): Clear, Crystals -- Amount (Microscopy): None , Glucose: 0, Trichomonads\n(Urinalysis-Microscopy): Absent, Parasites (Urine Microscopy): None, Crystals -- Type: None, Yeast\ncells (Microscopy): None, pH (Dipstick): 6.50, Blood (Dipstick): 0, Colour.: Amber, Pus cells: None,\nProteins: 0, Result..: Normal, Epithelial Cells: None, Specific Gravity: 1.02\nFull Haemogram (FHG): Lymphocyte Percentage: 33.70, MCHC: 31.20, P-LCR: 13.10, P-LCC:\n46.00, PCT: 0.26, RBC (Full Haemogram): 5.18, Neutrophill count: 5.46, WBC: 10.15, RDW-CV:\n17.20, MCV: 58.20, Lymphocytes Count: 3.42, RDW-SD: 38.40, MCH: 18.10, HGB: 9.40, MPV:\n7.50, Result..: Abnormal, Mid-granulocytes Count: 1.27, HCT: 30.10, Mid-granulocyte Percentage:\n12.50, Neutrophill percentage : 53.80, Plt: 351.00, PDW: 8.30\nAzithromycin susp 200mg/5ml 15ml: 3 MLS, 1 Times a day, After food for 3 Days\nIbuprofen/Paracetamol Susp 100mg/125mg 100ml: 7.5 MLS, 3 Times a day, After food for 3 Days\nFolic acid/Iron/Vitamin B12/Vitamin C syr 200ml: 2.5 ml, 2 Times a day, After food for 30 Days\nLikert score 1:\nExplanation: There is no indication for using Azithromycin and overuse/inappropriate use of\nantibiotics contributes to antibiotic resistance.",
    "is_context_enabled": true,
    "summary": "aiclinical.pdf [pdf | 12023986 bytes] — AI-based Clinical Decision Support for Primary Care: A Real-World Study Robert Korom*,1, Sarah Kiptinness *,1, Najib Adan1, Kassim Said 1, Catherine Ithuli1, Oliver Rotich 1, Boniface Kimani 1, Irene King’ori 1, Stellah Kamau 1, Elizabeth Atemba1, Muna Aden2, Preston Bowman3, Michael Sharman3, Rebecca Soskin Hicks 3, Rebecca Distler3, Johannes Heidecke3, Rahul K. Arora *,3, Karan Singhal *,3 1Pe"
  }
]